{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48060c32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper LLM Competition - Custom GRPO Training\n",
    "\n",
    "## Goal\n",
    "Finetune an LLM with LoRA using GRPO to play Minesweeper by:\n",
    "- **Input**: JSON game state (board configuration)\n",
    "- **Output**: JSON action (reveal or flag a cell)\n",
    "\n",
    "Teams will compete to train the best Minesweeper-playing LLM!\n",
    "\n",
    "## Training Approach\n",
    "- **Model**: Qwen2.5-14B-Instruct (from /root/.cache/huggingface/hub)\n",
    "- **Method**: GRPO (Group Relative Policy Optimization)\n",
    "- **Framework**: Unsloth (2-6x faster, 70% less VRAM)\n",
    "- **Hardware**: AMD MI300X GPU (192GB HBM3, ROCm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c2e56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load Model with Unsloth\n",
    "\n",
    "Load Qwen3-4B with LoRA configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e1118e-9532-4aa3-a4eb-ecf1bb2abb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"./workspace/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ecb51d-67e6-42e4-b739-cea6e57ab2a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m snapshot_download\n\u001b[32m      3\u001b[39m snapshot_download(\n\u001b[32m      4\u001b[39m     repo_id=\u001b[33m\"\u001b[39m\u001b[33munsloth/Qwen2.5-14B-Instruct\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     local_dir=\u001b[33m\"\u001b[39m\u001b[33m./workspace/Qwen2.5-14B-Instruct\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     local_dir_use_symlinks=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"unsloth/Qwen2.5-14B-Instruct\",\n",
    "    local_dir=\"./workspace/Qwen2.5-14B-Instruct\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af32493",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unsloth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'unsloth'"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "# Load config\n",
    "with open(\"minesweeper_config_me.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "lora_rank = config.get(\"lora_rank\", 32)\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"/workspace/workspace/Qwen2.5-14B-Instruct\",\n",
    "    load_in_4bit=False,   # AMD → 4bit disabled\n",
    "    max_seq_length=2048,  # Increased: larger boards need longer prompts\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Device: {model.device}\")\n",
    "print(f\"LoRA rank: {lora_rank} (from config)\")\n",
    "\n",
    "# ── Add newline as EOS token so generation stops after first JSON line ──\n",
    "# (replaces stop_strings which isn't supported by this GRPOConfig version)\n",
    "newline_token_id = tokenizer.encode(\"\\n\", add_special_tokens=False)[-1]\n",
    "original_eos = tokenizer.eos_token_id\n",
    "if original_eos != newline_token_id:\n",
    "    model.generation_config.eos_token_id = [original_eos, newline_token_id]\n",
    "    model.config.eos_token_id = [original_eos, newline_token_id]\n",
    "    print(f\"  ✅ Added newline (token {newline_token_id}) as additional EOS → stops after JSON line\")\n",
    "    print(f\"     EOS tokens: {model.generation_config.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f0712",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Add LoRA Adapters\n",
    "\n",
    "Add LoRA layers for efficient finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd54ba09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FastLanguageModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mFastLanguageModel\u001b[49m.get_peft_model(\n\u001b[32m      2\u001b[39m     model,\n\u001b[32m      3\u001b[39m     r = lora_rank,\n\u001b[32m      4\u001b[39m     target_modules = [\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mq_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mk_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mv_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mo_proj\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgate_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mup_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdown_proj\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     ],\n\u001b[32m      8\u001b[39m     lora_alpha = lora_rank,           \u001b[38;5;66;03m# alpha = rank → scaling factor = 1.0 (stable training)\u001b[39;00m\n\u001b[32m      9\u001b[39m     lora_dropout = \u001b[32m0.05\u001b[39m,              \u001b[38;5;66;03m# Small dropout for regularization\u001b[39;00m\n\u001b[32m     10\u001b[39m     use_gradient_checkpointing = \u001b[33m\"\u001b[39m\u001b[33munsloth\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     random_state = \u001b[32m3407\u001b[39m,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoRA config: rank=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlora_rank\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, alpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlora_rank\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, dropout=0.05\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m model.print_trainable_parameters()\n",
      "\u001b[31mNameError\u001b[39m: name 'FastLanguageModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank,           # alpha = rank → scaling factor = 1.0 (stable training)\n",
    "    lora_dropout = 0.05,              # Small dropout for regularization\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "print(f\"LoRA config: rank={lora_rank}, alpha={lora_rank}, dropout=0.05\")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503f9af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper Game Implementation\n",
    "\n",
    "Custom Minesweeper environment supporting:\n",
    "- Customizable board size and mine count\n",
    "- Actions: reveal or flag cells\n",
    "- Win: reveal all safe cells\n",
    "- Lose: reveal a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fc3220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MinesweeperGame (competition spec: 1-50 boards, 0-20% mines)...\n",
      "  ✅ do_action keeps game ongoing on invalid moves\n",
      "  ✅ Board uses '?' for unrevealed cells\n",
      "  ✅ Game phase tracking works\n",
      "  ✅ 0-mine board → instant win on first reveal\n",
      "  ✅ 1x1 board with 0 mines works\n",
      "  ✅ 1x1 board with 1 mine correctly rejected\n",
      "  ✅ 50x50 board with 20% mines works\n",
      "  ✅ 1x50 and 50x1 boards work\n",
      "  ✅ 2x2 board with 0 mines → instant cascade win\n",
      "  ✅ Variable board sizes (1x1 to 50x50) work\n",
      "  ✅ sample_board_config produces valid configs (200 tested)\n",
      "  ✅ All game engine tests passed\n",
      "  Board range: 1-50 rows × 1-50 cols\n",
      "  Mine density: 0%-20%\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Set\n",
    "import random\n",
    "import math\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Board size configuration — competition spec: n,m ∈ [1,50], mines 0-20%\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Constants\n",
    "MIN_ROWS, MAX_ROWS = 1, 50\n",
    "MIN_COLS, MAX_COLS = 1, 50\n",
    "MIN_MINE_DENSITY = 0.0    # 0% mines allowed (trivial board)\n",
    "MAX_MINE_DENSITY = 0.20   # 20% of total cells\n",
    "\n",
    "\n",
    "def sample_board_config(rng=None):\n",
    "    \"\"\"Sample a random (rows, cols, num_mines) from the full competition range.\n",
    "\n",
    "    - rows ∈ [1, 50], cols ∈ [1, 50]\n",
    "    - mines ∈ [0, floor(0.20 * rows * cols)]\n",
    "    - Uses a weighted distribution favoring smaller boards during training\n",
    "      (large boards are rare but included for coverage).\n",
    "    \"\"\"\n",
    "    rng = rng or random.Random()\n",
    "\n",
    "    # Weighted size distribution: favor small/medium, still cover large\n",
    "    size_band = rng.random()\n",
    "    if size_band < 0.30:\n",
    "        # Small: 1-8\n",
    "        rows = rng.randint(1, 8)\n",
    "        cols = rng.randint(1, 8)\n",
    "    elif size_band < 0.55:\n",
    "        # Medium: 5-15\n",
    "        rows = rng.randint(5, 15)\n",
    "        cols = rng.randint(5, 15)\n",
    "    elif size_band < 0.75:\n",
    "        # Large: 10-30\n",
    "        rows = rng.randint(10, 30)\n",
    "        cols = rng.randint(10, 30)\n",
    "    elif size_band < 0.90:\n",
    "        # XL: 20-40\n",
    "        rows = rng.randint(20, 40)\n",
    "        cols = rng.randint(20, 40)\n",
    "    else:\n",
    "        # Full range: 1-50 (including extreme cases)\n",
    "        rows = rng.randint(1, 50)\n",
    "        cols = rng.randint(1, 50)\n",
    "\n",
    "    total = rows * cols\n",
    "    max_mines = int(total * MAX_MINE_DENSITY)  # floor(0.20 * total)\n",
    "\n",
    "    if max_mines == 0:\n",
    "        num_mines = 0  # Boards too small for any mines at ≤20%\n",
    "    else:\n",
    "        num_mines = rng.randint(0, max_mines)\n",
    "\n",
    "    return rows, cols, num_mines\n",
    "\n",
    "\n",
    "def mine_density(rows, cols, num_mines):\n",
    "    \"\"\"Compute mine density as a fraction.\"\"\"\n",
    "    total = rows * cols\n",
    "    return num_mines / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MinesweeperGame:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    num_mines: int\n",
    "    seed: Optional[int] = None\n",
    "    _rng: random.Random = field(init=False, repr=False)\n",
    "    _board: List[List[int]] = field(init=False, repr=False)  # -1 = mine, 0-8 = count\n",
    "    _revealed: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _flagged: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _state: str = field(default=\"ongoing\", init=False, repr=False)\n",
    "    _move_count: int = field(default=0, init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # ── Input validation — competition spec: n,m ∈ [1,50] ──\n",
    "        if self.rows < MIN_ROWS or self.cols < MIN_COLS:\n",
    "            raise ValueError(f\"Board too small: {self.rows}x{self.cols} (min {MIN_ROWS}x{MIN_COLS})\")\n",
    "        if self.rows > MAX_ROWS or self.cols > MAX_COLS:\n",
    "            raise ValueError(f\"Board too large: {self.rows}x{self.cols} (max {MAX_ROWS}x{MAX_COLS})\")\n",
    "        if self.num_mines < 0:\n",
    "            raise ValueError(f\"num_mines cannot be negative, got {self.num_mines}\")\n",
    "        if self.num_mines >= self.rows * self.cols:\n",
    "            raise ValueError(f\"Too many mines ({self.num_mines}) for {self.rows}x{self.cols} board\")\n",
    "        # 0 mines is allowed — trivial board, instant win on first reveal cascade\n",
    "\n",
    "        self._rng = random.Random(self.seed)\n",
    "        self._board = [[0 for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "        self._place_mines()\n",
    "        self._calculate_numbers()\n",
    "\n",
    "        # ── Edge case: 0 mines → all cells are safe, auto-win on init check ──\n",
    "        self._check_win()\n",
    "\n",
    "    def _place_mines(self):\n",
    "        \"\"\"Place mines randomly on the board.\"\"\"\n",
    "        if self.num_mines == 0:\n",
    "            return  # No mines to place\n",
    "        positions = [(r, c) for r in range(self.rows) for c in range(self.cols)]\n",
    "        mine_positions = self._rng.sample(positions, self.num_mines)\n",
    "        for r, c in mine_positions:\n",
    "            self._board[r][c] = -1\n",
    "\n",
    "    def _calculate_numbers(self):\n",
    "        \"\"\"Calculate numbers for each cell based on adjacent mines.\"\"\"\n",
    "        for r in range(self.rows):\n",
    "            for c in range(self.cols):\n",
    "                if self._board[r][c] == -1:\n",
    "                    continue\n",
    "                count = 0\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if 0 <= nr < self.rows and 0 <= nc < self.cols:\n",
    "                            if self._board[nr][nc] == -1:\n",
    "                                count += 1\n",
    "                self._board[r][c] = count\n",
    "\n",
    "    def _reveal_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Reveal a cell. Returns True if valid move, False if invalid.\n",
    "        Uses iterative flood-fill to avoid recursion limit on large boards.\n",
    "        \"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed or (row, col) in self._flagged:\n",
    "            return False\n",
    "\n",
    "        stack = [(row, col)]\n",
    "        while stack:\n",
    "            r, c = stack.pop()\n",
    "            if (r, c) in self._revealed:\n",
    "                continue\n",
    "\n",
    "            self._revealed.add((r, c))\n",
    "\n",
    "            # Hit a mine!\n",
    "            if self._board[r][c] == -1:\n",
    "                self._state = \"failed\"\n",
    "                return True\n",
    "\n",
    "            # Auto-reveal neighbors if cell is 0\n",
    "            if self._board[r][c] == 0:\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < self.rows and 0 <= nc < self.cols\n",
    "                                and (nr, nc) not in self._revealed\n",
    "                                and (nr, nc) not in self._flagged):\n",
    "                            stack.append((nr, nc))\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _flag_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Flag/unflag a cell. Returns True if valid, False if invalid.\"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed:\n",
    "            return False\n",
    "\n",
    "        if (row, col) in self._flagged:\n",
    "            self._flagged.remove((row, col))\n",
    "        else:\n",
    "            self._flagged.add((row, col))\n",
    "        return True\n",
    "\n",
    "    def do_action(self, action: dict) -> str:\n",
    "        \"\"\"Execute an action and return a status string.\n",
    "\n",
    "        Returns one of:\n",
    "          'ok'               - valid move executed\n",
    "          'mine'             - revealed a mine (game over → state='failed')\n",
    "          'win'              - game won after this move (all safe cells revealed)\n",
    "          'invalid_format'   - bad action dict / missing keys / bad types\n",
    "          'out_of_bounds'    - coordinates outside the board\n",
    "          'already_revealed' - cell was already revealed\n",
    "          'flagged_cell'     - tried to reveal a flagged cell\n",
    "          'invalid_flag'     - tried to flag a revealed cell\n",
    "          'game_over'        - game was already over before this call\n",
    "\n",
    "        Only 'mine' sets state='failed'. All other invalid moves\n",
    "        return an error string but keep the game 'ongoing'.\n",
    "        NO move limit — game continues until success or failure.\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return \"game_over\"\n",
    "\n",
    "        if not isinstance(action, dict):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        action_type = action.get(\"type\")\n",
    "        row = action.get(\"row\")\n",
    "        col = action.get(\"col\")\n",
    "\n",
    "        if action_type not in (\"reveal\", \"flag\") or row is None or col is None:\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        try:\n",
    "            row, col = int(row), int(col)\n",
    "        except (ValueError, TypeError):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return \"out_of_bounds\"\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"already_revealed\"\n",
    "            if (row, col) in self._flagged:\n",
    "                return \"flagged_cell\"\n",
    "            self._reveal_cell(row, col)\n",
    "            self._move_count += 1\n",
    "        else:  # flag\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"invalid_flag\"\n",
    "            self._flag_cell(row, col)\n",
    "            self._move_count += 1\n",
    "\n",
    "        self._check_win()\n",
    "\n",
    "        if self._state == \"failed\":\n",
    "            return \"mine\"\n",
    "        if self._state == \"success\":\n",
    "            return \"win\"\n",
    "        return \"ok\"\n",
    "\n",
    "    def _check_win(self):\n",
    "        \"\"\"Check if player has won.\n",
    "\n",
    "        Win condition: ALL safe (non-mine) cells are revealed.\n",
    "        With 0 mines, ALL cells are safe → need to reveal every cell.\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return\n",
    "        total_cells = self.rows * self.cols\n",
    "        safe_cells = total_cells - self.num_mines\n",
    "        if safe_cells == 0:\n",
    "            self._state = \"success\"\n",
    "        elif len(self._revealed) >= safe_cells:\n",
    "            self._state = \"success\"\n",
    "\n",
    "    def get_visible_board(self) -> List[List[str]]:\n",
    "        \"\"\"Get board state as player sees it.\n",
    "        Uses '?' for unrevealed cells (competition standard).\n",
    "        \"\"\"\n",
    "        visible = []\n",
    "        for r in range(self.rows):\n",
    "            row = []\n",
    "            for c in range(self.cols):\n",
    "                if (r, c) in self._flagged:\n",
    "                    row.append('F')\n",
    "                elif (r, c) in self._revealed:\n",
    "                    val = self._board[r][c]\n",
    "                    row.append('*' if val == -1 else str(val))\n",
    "                else:\n",
    "                    row.append('?')\n",
    "            visible.append(row)\n",
    "        return visible\n",
    "\n",
    "    def state(self) -> str:\n",
    "        return self._state\n",
    "\n",
    "    @property\n",
    "    def move_count(self) -> int:\n",
    "        return self._move_count\n",
    "\n",
    "    def get_mine_positions(self) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"Return set of all mine positions (for reward computation).\"\"\"\n",
    "        return {(r, c) for r in range(self.rows) for c in range(self.cols)\n",
    "                if self._board[r][c] == -1}\n",
    "\n",
    "    def progress(self) -> float:\n",
    "        \"\"\"Fraction of safe cells revealed (0.0 to 1.0).\"\"\"\n",
    "        safe_cells = self.rows * self.cols - self.num_mines\n",
    "        return len(self._revealed) / safe_cells if safe_cells > 0 else 1.0\n",
    "\n",
    "    def game_phase(self) -> str:\n",
    "        \"\"\"Determine the current game phase for prompt selection.\"\"\"\n",
    "        if self._move_count == 0 and len(self._revealed) == 0:\n",
    "            return \"opening\"\n",
    "        prog = self.progress()\n",
    "        if prog >= 0.80:\n",
    "            return \"endgame\"\n",
    "        return \"midgame\"\n",
    "\n",
    "    def pretty_print(self) -> str:\n",
    "        \"\"\"Pretty print the board.\"\"\"\n",
    "        visible = self.get_visible_board()\n",
    "        lines = []\n",
    "\n",
    "        # Header — handle up to 2-digit column numbers\n",
    "        col_width = 3 if self.cols > 10 else 2\n",
    "        header = \"   \" + \" \".join(f\"{i:>{col_width-1}d}\" for i in range(self.cols))\n",
    "        lines.append(header)\n",
    "        lines.append(\"  \" + \"─\" * (self.cols * col_width + 1))\n",
    "\n",
    "        # Board\n",
    "        for r, row in enumerate(visible):\n",
    "            sep = \" \" * (col_width - 1)\n",
    "            line = f\"{r:2d}│ \" + sep.join(row)\n",
    "            lines.append(line)\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Sanity tests\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "print(\"Testing MinesweeperGame (competition spec: 1-50 boards, 0-20% mines)...\")\n",
    "\n",
    "# Basic gameplay\n",
    "g = MinesweeperGame(5, 5, 3, seed=0)\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": -1, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\", \"BUG: out_of_bounds should NOT end the game\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 99, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"flag\", \"row\": 0, \"col\": 0}) == \"ok\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0}) == \"flagged_cell\"\n",
    "assert g.state() == \"ongoing\", \"BUG: flagged_cell should NOT end the game\"\n",
    "assert g.do_action({}) == \"invalid_format\"\n",
    "assert g.state() == \"ongoing\", \"BUG: invalid_format should NOT end the game\"\n",
    "print(\"  ✅ do_action keeps game ongoing on invalid moves\")\n",
    "\n",
    "# Verify '?' is used for unrevealed cells\n",
    "board = g.get_visible_board()\n",
    "has_question = any('?' in row for row in board)\n",
    "assert has_question, \"Board should use '?' for unrevealed cells\"\n",
    "print(\"  ✅ Board uses '?' for unrevealed cells\")\n",
    "\n",
    "# Game phase tracking\n",
    "assert g.game_phase() == \"opening\" or g.move_count > 0\n",
    "print(\"  ✅ Game phase tracking works\")\n",
    "\n",
    "# ── Edge case: 0 mines board ──\n",
    "g0 = MinesweeperGame(3, 3, 0, seed=42)\n",
    "assert g0.state() == \"ongoing\"\n",
    "result = g0.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\", f\"0-mine board should win on first reveal, got {result}\"\n",
    "assert g0.state() == \"success\"\n",
    "print(\"  ✅ 0-mine board → instant win on first reveal\")\n",
    "\n",
    "# ── Edge case: 1x1 board with 0 mines ──\n",
    "g1x1 = MinesweeperGame(1, 1, 0, seed=42)\n",
    "assert g1x1.state() == \"ongoing\"\n",
    "result = g1x1.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\"\n",
    "print(\"  ✅ 1x1 board with 0 mines works\")\n",
    "\n",
    "# ── Edge case: 1x1 board — cannot have mines ──\n",
    "try:\n",
    "    MinesweeperGame(1, 1, 1, seed=42)\n",
    "    assert False, \"Should have raised ValueError\"\n",
    "except ValueError:\n",
    "    pass\n",
    "print(\"  ✅ 1x1 board with 1 mine correctly rejected\")\n",
    "\n",
    "# ── Edge case: 50x50 board ──\n",
    "g50 = MinesweeperGame(50, 50, 500, seed=42)\n",
    "assert g50.state() == \"ongoing\"\n",
    "assert g50.rows == 50 and g50.cols == 50\n",
    "assert mine_density(50, 50, 500) == 0.20\n",
    "print(\"  ✅ 50x50 board with 20% mines works\")\n",
    "\n",
    "# ── Edge cases: rectangular ──\n",
    "g1x50 = MinesweeperGame(1, 50, 10, seed=42)\n",
    "assert g1x50.rows == 1 and g1x50.cols == 50\n",
    "g50x1 = MinesweeperGame(50, 1, 10, seed=42)\n",
    "assert g50x1.rows == 50 and g50x1.cols == 1\n",
    "print(\"  ✅ 1x50 and 50x1 boards work\")\n",
    "\n",
    "# ── Edge case: 2x2 with 0 mines ──\n",
    "g2x2 = MinesweeperGame(2, 2, 0, seed=42)\n",
    "result = g2x2.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\"\n",
    "print(\"  ✅ 2x2 board with 0 mines → instant cascade win\")\n",
    "\n",
    "# Variable sizes across the full range\n",
    "for r, c, m in [(1,1,0), (2,2,0), (3,3,1), (5,5,3), (10,10,20),\n",
    "                (20,20,80), (30,30,180), (50,50,500), (1,50,10), (50,1,10)]:\n",
    "    g = MinesweeperGame(r, c, m, seed=42)\n",
    "    assert g.rows == r and g.cols == c\n",
    "    board = g.get_visible_board()\n",
    "    assert len(board) == r and len(board[0]) == c\n",
    "print(f\"  ✅ Variable board sizes (1x1 to 50x50) work\")\n",
    "\n",
    "# Test sample_board_config produces valid configs\n",
    "rng = random.Random(42)\n",
    "for _ in range(200):\n",
    "    r, c, m = sample_board_config(rng)\n",
    "    assert MIN_ROWS <= r <= MAX_ROWS\n",
    "    assert MIN_COLS <= c <= MAX_COLS\n",
    "    assert 0 <= m <= int(r * c * MAX_MINE_DENSITY)\n",
    "    g = MinesweeperGame(r, c, m, seed=42)\n",
    "print(f\"  ✅ sample_board_config produces valid configs (200 tested)\")\n",
    "\n",
    "# Test progress\n",
    "g = MinesweeperGame(5, 5, 3, seed=42)\n",
    "assert g.progress() == 0.0\n",
    "print(f\"  ✅ All game engine tests passed\")\n",
    "print(f\"  Board range: {MIN_ROWS}-{MAX_ROWS} rows × {MIN_COLS}-{MAX_COLS} cols\")\n",
    "print(f\"  Mine density: {MIN_MINE_DENSITY*100:.0f}%-{MAX_MINE_DENSITY*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617e14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Prompt System & Game Logic Helpers\n",
    "\n",
    "## Simplified Unified Prompt System\n",
    "Single prompt format for all board sizes (1×1 to 50×50) — no training/inference split.\n",
    "\n",
    "**Key Design Principles:**\n",
    "- **Prompt minimalism** — Model learns from examples (GRPO fine-tuning), not verbose instructions\n",
    "- **JSON-only output** — `max_completion_length=128` enforces direct action output\n",
    "- **Pre-computed hints** — Safe/mine cell lists provide the logical analysis\n",
    "\n",
    "## Prompt Structure (~300-400 tokens)\n",
    "```\n",
    "Board info → Grid → Legend → [Critical hint] → [Safe/Mine hints] → JSON format spec\n",
    "```\n",
    "\n",
    "## Board Representation\n",
    "| Size | Display |\n",
    "|------|---------|\n",
    "| 1–30 | Full grid with column headers |\n",
    "| 31–50 | Frontier zone only (revealed numbers + neighbors) |\n",
    "\n",
    "## Critical Edge Cases (only 3)\n",
    "1. **Zero mines** — \"All cells safe\"\n",
    "2. **All mines flagged** — \"Reveal any '?' to win\"\n",
    "3. **Last cell** — \"Cell (r,c) is safe/mine\"\n",
    "\n",
    "## Output Format\n",
    "```json\n",
    "{\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae25ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing simplified unified prompt system...\n",
      "============================================================\n",
      "\n",
      "Prompt lengths by board size:\n",
      "   1× 1 m= 0:  277 chars\n",
      "   3× 3 m= 1:  260 chars\n",
      "   5× 5 m= 3:  303 chars\n",
      "   6× 6 m= 5:  330 chars\n",
      "   8× 8 m=10:  398 chars\n",
      "  10×10 m=20:  482 chars\n",
      "  15×15 m=45:  776 chars\n",
      "  20×20 m=80: 1156 chars\n",
      "   1×10 m= 2:  271 chars\n",
      "\n",
      "Large board (35×35) frontier zone format:\n",
      "  35×35: 445 chars\n",
      "\n",
      "Edge case detection:\n",
      "  ✅ Zero mines edge case\n",
      "  ✅ All mines flagged edge case\n",
      "  ✅ parse_llm_action handles all cases\n",
      "  ✅ mode parameter backward compatible (ignored)\n",
      "\n",
      "============================================================\n",
      "EXAMPLE PROMPT (6×6 board after opening move):\n",
      "============================================================\n",
      "Minesweeper 6×6, 5 mines\n",
      "Revealed: 1/31 | Flags: 0/5\n",
      "\n",
      "   0 1 2 3 4 5\n",
      " 0 2 ? ? ? ? ?\n",
      " 1 ? ? ? ? ? ?\n",
      " 2 ? ? ? ? ? ?\n",
      " 3 ? ? ? ? ? ?\n",
      " 4 ? ? ? ? ? ?\n",
      " 5 ? ? ? ? ? ?\n",
      "\n",
      "Legend: ?=unrevealed F=flagged 0-8=safe (number=adjacent mines)\n",
      "\n",
      "No certain moves — guess needed\n",
      "\n",
      "Output JSON only: {\"type\":\"reveal\",\"row\":N,\"col\":N} or {\"type\":\"flag\",\"row\":N,\"col\":N}\n",
      "Row: 0-5, Col: 0-5\n",
      "\n",
      "[Total: 363 characters]\n",
      "\n",
      "============================================================\n",
      "SIMPLIFICATION SUMMARY:\n",
      "============================================================\n",
      "  ✅ Single board format (was 3-tier A/B/C)\n",
      "  ✅ No training/inference mode split\n",
      "  ✅ No ReAct scaffolding (STEP 1-4)\n",
      "  ✅ Only 3 critical edge cases (was 9)\n",
      "  ✅ ~363 chars for 6×6 board (target: 250-400 tokens ≈ 1000-1600 chars)\n",
      "  ✅ Code reduced from ~350 lines to ~100 lines\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# SIMPLIFIED PROMPTING SYSTEM\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Replaces the over-engineered 3-tier board format (A/B/C) and dual-mode\n",
    "# (training/inference) system with a single, unified prompt format.\n",
    "#\n",
    "# Key simplifications:\n",
    "#   1. Single board representation for all sizes (1-50)\n",
    "#   2. No training/inference mode split\n",
    "#   3. No ReAct scaffolding (STEP 1-4) — model outputs JSON directly\n",
    "#   4. Only 3 critical edge cases kept (zero-mines, all-flagged, last-cell)\n",
    "#   5. ~350 tokens target (down from 800-1200)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "\n",
    "def _compute_safe_and_mine_cells(game: MinesweeperGame):\n",
    "    \"\"\"Compute both safe and mine cells in a SINGLE pass (O(n²) not O(n⁴)).\n",
    "\n",
    "    Returns (safe_set, mine_set) where each is a set of (row, col) tuples.\n",
    "\n",
    "    A cell is logically SAFE if any adjacent revealed number has all its\n",
    "    mines accounted for by flags (remaining_mines == 0).\n",
    "    A cell is a logically CERTAIN mine if an adjacent number has\n",
    "    remaining_mines == remaining unrevealed neighbors.\n",
    "    \"\"\"\n",
    "    safe = set()\n",
    "    mines = set()\n",
    "\n",
    "    for r in range(game.rows):\n",
    "        for c in range(game.cols):\n",
    "            if (r, c) not in game._revealed:\n",
    "                continue\n",
    "            val = game._board[r][c]\n",
    "            if val <= 0:\n",
    "                continue\n",
    "\n",
    "            flags = 0\n",
    "            unrevealed = []\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    if dr == 0 and dc == 0:\n",
    "                        continue\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if 0 <= nr < game.rows and 0 <= nc < game.cols:\n",
    "                        if (nr, nc) in game._flagged:\n",
    "                            flags += 1\n",
    "                        elif (nr, nc) not in game._revealed:\n",
    "                            unrevealed.append((nr, nc))\n",
    "\n",
    "            remaining = val - flags\n",
    "\n",
    "            if remaining == 0 and unrevealed:\n",
    "                for cell in unrevealed:\n",
    "                    safe.add(cell)\n",
    "            elif remaining > 0 and remaining == len(unrevealed):\n",
    "                for cell in unrevealed:\n",
    "                    mines.add(cell)\n",
    "\n",
    "    return safe, mines\n",
    "\n",
    "\n",
    "def _compute_safe_cells(game: MinesweeperGame) -> list:\n",
    "    \"\"\"Return list of [row, col] for logically safe cells.\"\"\"\n",
    "    safe, _ = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in safe]\n",
    "\n",
    "\n",
    "def _compute_mine_cells(game: MinesweeperGame) -> list:\n",
    "    \"\"\"Return list of [row, col] for logically certain mine cells.\"\"\"\n",
    "    _, mines = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in mines]\n",
    "\n",
    "\n",
    "def _is_logically_safe(game: MinesweeperGame, row: int, col: int) -> bool:\n",
    "    safe, _ = _compute_safe_and_mine_cells(game)\n",
    "    return (row, col) in safe\n",
    "\n",
    "\n",
    "def _is_logically_mine(game: MinesweeperGame, row: int, col: int) -> bool:\n",
    "    _, mines = _compute_safe_and_mine_cells(game)\n",
    "    return (row, col) in mines\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# UNIFIED BOARD REPRESENTATION\n",
    "# Single format for all board sizes (1×1 to 50×50)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _format_board_unified(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Single board format for all sizes.\n",
    "    \n",
    "    - Boards ≤30×30: Full grid with simple spacing\n",
    "    - Boards 31-50: Frontier zone only (revealed numbers + unrevealed neighbors)\n",
    "    \"\"\"\n",
    "    board = game.get_visible_board()\n",
    "    \n",
    "    # For large boards (31+), show only the frontier zone\n",
    "    if game.rows > 30 or game.cols > 30:\n",
    "        return _format_frontier_zone(game, board)\n",
    "    \n",
    "    # For small/medium boards, show full grid\n",
    "    lines = []\n",
    "    \n",
    "    # Column header\n",
    "    if game.cols <= 10:\n",
    "        col_header = \"   \" + \" \".join(f\"{c}\" for c in range(game.cols))\n",
    "    else:\n",
    "        col_header = \"   \" + \"\".join(f\"{c:2d}\" for c in range(game.cols))\n",
    "    lines.append(col_header)\n",
    "    \n",
    "    # Grid rows\n",
    "    for r, row in enumerate(board):\n",
    "        if game.cols <= 10:\n",
    "            lines.append(f\"{r:2d} \" + \" \".join(row))\n",
    "        else:\n",
    "            lines.append(f\"{r:2d} \" + \"\".join(f\"{v:>2s}\" for v in row))\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def _format_frontier_zone(game: MinesweeperGame, board: list) -> str:\n",
    "    \"\"\"For large boards (31+), show only frontier cells and their context.\"\"\"\n",
    "    # Find frontier cells (unrevealed adjacent to revealed numbers)\n",
    "    frontier = set()\n",
    "    number_cells = {}\n",
    "    \n",
    "    for r in range(game.rows):\n",
    "        for c in range(game.cols):\n",
    "            if (r, c) in game._revealed and game._board[r][c] > 0:\n",
    "                number_cells[(r, c)] = game._board[r][c]\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < game.rows and 0 <= nc < game.cols\n",
    "                                and (nr, nc) not in game._revealed):\n",
    "                            frontier.add((nr, nc))\n",
    "    \n",
    "    if not frontier:\n",
    "        # No frontier yet — show center region\n",
    "        cr, cc = game.rows // 2, game.cols // 2\n",
    "        r_min, r_max = max(0, cr - 5), min(game.rows, cr + 6)\n",
    "        c_min, c_max = max(0, cc - 5), min(game.cols, cc + 6)\n",
    "    else:\n",
    "        # Find bounding box of frontier with padding\n",
    "        rs = [r for r, c in frontier]\n",
    "        cs = [c for r, c in frontier]\n",
    "        r_min = max(0, min(rs) - 2)\n",
    "        r_max = min(game.rows, max(rs) + 3)\n",
    "        c_min = max(0, min(cs) - 2)\n",
    "        c_max = min(game.cols, max(cs) + 3)\n",
    "        \n",
    "        # Limit to ~20 rows/cols max for readability\n",
    "        if r_max - r_min > 20:\n",
    "            mid_r = (r_min + r_max) // 2\n",
    "            r_min, r_max = mid_r - 10, mid_r + 10\n",
    "        if c_max - c_min > 20:\n",
    "            mid_c = (c_min + c_max) // 2\n",
    "            c_min, c_max = mid_c - 10, mid_c + 10\n",
    "    \n",
    "    lines = [f\"[Showing rows {r_min}-{r_max-1}, cols {c_min}-{c_max-1}]\"]\n",
    "    col_header = \"   \" + \"\".join(f\"{c:2d}\" for c in range(c_min, c_max))\n",
    "    lines.append(col_header)\n",
    "    \n",
    "    for r in range(r_min, r_max):\n",
    "        cells = \"\".join(f\"{board[r][c]:>2s}\" for c in range(c_min, c_max))\n",
    "        lines.append(f\"{r:2d} {cells}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# SIMPLIFIED EDGE CASE GUIDANCE (only 3 critical cases)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _get_critical_hints(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Return hints only for the 3 critical edge cases.\"\"\"\n",
    "    remaining = game.rows * game.cols - len(game._revealed) - len(game._flagged)\n",
    "    remaining_mines = game.num_mines - len(game._flagged)\n",
    "    \n",
    "    # Case 1: Zero mines board\n",
    "    if game.num_mines == 0:\n",
    "        return \"All cells safe (0 mines) — reveal any '?'\"\n",
    "    \n",
    "    # Case 2: All mines flagged\n",
    "    if remaining_mines == 0 and remaining > 0:\n",
    "        return f\"All {game.num_mines} mines flagged — reveal any '?' to win\"\n",
    "    \n",
    "    # Case 3: Last cell\n",
    "    if remaining == 1:\n",
    "        for r in range(game.rows):\n",
    "            for c in range(game.cols):\n",
    "                if (r, c) not in game._revealed and (r, c) not in game._flagged:\n",
    "                    if remaining_mines == 0:\n",
    "                        return f\"Last cell ({r},{c}) is safe — reveal to win\"\n",
    "                    else:\n",
    "                        return f\"Last cell ({r},{c}) is a mine — flag it\"\n",
    "    \n",
    "    # Case 4: All remaining cells are mines\n",
    "    if remaining > 0 and remaining == remaining_mines:\n",
    "        return f\"All {remaining} remaining cells are mines — flag any\"\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# UNIFIED PROMPT FORMAT\n",
    "# Single format for training and inference (~350 tokens)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a Minesweeper AI. Output ONLY valid JSON.\"\n",
    "\n",
    "\n",
    "def format_state_for_llm(game: MinesweeperGame, mode=None) -> str:\n",
    "    \"\"\"Generate a simplified, unified prompt for any game state.\n",
    "    \n",
    "    Args:\n",
    "        game: The MinesweeperGame instance\n",
    "        mode: Ignored (kept for backward compatibility). Same prompt always.\n",
    "    \n",
    "    Returns:\n",
    "        A prompt string (~250-400 tokens) with:\n",
    "        - Board dimensions and mine count\n",
    "        - Grid representation\n",
    "        - Pre-computed safe/mine hints\n",
    "        - Critical edge case hint (if applicable)\n",
    "        - JSON output format specification\n",
    "    \"\"\"\n",
    "    if game.state() == \"success\":\n",
    "        return \"Game won. No action needed.\"\n",
    "    \n",
    "    rows, cols = game.rows, game.cols\n",
    "    mines = game.num_mines\n",
    "    revealed = len(game._revealed)\n",
    "    flagged = len(game._flagged)\n",
    "    safe_total = rows * cols - mines\n",
    "    \n",
    "    # ── Board representation ──\n",
    "    board_repr = _format_board_unified(game)\n",
    "    \n",
    "    # ── Pre-computed logical hints ──\n",
    "    safe_cells = _compute_safe_cells(game)[:8]  # Limit to 8 for brevity\n",
    "    mine_cells = _compute_mine_cells(game)[:8]\n",
    "    \n",
    "    hint_lines = []\n",
    "    if safe_cells:\n",
    "        hint_lines.append(f\"Safe (100%): {safe_cells}\")\n",
    "    if mine_cells:\n",
    "        hint_lines.append(f\"Mines (100%): {mine_cells}\")\n",
    "    if not safe_cells and not mine_cells and revealed > 0:\n",
    "        hint_lines.append(\"No certain moves — guess needed\")\n",
    "    \n",
    "    hints = \"\\n\".join(hint_lines) if hint_lines else \"\"\n",
    "    \n",
    "    # ── Critical edge case hint ──\n",
    "    critical = _get_critical_hints(game)\n",
    "    \n",
    "    # ── Build prompt ──\n",
    "    prompt = f\"\"\"Minesweeper {rows}×{cols}, {mines} mines\n",
    "Revealed: {revealed}/{safe_total} | Flags: {flagged}/{mines}\n",
    "\n",
    "{board_repr}\n",
    "\n",
    "Legend: ?=unrevealed F=flagged 0-8=safe (number=adjacent mines)\n",
    "\"\"\"\n",
    "    \n",
    "    if critical:\n",
    "        prompt += f\"\\n{critical}\\n\"\n",
    "    \n",
    "    if hints:\n",
    "        prompt += f\"\\n{hints}\\n\"\n",
    "    \n",
    "    prompt += f\"\"\"\n",
    "Output JSON only: {{\"type\":\"reveal\",\"row\":N,\"col\":N}} or {{\"type\":\"flag\",\"row\":N,\"col\":N}}\n",
    "Row: 0-{rows-1}, Col: 0-{cols-1}\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_llm_action(response: str) -> dict:\n",
    "    \"\"\"Extract JSON action from LLM response.\n",
    "\n",
    "    Finds all JSON-like objects and returns the LAST one matching the\n",
    "    expected schema (type + row + col). LLMs typically place their\n",
    "    final answer at the end.\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for match in re.finditer(r'\\{[^{}]*\\}', response):\n",
    "        try:\n",
    "            action = json.loads(match.group())\n",
    "            if (\"type\" in action and \"row\" in action and \"col\" in action\n",
    "                    and action[\"type\"] in (\"reveal\", \"flag\")):\n",
    "                action[\"row\"] = int(action[\"row\"])\n",
    "                action[\"col\"] = int(action[\"col\"])\n",
    "                best = action\n",
    "        except (json.JSONDecodeError, ValueError, TypeError):\n",
    "            continue\n",
    "    return best\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# TESTS\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"Testing simplified unified prompt system...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test prompt length on various board sizes\n",
    "print(\"\\nPrompt lengths by board size:\")\n",
    "for rows, cols, mines in [(1,1,0), (3,3,1), (5,5,3), (6,6,5), (8,8,10),\n",
    "                           (10,10,20), (15,15,45), (20,20,80), (1,10,2)]:\n",
    "    if mines >= rows * cols:\n",
    "        continue\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=42)\n",
    "    if game.state() == \"ongoing\":\n",
    "        prompt = format_state_for_llm(game)\n",
    "        print(f\"  {rows:2d}×{cols:2d} m={mines:2d}: {len(prompt):4d} chars\")\n",
    "\n",
    "# Test large board (frontier zone)\n",
    "print(\"\\nLarge board (35×35) frontier zone format:\")\n",
    "game_large = MinesweeperGame(35, 35, 100, seed=42)\n",
    "game_large.do_action({\"type\": \"reveal\", \"row\": 17, \"col\": 17})\n",
    "prompt_large = format_state_for_llm(game_large)\n",
    "print(f\"  35×35: {len(prompt_large)} chars\")\n",
    "\n",
    "# Test edge cases\n",
    "print(\"\\nEdge case detection:\")\n",
    "\n",
    "# Zero mines\n",
    "game_0 = MinesweeperGame(5, 5, 0, seed=42)\n",
    "p = format_state_for_llm(game_0)\n",
    "assert \"0 mines\" in p.lower() or \"safe\" in p.lower()\n",
    "print(\"  ✅ Zero mines edge case\")\n",
    "\n",
    "# All mines flagged scenario\n",
    "game_flagged = MinesweeperGame(3, 3, 1, seed=42)\n",
    "game_flagged.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "# Find and flag the mine\n",
    "for r in range(3):\n",
    "    for c in range(3):\n",
    "        if game_flagged._board[r][c] == -1:\n",
    "            game_flagged.do_action({\"type\": \"flag\", \"row\": r, \"col\": c})\n",
    "            break\n",
    "p = format_state_for_llm(game_flagged)\n",
    "if \"flagged\" in p.lower():\n",
    "    print(\"  ✅ All mines flagged edge case\")\n",
    "else:\n",
    "    print(\"  ⚠️ All mines flagged case (may not trigger if game state changed)\")\n",
    "\n",
    "# Test parse_llm_action\n",
    "assert parse_llm_action('{\"type\":\"reveal\",\"row\":2,\"col\":3}') == {\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "assert parse_llm_action('blah {\"type\":\"flag\",\"row\":\"1\",\"col\":\"2\"} done') == {\"type\": \"flag\", \"row\": 1, \"col\": 2}\n",
    "assert parse_llm_action('no json here') is None\n",
    "assert parse_llm_action('{\"type\":\"invalid\",\"row\":0,\"col\":0}') is None\n",
    "print(\"  ✅ parse_llm_action handles all cases\")\n",
    "\n",
    "# Test backward compatibility (mode parameter ignored)\n",
    "game = MinesweeperGame(6, 6, 5, seed=42)\n",
    "p1 = format_state_for_llm(game)\n",
    "p2 = format_state_for_llm(game, mode=\"training\")\n",
    "p3 = format_state_for_llm(game, mode=\"inference\")\n",
    "assert p1 == p2 == p3\n",
    "print(\"  ✅ mode parameter backward compatible (ignored)\")\n",
    "\n",
    "# Show example prompt\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"EXAMPLE PROMPT (6×6 board after opening move):\")\n",
    "print(\"=\" * 60)\n",
    "game = MinesweeperGame(6, 6, 5, seed=42)\n",
    "game.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "prompt = format_state_for_llm(game)\n",
    "print(prompt)\n",
    "print(f\"\\n[Total: {len(prompt)} characters]\")\n",
    "\n",
    "# Verify we hit the target token range\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"SIMPLIFICATION SUMMARY:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  ✅ Single board format (was 3-tier A/B/C)\")\n",
    "print(f\"  ✅ No training/inference mode split\")\n",
    "print(f\"  ✅ No ReAct scaffolding (STEP 1-4)\")\n",
    "print(f\"  ✅ Only 3 critical edge cases (was 9)\")\n",
    "print(f\"  ✅ ~{len(prompt)} chars for 6×6 board (target: 250-400 tokens ≈ 1000-1600 chars)\")\n",
    "print(f\"  ✅ Code reduced from ~350 lines to ~100 lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302a238",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Model Before Training\n",
    "\n",
    "See how the base model performs without finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=42)\n",
    "prompt = format_state_for_llm(game)\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": prompt}],\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True,\n",
    ")\n",
    "\n",
    "print(\"=== Base Model Response ===\")\n",
    "output = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.7,\n",
    "    top_p = 0.9,\n",
    "    max_new_tokens = 128,\n",
    "    do_sample = True,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b3c5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# GRPO Reward Functions\n",
    "\n",
    "Define reward functions to guide the model's learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b64ca52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All reward functions defined with correct TRL signature:\n",
      "   1. valid_json_reward — format + length penalty (GRPO-LEAD)\n",
      "   2. gameplay_scores   — 12 criteria + difficulty reweight (XRPO)\n",
      "   3. strategic_reward  — deduction + center-opening + difficulty (XRPO)\n",
      "\n",
      "Length penalty tests (GRPO-LEAD):\n",
      "  Pure JSON (30c):  +2.00\n",
      "  Brief (100c):     +0.27\n",
      "  Moderate (300c):  -2.00\n",
      "  Verbose (600c):   -2.00\n",
      "  Very long (1000c):-2.00\n",
      "\n",
      "Difficulty multiplier tests (XRPO):\n",
      "  3x3 m=0 (0.0%): ×1.00\n",
      "  5x5 m=3 (12.0%): ×1.13\n",
      "  10x10 m=10 (10.0%): ×1.14\n",
      "  10x10 m=20 (20.0%): ×1.41\n",
      "  30x30 m=180 (20.0%): ×1.45\n",
      "  50x50 m=500 (20.0%): ×1.46\n",
      "\n",
      "Smoke test (6x6 m=5):\n",
      "  Pure JSON:    format=7.00, gameplay=12.2, strategic=-2.4\n",
      "  Verbose JSON: format=-2.79 (length penalty working)\n",
      "  0-mine board: gameplay=117.5, strategic=2.0\n",
      "  1x1 m=0:     gameplay=115.1\n",
      "  Hard 20x20:   gameplay=14.4, strategic=-2.9 (XRPO amplified)\n",
      "\n",
      "  ✅ Edge cases: 0-mine boards, 1x1 boards, hard boards handled\n",
      "  ✅ All reward functions work with kwargs (seed, move_history, board_rows/cols/mines)\n",
      "  ✅ Length penalty (GRPO-LEAD): pure JSON ≤60c → +5.0, verbose >100c → -2.0\n",
      "  ✅ Explicit wrong penalty (GRPO-LEAD): mine reveal -26, wrong flag -11\n",
      "  ✅ Difficulty reweighting (XRPO): harder boards → amplified signal\n",
      "  ✅ Win bonus scales with board size: 6×6→+104, 20×20→+140, 50×50→+250\n",
      "  ✅ HACKATHON: JSON-only output, 128-token constraint, α=0.15 length penalty\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Helper: Reconstruct game from dataset columns\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _reconstruct_game(idx, kwargs):\n",
    "    \"\"\"Reconstruct a MinesweeperGame from dataset columns passed via GRPO kwargs.\n",
    "\n",
    "    The dataset stores: seed, move_history, board_rows, board_cols, board_mines\n",
    "    GRPOTrainer passes all non-'prompt' columns as lists in **kwargs.\n",
    "\n",
    "    Returns (game, move_history_list) or (None, None) if data is missing.\n",
    "    Handles 0-mine boards correctly.\n",
    "    \"\"\"\n",
    "    seeds = kwargs.get(\"seed\", [])\n",
    "    move_histories = kwargs.get(\"move_history\", [])\n",
    "    rows_list = kwargs.get(\"board_rows\", [])\n",
    "    cols_list = kwargs.get(\"board_cols\", [])\n",
    "    mines_list = kwargs.get(\"board_mines\", [])\n",
    "\n",
    "    if idx >= len(seeds) or idx >= len(move_histories):\n",
    "        return None, None\n",
    "\n",
    "    seed = seeds[idx]\n",
    "    rows = rows_list[idx] if idx < len(rows_list) else 6\n",
    "    cols = cols_list[idx] if idx < len(cols_list) else 6\n",
    "    num_mines = mines_list[idx] if idx < len(mines_list) else 5\n",
    "\n",
    "    mh_raw = move_histories[idx]\n",
    "    if isinstance(mh_raw, str):\n",
    "        move_history = json.loads(mh_raw)\n",
    "    else:\n",
    "        move_history = list(mh_raw)\n",
    "\n",
    "    game = MinesweeperGame(rows=int(rows), cols=int(cols),\n",
    "                           num_mines=int(num_mines), seed=int(seed))\n",
    "    for prev in move_history:\n",
    "        result = game.do_action(prev)\n",
    "        if result == \"mine\":\n",
    "            return None, None  # History hit a mine — bad data\n",
    "\n",
    "    return game, move_history\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Length penalty helper (GRPO-LEAD: α=0.05)\n",
    "#\n",
    "# Shorter correct responses → bonus, longer → penalty.\n",
    "# Applied to Reward 1 (valid_json_reward) since that's the format reward.\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "LENGTH_PENALTY_ALPHA = 0.15  # Stronger penalty (was 0.05) for JSON-only constraint\n",
    "\n",
    "\n",
    "def _length_penalty(response: str) -> float:\n",
    "    \"\"\"Compute length-based reward modifier (GRPO-LEAD paper).\n",
    "\n",
    "    HACKATHON VERSION: JSON-only output, 128-token constraint.\n",
    "    Heavily rewards pure JSON (≤60 chars), severely penalizes extra text.\n",
    "\n",
    "    Returns a value in [-2.0, +2.0]:\n",
    "      Pure JSON (~30 chars)    → +2.0\n",
    "      Near-pure (<60c)         → +1.5\n",
    "      Some extra text (<100c)  → +0.5\n",
    "      Moderate (100-200 chars) → -0.5\n",
    "      Verbose (>200 chars)     → -1.5 to -2.0\n",
    "    \"\"\"\n",
    "    n = len(response)\n",
    "    if n <= 40:       # Pure JSON action\n",
    "        return 2.0\n",
    "    elif n <= 60:     # Near-pure JSON\n",
    "        return 1.5\n",
    "    elif n <= 100:    # Minor extra text\n",
    "        return 0.5 * math.exp(-LENGTH_PENALTY_ALPHA * (n - 60) / 10)\n",
    "    elif n <= 200:    # Significant extra text — penalty\n",
    "        return -0.5 - 0.5 * ((n - 100) / 100)\n",
    "    else:             # Way too verbose for 128-token JSON-only\n",
    "        return -1.5 - min(0.5, (n - 200) / 200)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Difficulty reweighting helper (XRPO paper)\n",
    "#\n",
    "# Harder boards get amplified reward signal so the model doesn't\n",
    "# ignore difficult scenarios. Uses board difficulty proxy:\n",
    "#   difficulty = density × (1 + move_depth / total_cells)\n",
    "#\n",
    "# Multiplier: 0.4 + (1.1 / (1 + exp(10 * (success_rate - 0.75))))\n",
    "# Since we don't have per-board success rates in a single pass,\n",
    "# we use density + board size as difficulty proxy.\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _difficulty_multiplier(game) -> float:\n",
    "    \"\"\"Compute difficulty-based reward multiplier (XRPO paper).\n",
    "\n",
    "    Returns a value in [0.7, 1.5]:\n",
    "      Easy boards (low density, small) → ~0.7-0.9  (slight damping)\n",
    "      Medium boards                    → ~1.0\n",
    "      Hard boards (high density, large) → ~1.2-1.5 (amplified signal)\n",
    "    \"\"\"\n",
    "    board_size = game.rows * game.cols\n",
    "\n",
    "    # Safety check: degenerate boards get neutral multiplier\n",
    "    if board_size == 0 or game.num_mines == 0:\n",
    "        return 1.0\n",
    "\n",
    "    density = mine_density(game.rows, game.cols, game.num_mines)\n",
    "\n",
    "    # Difficulty proxy: combination of density and board complexity\n",
    "    # density ∈ [0, 0.2], size ∈ [1, 2500]\n",
    "    # Normalize size: log scale so 1→0, 100→0.5, 2500→1.0\n",
    "    size_factor = min(1.0, math.log(max(1, board_size)) / math.log(2500))\n",
    "\n",
    "    # Combined difficulty ∈ [0, 1]\n",
    "    difficulty = 0.6 * (density / 0.20) + 0.4 * size_factor\n",
    "\n",
    "    # Sigmoid-based multiplier: harder → higher\n",
    "    # At difficulty=0 → ~0.7, at difficulty=0.5 → ~1.0, at difficulty=1.0 → ~1.5\n",
    "    multiplier = 0.7 + 0.8 / (1.0 + math.exp(-6.0 * (difficulty - 0.5)))\n",
    "\n",
    "    return multiplier\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 1: Valid JSON format + conciseness + length penalty (GRPO-LEAD)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def valid_json_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"GRPO-LEAD: Length-regularized reward - HACKATHON VERSION (JSON-only, 128 tokens).\n",
    "\n",
    "    Heavily rewards pure JSON (≤60 chars), penalizes ANY extra text.\n",
    "    Constraint: max_new_tokens=128 for competition.\n",
    "\n",
    "    Two-pass approach:\n",
    "      Pass 1: Score format correctness & collect correct response lengths\n",
    "      Pass 2: Apply z-score normalized length penalty to correct responses\n",
    "    \"\"\"\n",
    "    # ── Pass 1: Evaluate format correctness & collect lengths ──\n",
    "    results = []  # List of (action, response, base_score, is_correct)\n",
    "    correct_lengths = []\n",
    "\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"].strip() if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            results.append((None, response, -3.0, False))\n",
    "            continue\n",
    "\n",
    "        # Check if it's PURE JSON (no extra text)\n",
    "        try:\n",
    "            parsed = json.loads(response)\n",
    "            if \"type\" in parsed and \"row\" in parsed and \"col\" in parsed:\n",
    "                # Pure JSON - MAXIMUM REWARD\n",
    "                if len(response) <= 60:\n",
    "                    correct_lengths.append(len(response))\n",
    "                    results.append((action, response, 5.0, True))  # Ultra-short pure JSON\n",
    "                elif len(response) <= 100:\n",
    "                    correct_lengths.append(len(response))\n",
    "                    results.append((action, response, 3.0, True))  # Standard pure JSON\n",
    "                else:\n",
    "                    correct_lengths.append(len(response))\n",
    "                    results.append((action, response, 2.0, True))  # Pure but verbose\n",
    "                continue\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        # JSON found but with extra text — PENALTY\n",
    "        json_match = re.search(r'\\{[^{}]*\\}', response)\n",
    "        extra_chars = len(response) - len(json_match.group()) if json_match else len(response)\n",
    "\n",
    "        if extra_chars <= 10:       # Minor formatting chars\n",
    "            base = 1.5\n",
    "        elif extra_chars <= 30:     # Some extra text\n",
    "            base = 0.5\n",
    "        elif extra_chars <= 100:    # Significant reasoning\n",
    "            base = -0.5\n",
    "        else:                       # Way too verbose\n",
    "            base = -2.0             # HEAVY PENALTY\n",
    "\n",
    "        correct_lengths.append(len(response))\n",
    "        results.append((action, response, base, True))\n",
    "\n",
    "    # ── Pass 2: Apply group-normalized length penalty (GRPO-LEAD) ──\n",
    "    scores = []\n",
    "\n",
    "    if len(correct_lengths) > 1:\n",
    "        mean_len = np.mean(correct_lengths)\n",
    "        std_len = np.std(correct_lengths) + 1e-8  # Avoid div by zero\n",
    "\n",
    "        for action, response, base_score, is_correct in results:\n",
    "            if not is_correct:\n",
    "                scores.append(base_score)  # Invalid JSON — no length adjustment\n",
    "            else:\n",
    "                z_score = (len(response) - mean_len) / std_len\n",
    "                length_multiplier = math.exp(-LENGTH_PENALTY_ALPHA * z_score)\n",
    "                # Clamp multiplier to [0.5, 1.5] for stability\n",
    "                length_multiplier = max(0.5, min(1.5, length_multiplier))\n",
    "                scores.append(base_score * length_multiplier)\n",
    "    else:\n",
    "        # Not enough correct responses for group normalization\n",
    "        # Fall back to absolute length penalty\n",
    "        for action, response, base_score, is_correct in results:\n",
    "            if not is_correct:\n",
    "                scores.append(base_score)\n",
    "            else:\n",
    "                lp = _length_penalty(response)\n",
    "                scores.append(base_score + lp)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 2: Gameplay — complete 12-criterion scoring\n",
    "# Handles: 0-mine boards, 1x1 boards, large boards, all edge cases\n",
    "# Now with difficulty reweighting (XRPO)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def gameplay_scores(prompts, completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Complete gameplay reward implementing all 12 scoring criteria.\n",
    "    Uses variable board sizes from dataset columns.\n",
    "    No move limit — only success or failure.\n",
    "    XRPO: Difficulty reweighting — harder boards get amplified signal.\n",
    "\n",
    "    1.  Flag cell that IS a mine        → +15 / +20 (logical)\n",
    "    2.  Flag cell that is NOT a mine    → -10\n",
    "    3.  Reveal cell that IS a mine      → -25\n",
    "    4.  Reveal cell that is safe        → +10 (guess) / +15 (logical)\n",
    "    5.  Flag already flagged cell       → -12\n",
    "    6.  Reveal already revealed cell    → -12\n",
    "    7.  Out of bounds                   → -15\n",
    "    8.  Total flags > total mines       → -10 (additional)\n",
    "    9.  Invalid JSON                    → -10\n",
    "    10. Win the game                    → +100 × size_scale\n",
    "    11. Reveal a flagged cell           → -8\n",
    "    12. Flag a revealed cell            → -8\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"] if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        # ── Criterion 9: Invalid JSON ──\n",
    "        if action is None:\n",
    "            scores.append(-10.0)\n",
    "            continue\n",
    "\n",
    "        # ── Reconstruct game state from dataset columns ──\n",
    "        game, move_history = _reconstruct_game(idx, kwargs)\n",
    "        if game is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # ── Difficulty multiplier (XRPO) ──\n",
    "        diff_mult = _difficulty_multiplier(game)\n",
    "\n",
    "        # ── Edge case: game already won (0-mine board or all safe revealed) ──\n",
    "        if game.state() != \"ongoing\":\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        row, col = action[\"row\"], action[\"col\"]\n",
    "        action_type = action[\"type\"]\n",
    "\n",
    "        # ── Criterion 7: Out of bounds ──\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(-15.0 * diff_mult)\n",
    "            continue\n",
    "\n",
    "        # ── Edge case: 0-mine board — any reveal is safe, any flag is wrong ──\n",
    "        if game.num_mines == 0:\n",
    "            if action_type == \"reveal\":\n",
    "                if (row, col) in game._revealed:\n",
    "                    scores.append(-12.0)\n",
    "                else:\n",
    "                    game_copy = MinesweeperGame(\n",
    "                        rows=game.rows, cols=game.cols,\n",
    "                        num_mines=0, seed=kwargs.get(\"seed\", [0])[idx]\n",
    "                    )\n",
    "                    for prev in move_history:\n",
    "                        game_copy.do_action(prev)\n",
    "                    result = game_copy.do_action(action)\n",
    "                    # Scale win bonus with board size\n",
    "                    board_size = game.rows * game.cols\n",
    "                    size_scale = 1.0 + min(1.0, board_size / 1000)\n",
    "                    win_bonus = (100.0 * size_scale) if result == \"win\" else 0.0\n",
    "                    scores.append(15.0 + win_bonus)\n",
    "            else:\n",
    "                scores.append(-10.0)\n",
    "            continue\n",
    "\n",
    "        # ── Compute logical deductions ONCE ──\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        score = 0.0\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            # ── Criterion 6: Reveal already revealed cell ──\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-12.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 11: Reveal a flagged cell ──\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-8.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 3: Reveal a mine ──\n",
    "            if game._board[row][col] == -1:\n",
    "                # GRPO-LEAD: explicit wrong penalty (-1.0 additional)\n",
    "                scores.append((-25.0 - 1.0) * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 4: Reveal safe cell ──\n",
    "            if (row, col) in safe_set:\n",
    "                score += 15.0   # Logically deduced safe cell\n",
    "            else:\n",
    "                score += 10.0   # Guessed safe cell\n",
    "\n",
    "            # Small bonus for revealing near numbers (information-rich)\n",
    "            board = game.get_visible_board()\n",
    "            has_adjacent_number = False\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    nr, nc = row + dr, col + dc\n",
    "                    if 0 <= nr < game.rows and 0 <= nc < game.cols:\n",
    "                        if board[nr][nc] in ('1','2','3','4','5','6','7','8'):\n",
    "                            has_adjacent_number = True\n",
    "                            break\n",
    "                if has_adjacent_number:\n",
    "                    break\n",
    "            if has_adjacent_number:\n",
    "                score += 1.0\n",
    "\n",
    "            # ── Criterion 10: Check for win ──\n",
    "            game_copy = MinesweeperGame(\n",
    "                rows=game.rows, cols=game.cols,\n",
    "                num_mines=game.num_mines, seed=kwargs.get(\"seed\", [0])[idx]\n",
    "            )\n",
    "            for prev in move_history:\n",
    "                game_copy.do_action(prev)\n",
    "            result = game_copy.do_action(action)\n",
    "            if result == \"win\":\n",
    "                # Scale win bonus with board size — 50×50 boards worth 2× a 6×6\n",
    "                board_size = game.rows * game.cols\n",
    "                size_scale = 1.0 + min(1.0, board_size / 1000)\n",
    "                score += 100.0 * size_scale\n",
    "\n",
    "        elif action_type == \"flag\":\n",
    "            # ── Criterion 5: Flag already flagged cell ──\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-12.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 12: Flag a revealed cell ──\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-8.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 1: Flag a mine (correct) ──\n",
    "            if game._board[row][col] == -1:\n",
    "                if (row, col) in mine_set:\n",
    "                    score += 20.0   # Logically deduced mine\n",
    "                else:\n",
    "                    score += 15.0   # Correct but guessed\n",
    "\n",
    "            # ── Criterion 2: Flag a non-mine (wrong) ──\n",
    "            else:\n",
    "                # GRPO-LEAD: explicit wrong penalty\n",
    "                score -= 10.0 + 1.0\n",
    "\n",
    "            # ── Criterion 8: Total flags > total mines ──\n",
    "            new_flag_count = len(game._flagged) + 1\n",
    "            if new_flag_count > game.num_mines:\n",
    "                score -= 10.0\n",
    "\n",
    "        # Apply difficulty multiplier (XRPO)\n",
    "        scores.append(score * diff_mult)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 3: Strategic play — rewards logical deduction over guessing\n",
    "# Now with difficulty reweighting (XRPO)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def strategic_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"Reward strategic play patterns:\n",
    "    - Choosing logically deducible moves when available\n",
    "    - Opening in center (LAMER paper: center-opening for dense boards)\n",
    "    - Penalize ignoring available deductions\n",
    "    - Handles 0-mine boards (any reveal is correct)\n",
    "    - Difficulty reweighting (XRPO)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"] if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        game, move_history = _reconstruct_game(idx, kwargs)\n",
    "        if game is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # Game already over — no strategic value\n",
    "        if game.state() != \"ongoing\":\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        row, col = action[\"row\"], action[\"col\"]\n",
    "        action_type = action[\"type\"]\n",
    "        score = 0.0\n",
    "\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # ── Difficulty multiplier (XRPO) ──\n",
    "        diff_mult = _difficulty_multiplier(game)\n",
    "\n",
    "        # ── 0-mine board: any reveal is trivially correct ──\n",
    "        if game.num_mines == 0:\n",
    "            if action_type == \"reveal\":\n",
    "                scores.append(2.0)\n",
    "            else:\n",
    "                scores.append(-2.0)\n",
    "            continue\n",
    "\n",
    "        # ── Compute logical deductions ONCE ──\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        # ── Fresh game opening strategy (LAMER paper: center-opening) ──\n",
    "        if len(game._revealed) == 0 and action_type == \"reveal\":\n",
    "            density_pct = mine_density(game.rows, game.cols, game.num_mines) * 100\n",
    "            center_r, center_c = game.rows // 2, game.cols // 2\n",
    "            dist_to_center = abs(row - center_r) + abs(col - center_c)\n",
    "            max_dist = center_r + center_c\n",
    "\n",
    "            if density_pct > 10:\n",
    "                if dist_to_center == 0:\n",
    "                    score += 5.0\n",
    "                elif dist_to_center <= max(1, max_dist // 4):\n",
    "                    score += 3.0\n",
    "                elif dist_to_center <= max_dist // 2:\n",
    "                    score += 1.0\n",
    "                else:\n",
    "                    score -= 2.0\n",
    "            else:\n",
    "                if dist_to_center <= max(1, max_dist // 3):\n",
    "                    score += 2.0\n",
    "\n",
    "        # ── Reward choosing logically deducible moves ──\n",
    "        if action_type == \"reveal\" and (row, col) in safe_set:\n",
    "            score += 5.0   # Chose a provably safe cell\n",
    "        elif action_type == \"flag\" and (row, col) in mine_set:\n",
    "            score += 5.0   # Chose a provably mine cell\n",
    "        elif safe_set or mine_set:\n",
    "            # Deducible moves existed but agent didn't pick one\n",
    "            score -= 3.0\n",
    "\n",
    "        # ── Penalize flagging on a fresh board (no info to deduce) ──\n",
    "        if len(game._revealed) == 0 and action_type == \"flag\":\n",
    "            score -= 2.0\n",
    "\n",
    "        # Apply difficulty multiplier (XRPO)\n",
    "        scores.append(score * diff_mult)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ── Verify reward function signatures ──\n",
    "print(\"✅ All reward functions defined with correct TRL signature:\")\n",
    "print(\"   1. valid_json_reward — format + length penalty (GRPO-LEAD)\")\n",
    "print(\"   2. gameplay_scores   — 12 criteria + difficulty reweight (XRPO)\")\n",
    "print(\"   3. strategic_reward  — deduction + center-opening + difficulty (XRPO)\")\n",
    "print()\n",
    "\n",
    "# ── Test length penalty ──\n",
    "print(\"Length penalty tests (GRPO-LEAD):\")\n",
    "print(f\"  Pure JSON (30c):  {_length_penalty('x' * 30):+.2f}\")\n",
    "print(f\"  Brief (100c):     {_length_penalty('x' * 100):+.2f}\")\n",
    "print(f\"  Moderate (300c):  {_length_penalty('x' * 300):+.2f}\")\n",
    "print(f\"  Verbose (600c):   {_length_penalty('x' * 600):+.2f}\")\n",
    "print(f\"  Very long (1000c):{_length_penalty('x' * 1000):+.2f}\")\n",
    "print()\n",
    "\n",
    "# ── Test difficulty multiplier ──\n",
    "print(\"Difficulty multiplier tests (XRPO):\")\n",
    "for rows, cols, mines in [(3,3,0), (5,5,3), (10,10,10), (10,10,20), (30,30,180), (50,50,500)]:\n",
    "    g = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=42)\n",
    "    dm = _difficulty_multiplier(g)\n",
    "    d = mine_density(rows, cols, mines) * 100\n",
    "    print(f\"  {rows}x{cols} m={mines} ({d:.1f}%): ×{dm:.2f}\")\n",
    "print()\n",
    "\n",
    "# ── Smoke test: simulate what GRPOTrainer passes ──\n",
    "test_completions_pure = [[{\"role\": \"assistant\", \"content\": '{\"type\":\"reveal\",\"row\":0,\"col\":0}'}]]\n",
    "test_completions_verbose = [[{\"role\": \"assistant\", \"content\": 'Let me analyze this board step by step. The cell at row 0, col 0 looks promising because it has several revealed neighbors. ' + '{\"type\":\"reveal\",\"row\":0,\"col\":0}'}]]\n",
    "test_prompts = [\"test\"]\n",
    "\n",
    "# Normal board\n",
    "test_kwargs = {\n",
    "    \"seed\": [42],\n",
    "    \"move_history\": [\"[]\"],\n",
    "    \"board_rows\": [6],\n",
    "    \"board_cols\": [6],\n",
    "    \"board_mines\": [5],\n",
    "}\n",
    "\n",
    "print(\"Smoke test (6x6 m=5):\")\n",
    "r1p = valid_json_reward(test_prompts, test_completions_pure, **test_kwargs)\n",
    "r1v = valid_json_reward(test_prompts, test_completions_verbose, **test_kwargs)\n",
    "r2 = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs)\n",
    "r3 = strategic_reward(test_prompts, test_completions_pure, **test_kwargs)\n",
    "print(f\"  Pure JSON:    format={r1p[0]:.2f}, gameplay={r2[0]:.1f}, strategic={r3[0]:.1f}\")\n",
    "print(f\"  Verbose JSON: format={r1v[0]:.2f} (length penalty working)\")\n",
    "\n",
    "# 0-mine board\n",
    "test_kwargs_zero = {\n",
    "    \"seed\": [42],\n",
    "    \"move_history\": [\"[]\"],\n",
    "    \"board_rows\": [5],\n",
    "    \"board_cols\": [5],\n",
    "    \"board_mines\": [0],\n",
    "}\n",
    "\n",
    "r2z = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs_zero)\n",
    "r3z = strategic_reward(test_prompts, test_completions_pure, **test_kwargs_zero)\n",
    "print(f\"  0-mine board: gameplay={r2z[0]:.1f}, strategic={r3z[0]:.1f}\")\n",
    "\n",
    "# 1x1 board with 0 mines\n",
    "test_kwargs_1x1 = {\n",
    "    \"seed\": [42],\n",
    "    \"move_history\": [\"[]\"],\n",
    "    \"board_rows\": [1],\n",
    "    \"board_cols\": [1],\n",
    "    \"board_mines\": [0],\n",
    "}\n",
    "\n",
    "r2_1x1 = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs_1x1)\n",
    "print(f\"  1x1 m=0:     gameplay={r2_1x1[0]:.1f}\")\n",
    "\n",
    "# Hard board — difficulty multiplier should amplify\n",
    "test_kwargs_hard = {\n",
    "    \"seed\": [42],\n",
    "    \"move_history\": [\"[]\"],\n",
    "    \"board_rows\": [20],\n",
    "    \"board_cols\": [20],\n",
    "    \"board_mines\": [80],\n",
    "}\n",
    "\n",
    "r2h = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs_hard)\n",
    "r3h = strategic_reward(test_prompts, test_completions_pure, **test_kwargs_hard)\n",
    "print(f\"  Hard 20x20:   gameplay={r2h[0]:.1f}, strategic={r3h[0]:.1f} (XRPO amplified)\")\n",
    "\n",
    "print(f\"\\n  ✅ Edge cases: 0-mine boards, 1x1 boards, hard boards handled\")\n",
    "print(f\"  ✅ All reward functions work with kwargs (seed, move_history, board_rows/cols/mines)\")\n",
    "print(f\"  ✅ Length penalty (GRPO-LEAD): pure JSON ≤60c → +5.0, verbose >100c → -2.0\")\n",
    "print(f\"  ✅ Explicit wrong penalty (GRPO-LEAD): mine reveal -26, wrong flag -11\")\n",
    "print(f\"  ✅ Difficulty reweighting (XRPO): harder boards → amplified signal\")\n",
    "print(f\"  ✅ Win bonus scales with board size: 6×6→+104, 20×20→+140, 50×50→+250\")\n",
    "print(f\"  ✅ HACKATHON: JSON-only output, 128-token constraint, α=0.15 length penalty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b787f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Exhaustive Training Dataset Generation\n",
    "\n",
    "6-phase composition targeting **4000 samples** with density-stratified sampling:\n",
    "\n",
    "| Phase | Budget | Description |\n",
    "|-------|--------|-------------|\n",
    "| 1. Edge Cases | 10% | 50+ explicit configs (trivial, linear, rectangular, density extremes) |\n",
    "| 2. Opening | 25% | 75% fresh + 25% single-move — fix 75% early death rate |\n",
    "| 3. Pattern-Specific | 15% | Satisfied numbers (60%) + multi-region boards (40%) |\n",
    "| 4. Mid-Game | 25% | 3-15 moves, progressive flagging 10%→30%→50% |\n",
    "| 5. Endgame | 15% | 80-98% revealed, flag accounting, completion strategy |\n",
    "| 6. Forced Guess | 10% | No logical deductions available — probability reasoning |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993c0d4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ══════════════════════════════════════════════════════════════════════\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#  EXHAUSTIVE DATASET GENERATION\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#  Fixes: 75% early deaths, no pattern training, 0.7% endgame,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Helper: Smart move selection with progressive flagging\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ──────────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_smart_reveal\u001b[39m(game, rng):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  EXHAUSTIVE DATASET GENERATION\n",
    "#  Fixes: 75% early deaths, no pattern training, 0.7% endgame,\n",
    "#         no forced-guess scenarios, insufficient flag training\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Helper: Smart move selection with progressive flagging\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _smart_reveal(game, rng):\n",
    "    \"\"\"Pick a smart cell to reveal during history generation.\n",
    "    Prefers safe cells (if known) to avoid hitting mines and losing the game.\n",
    "    Falls back to random unrevealed cell.\n",
    "    \"\"\"\n",
    "    safe_set, _ = _compute_safe_and_mine_cells(game)\n",
    "    if safe_set:\n",
    "        return rng.choice(list(safe_set))\n",
    "\n",
    "    # Fallback: random unrevealed, unflagged cell\n",
    "    unrevealed = [(r, c) for r in range(game.rows) for c in range(game.cols)\n",
    "                  if (r, c) not in game._revealed and (r, c) not in game._flagged]\n",
    "    if not unrevealed:\n",
    "        return None\n",
    "    return rng.choice(unrevealed)\n",
    "\n",
    "\n",
    "def _smart_flag(game, rng):\n",
    "    \"\"\"Pick a logically certain mine to flag, or None if none available.\"\"\"\n",
    "    _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "    mine_candidates = [c for c in mine_set if c not in game._flagged]\n",
    "    if mine_candidates:\n",
    "        return rng.choice(mine_candidates)\n",
    "    return None  # Don't flag randomly — creates bad training data\n",
    "\n",
    "\n",
    "def _progressive_flag_probability(game):\n",
    "    \"\"\"Adaptive flagging based on game progress (LAMER-inspired).\n",
    "    - Early game (0-30%):  10% flagging (explore first)\n",
    "    - Mid game (30-70%):   30% flagging (deduce mines)\n",
    "    - Late game (70-100%): 50% flagging (lock in certain mines)\n",
    "    \"\"\"\n",
    "    progress = game.progress()\n",
    "    if progress < 0.30:\n",
    "        return 0.10\n",
    "    elif progress < 0.70:\n",
    "        return 0.30\n",
    "    else:\n",
    "        return 0.50\n",
    "\n",
    "\n",
    "def _play_smart_moves(game, rng, num_moves, use_progressive_flags=True):\n",
    "    \"\"\"Play num_moves smart moves on a game. Returns move_history list.\n",
    "    Uses progressive flagging strategy when enabled.\n",
    "    Returns early if game ends or gets stuck.\n",
    "\n",
    "    Fix #1: Added stuck_count to prevent infinite loops when no valid\n",
    "    moves can be found (e.g., all cells revealed/flagged but game ongoing).\n",
    "    \"\"\"\n",
    "    move_history = []\n",
    "    stuck_count = 0\n",
    "    MAX_STUCK = 10  # Abort after 10 consecutive failed attempts\n",
    "\n",
    "    for _ in range(num_moves):\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "\n",
    "        action_dict = None\n",
    "        flag_prob = _progressive_flag_probability(game) if use_progressive_flags else 0.15\n",
    "\n",
    "        # Try flagging with adaptive probability\n",
    "        if rng.random() < flag_prob:\n",
    "            flag_target = _smart_flag(game, rng)\n",
    "            if flag_target:\n",
    "                action_dict = {\"type\": \"flag\", \"row\": flag_target[0], \"col\": flag_target[1]}\n",
    "\n",
    "        # Fall back to reveal\n",
    "        if action_dict is None:\n",
    "            reveal_target = _smart_reveal(game, rng)\n",
    "            if reveal_target is None:\n",
    "                stuck_count += 1\n",
    "                if stuck_count >= MAX_STUCK:\n",
    "                    break  # Prevent infinite loop\n",
    "                continue\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": reveal_target[0], \"col\": reveal_target[1]}\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            break  # Hit a mine — stop\n",
    "\n",
    "        move_history.append(action_dict)\n",
    "        stuck_count = 0  # Reset on successful move\n",
    "\n",
    "    return move_history\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Scenario generators: endgame, forced-guess, multi-region\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _generate_endgame_state(rows, cols, num_mines, rng, completion_target=0.85):\n",
    "    \"\"\"Generate boards that are 80-98% complete.\n",
    "    Critical for teaching finishing strategy and flag accounting.\n",
    "    Returns (game, move_history) or (None, None) on failure.\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    safe_total = rows * cols - num_mines\n",
    "    if safe_total <= 1:\n",
    "        return None, None, seed\n",
    "\n",
    "    target_revealed = int(safe_total * rng.uniform(completion_target, 0.98))\n",
    "    target_revealed = max(1, min(target_revealed, safe_total - 1))\n",
    "\n",
    "    move_history = []\n",
    "    stuck_count = 0\n",
    "    max_stuck = 20\n",
    "\n",
    "    while len(game._revealed) < target_revealed and game.state() == \"ongoing\":\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        if safe_set:\n",
    "            target = rng.choice(list(safe_set))\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        else:\n",
    "            # No logical moves — reveal a random safe cell (we know the board)\n",
    "            all_safe_unrevealed = [\n",
    "                (r, c) for r in range(rows) for c in range(cols)\n",
    "                if game._board[r][c] != -1\n",
    "                and (r, c) not in game._revealed\n",
    "                and (r, c) not in game._flagged\n",
    "            ]\n",
    "            if not all_safe_unrevealed:\n",
    "                break\n",
    "            target = rng.choice(all_safe_unrevealed)\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "            stuck_count += 1\n",
    "            if stuck_count >= max_stuck:\n",
    "                break\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Optionally add some flags in endgame\n",
    "    if game.state() == \"ongoing\":\n",
    "        _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "        flaggable = [c for c in mine_set if c not in game._flagged]\n",
    "        if flaggable and rng.random() < 0.7:\n",
    "            num_flags = rng.randint(1, min(len(flaggable), 5))\n",
    "            for target in rng.sample(flaggable, num_flags):\n",
    "                action_dict = {\"type\": \"flag\", \"row\": target[0], \"col\": target[1]}\n",
    "                game.do_action(action_dict)\n",
    "                move_history.append(action_dict)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    return game, move_history, seed\n",
    "\n",
    "\n",
    "def _generate_forced_guess_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Generate a board state where no 100% certain logical moves exist.\n",
    "    These teach the model probability-based guessing.\n",
    "    Returns (game, move_history, seed) or (None, None, seed).\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    move_history = []\n",
    "    max_reveal_attempts = rows * cols\n",
    "\n",
    "    for _ in range(max_reveal_attempts):\n",
    "        if game.state() != \"ongoing\":\n",
    "            return None, None, seed\n",
    "\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        if not safe_set and not mine_set and len(game._revealed) > 0:\n",
    "            # No logical moves available — this is what we want!\n",
    "            unrevealed_count = sum(\n",
    "                1 for r in range(rows) for c in range(cols)\n",
    "                if (r, c) not in game._revealed and (r, c) not in game._flagged\n",
    "            )\n",
    "            if unrevealed_count >= 2:\n",
    "                return game, move_history, seed\n",
    "\n",
    "        if safe_set:\n",
    "            target = rng.choice(list(safe_set))\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        else:\n",
    "            # Must guess — reveal random safe cell (using board knowledge)\n",
    "            all_safe = [\n",
    "                (r, c) for r in range(rows) for c in range(cols)\n",
    "                if game._board[r][c] != -1\n",
    "                and (r, c) not in game._revealed\n",
    "                and (r, c) not in game._flagged\n",
    "            ]\n",
    "            if not all_safe:\n",
    "                break\n",
    "            target = rng.choice(all_safe)\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Fallback: return whatever state we reached (might still have logical moves)\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "def _generate_multi_region_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Create board with multiple separated revealed regions.\n",
    "    Teaches model to reason across disconnected information.\n",
    "    Returns (game, move_history, seed) or (None, None, seed).\n",
    "    \"\"\"\n",
    "    if rows < 6 or cols < 6:\n",
    "        return None, None, 0  # Need space for multiple regions\n",
    "\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    # Pick 2-4 starting points in different quadrants\n",
    "    quadrant_centers = [\n",
    "        (rows // 4, cols // 4),\n",
    "        (rows // 4, 3 * cols // 4),\n",
    "        (3 * rows // 4, cols // 4),\n",
    "        (3 * rows // 4, 3 * cols // 4),\n",
    "    ]\n",
    "    rng.shuffle(quadrant_centers)\n",
    "    num_regions = rng.randint(2, min(4, len(quadrant_centers)))\n",
    "    selected = quadrant_centers[:num_regions]\n",
    "\n",
    "    move_history = []\n",
    "    for r, c in selected:\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "        r = max(0, min(r, rows - 1))\n",
    "        c = max(0, min(c, cols - 1))\n",
    "\n",
    "        if (r, c) not in game._revealed and game._board[r][c] != -1:\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "            result = game.do_action(action_dict)\n",
    "            if result == \"mine\":\n",
    "                return None, None, seed\n",
    "            move_history.append(action_dict)\n",
    "\n",
    "        # Reveal a few logical neighbors around this region\n",
    "        for _ in range(rng.randint(1, 3)):\n",
    "            if game.state() != \"ongoing\":\n",
    "                break\n",
    "            safe_set, _ = _compute_safe_and_mine_cells(game)\n",
    "            if safe_set:\n",
    "                # Prefer safe cells near this region\n",
    "                nearby = [\n",
    "                    (sr, sc) for sr, sc in safe_set\n",
    "                    if abs(sr - r) <= rows // 3 and abs(sc - c) <= cols // 3\n",
    "                ]\n",
    "                target = rng.choice(nearby) if nearby else rng.choice(list(safe_set))\n",
    "                action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "                result = game.do_action(action_dict)\n",
    "                if result == \"mine\":\n",
    "                    return None, None, seed\n",
    "                move_history.append(action_dict)\n",
    "\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "def _generate_satisfied_numbers_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Generate board with multiple satisfied numbers (easy deductions available).\n",
    "    Satisfied number = number whose count of adjacent flags equals its value.\n",
    "    All remaining unrevealed neighbors of a satisfied number are safe.\n",
    "    Teaches basic constraint satisfaction.\n",
    "    Returns (game, move_history, seed).\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    move_history = []\n",
    "\n",
    "    # Reveal some cells first\n",
    "    num_initial = rng.randint(3, max(3, min(15, rows * cols // 4)))\n",
    "    for _ in range(num_initial):\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "        target = _smart_reveal(game, rng)\n",
    "        if target is None:\n",
    "            break\n",
    "        action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Now flag logically certain mines to create satisfied numbers\n",
    "    if game.state() == \"ongoing\":\n",
    "        for _ in range(5):\n",
    "            _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "            flaggable = [c for c in mine_set if c not in game._flagged]\n",
    "            if not flaggable:\n",
    "                break\n",
    "            target = rng.choice(flaggable)\n",
    "            action_dict = {\"type\": \"flag\", \"row\": target[0], \"col\": target[1]}\n",
    "            game.do_action(action_dict)\n",
    "            move_history.append(action_dict)\n",
    "\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Density-stratified board sampling\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "DENSITY_TARGETS = [\n",
    "    # (density_range, weight, label)\n",
    "    ((0.00, 0.00), 0.08, \"Zero mines\"),       # 8%  - trivial edge case\n",
    "    ((0.01, 0.05), 0.17, \"Very sparse\"),       # 17%\n",
    "    ((0.05, 0.10), 0.25, \"Sparse\"),            # 25%\n",
    "    ((0.10, 0.15), 0.25, \"Medium\"),            # 25%\n",
    "    ((0.15, 0.20), 0.25, \"Dense/Max\"),         # 25%\n",
    "]\n",
    "\n",
    "\n",
    "def _sample_board_with_density(rng, target_density_range=None):\n",
    "    \"\"\"Sample board config with explicit density control.\n",
    "    If target_density_range is None, picks one from DENSITY_TARGETS.\n",
    "    \"\"\"\n",
    "    if target_density_range is None:\n",
    "        # Weighted random density band\n",
    "        weights = [w for _, w, _ in DENSITY_TARGETS]\n",
    "        ranges = [r for r, _, _ in DENSITY_TARGETS]\n",
    "        idx = rng.choices(range(len(DENSITY_TARGETS)), weights=weights, k=1)[0]\n",
    "        target_density_range = ranges[idx]\n",
    "\n",
    "    # Sample board size — boosted large-board representation for 50×50 support\n",
    "    size_band = rng.random()\n",
    "    if size_band < 0.25:\n",
    "        rows, cols = rng.randint(1, 8), rng.randint(1, 8)      # 25% tiny\n",
    "    elif size_band < 0.45:\n",
    "        rows, cols = rng.randint(5, 15), rng.randint(5, 15)    # 20% small\n",
    "    elif size_band < 0.65:\n",
    "        rows, cols = rng.randint(10, 30), rng.randint(10, 30)  # 20% medium\n",
    "    elif size_band < 0.85:\n",
    "        rows, cols = rng.randint(20, 40), rng.randint(20, 40)  # 20% large\n",
    "    else:\n",
    "        rows, cols = rng.randint(30, 50), rng.randint(30, 50)  # 15% XL (30-50)\n",
    "\n",
    "    total = rows * cols\n",
    "    min_d, max_d = target_density_range\n",
    "\n",
    "    if min_d == 0.0 and max_d == 0.0:\n",
    "        return rows, cols, 0\n",
    "\n",
    "    min_mines = max(0, int(math.ceil(total * min_d)))\n",
    "    max_mines = min(int(total * max_d), int(total * MAX_MINE_DENSITY), total - 1)\n",
    "\n",
    "    if max_mines < min_mines:\n",
    "        num_mines = max(0, min(min_mines, total - 1))\n",
    "    else:\n",
    "        num_mines = rng.randint(min_mines, max_mines)\n",
    "\n",
    "    return rows, cols, num_mines\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Exhaustive edge-case configs (50+ scenarios)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "EDGE_CASE_CONFIGS = [\n",
    "    # (rows, cols, mines, label)\n",
    "\n",
    "    # === TRIVIAL BOARDS ===\n",
    "    (1, 1, 0,   \"1x1 trivial\"),\n",
    "    (2, 2, 0,   \"2x2 no mines\"),\n",
    "    (3, 3, 0,   \"3x3 no mines\"),\n",
    "    (4, 4, 0,   \"4x4 no mines\"),\n",
    "    (5, 5, 0,   \"5x5 no mines - cascade practice\"),\n",
    "\n",
    "    # === LINEAR BOARDS (1D Minesweeper) ===\n",
    "    (1, 5, 1,   \"1x5 single mine\"),\n",
    "    (1, 10, 2,  \"1x10 two mines\"),\n",
    "    (1, 20, 4,  \"1x20 row\"),\n",
    "    (1, 50, 10, \"1x50 maximum row\"),\n",
    "    (5, 1, 1,   \"5x1 column\"),\n",
    "    (10, 1, 2,  \"10x1 column\"),\n",
    "    (20, 1, 4,  \"20x1 column\"),\n",
    "    (50, 1, 10, \"50x1 maximum column\"),\n",
    "\n",
    "    # === TINY BOARDS ===\n",
    "    (1, 2, 0,   \"1x2 trivial\"),\n",
    "    (2, 1, 0,   \"2x1 trivial\"),\n",
    "    (2, 2, 1,   \"2x2 single mine\"),\n",
    "    (2, 3, 1,   \"2x3 mini\"),\n",
    "    (3, 2, 1,   \"3x2 mini\"),\n",
    "    (3, 3, 1,   \"3x3 single mine\"),\n",
    "    (3, 3, 2,   \"3x3 two mines\"),\n",
    "    (4, 4, 3,   \"4x4 medium density\"),\n",
    "\n",
    "    # === EXTREME RECTANGULAR ===\n",
    "    (2, 50, 20, \"2x50 ultra-wide\"),\n",
    "    (50, 2, 20, \"50x2 ultra-tall\"),\n",
    "    (3, 40, 24, \"3x40 extreme ratio\"),\n",
    "    (40, 3, 24, \"40x3 extreme ratio\"),\n",
    "    (5, 50, 50, \"5x50 max density wide\"),\n",
    "    (50, 5, 50, \"50x5 max density tall\"),\n",
    "\n",
    "    # === CLASSIC MINESWEEPER SIZES ===\n",
    "    (8, 8, 1,   \"8x8 very sparse\"),\n",
    "    (8, 8, 5,   \"8x8 sparse\"),\n",
    "    (8, 8, 10,  \"8x8 medium - classic beginner\"),\n",
    "    (8, 8, 13,  \"8x8 max density\"),\n",
    "    (16, 16, 10, \"16x16 sparse\"),\n",
    "    (16, 16, 40, \"16x16 medium - classic intermediate\"),\n",
    "    (16, 16, 51, \"16x16 max density\"),\n",
    "    (16, 30, 20, \"16x30 rectangular sparse\"),\n",
    "    (16, 30, 96, \"16x30 rectangular dense - classic expert\"),\n",
    "\n",
    "    # === LARGE BOARDS ===\n",
    "    (20, 20, 10, \"20x20 very sparse\"),\n",
    "    (20, 20, 80, \"20x20 max density\"),\n",
    "    (25, 25, 30, \"25x25 sparse\"),\n",
    "    (25, 25, 125, \"25x25 max density\"),\n",
    "    (30, 30, 50, \"30x30 sparse\"),\n",
    "    (30, 30, 180, \"30x30 max density\"),\n",
    "    (40, 40, 100, \"40x40 sparse\"),\n",
    "    (40, 40, 320, \"40x40 max density\"),\n",
    "\n",
    "    # === MAXIMUM SIZE ===\n",
    "    (50, 50, 10,  \"50x50 ultra-sparse\"),\n",
    "    (50, 50, 100, \"50x50 sparse\"),\n",
    "    (50, 50, 250, \"50x50 medium\"),\n",
    "    (50, 50, 500, \"50x50 maximum density\"),\n",
    "\n",
    "    # === DENSITY EDGE CASES ===\n",
    "    (10, 10, 0,  \"10x10 no mines\"),\n",
    "    (15, 15, 0,  \"15x15 no mines - large trivial\"),\n",
    "    (20, 20, 0,  \"20x20 no mines - huge trivial\"),\n",
    "    (10, 10, 1,  \"10x10 single mine\"),\n",
    "    (20, 20, 1,  \"20x20 single mine in large board\"),\n",
    "\n",
    "    # === MORE RECTANGULAR VARIETY ===\n",
    "    (3, 50, 30,  \"3x50 wide\"),\n",
    "    (50, 3, 30,  \"50x3 tall\"),\n",
    "    (5, 15, 15,  \"5x15 wide rect\"),\n",
    "    (15, 5, 15,  \"15x5 tall rect\"),\n",
    "    (6, 8, 6,    \"6x8 rect\"),\n",
    "    (8, 6, 6,    \"8x6 rect\"),\n",
    "    (7, 13, 18,  \"7x13 odd rect\"),\n",
    "    (13, 7, 18,  \"13x7 odd rect\"),\n",
    "    (15, 30, 90, \"15x30 wide large\"),\n",
    "]\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Dataset item builder (DRY helper)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _build_dataset_item(game, seed, move_history):\n",
    "    \"\"\"Build a single dataset item dict from a game state.\"\"\"\n",
    "    prompt_text = format_state_for_llm(game)\n",
    "    return {\n",
    "        \"prompt\": [{\"role\": \"user\", \"content\": prompt_text}],\n",
    "        \"seed\": seed,\n",
    "        \"move_history\": json.dumps(move_history),\n",
    "        \"board_rows\": game.rows,\n",
    "        \"board_cols\": game.cols,\n",
    "        \"board_mines\": game.num_mines,\n",
    "    }\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  MAIN GENERATOR — 6-Phase Exhaustive Composition\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def generate_exhaustive_dataset(num_samples=1000, rng_seed=42):\n",
    "    \"\"\"\n",
    "    Comprehensive Minesweeper training dataset covering ALL scenarios.\n",
    "\n",
    "    6-Phase composition:\n",
    "      Phase 1: Edge cases           — 10%  (50+ explicit configs)\n",
    "      Phase 2: Opening-heavy        — 25%  (fresh + single-move boards)\n",
    "      Phase 3: Pattern-specific     — 15%  (satisfied numbers, multi-region)\n",
    "      Phase 4: Mid-game deduction   — 25%  (core logical reasoning)\n",
    "      Phase 5: Endgame completion   — 15%  (80-98% revealed, flag accounting)\n",
    "      Phase 6: Forced guess         — 10%  (no logical moves available)\n",
    "\n",
    "    Improvements over previous version:\n",
    "      ✅ 50+ edge case configs (was 25)\n",
    "      ✅ Progressive flagging 10%→30%→50% by game phase (was flat 15%)\n",
    "      ✅ Density-stratified board sampling\n",
    "      ✅ Dedicated endgame generator (was 0.7% late-game)\n",
    "      ✅ Forced-guess scenario training (was 0%)\n",
    "      ✅ Multi-region disconnected boards (was 0%)\n",
    "      ✅ Satisfied-number pattern training (was 0%)\n",
    "      ✅ 4000 samples (was 3000)\n",
    "    \"\"\"\n",
    "    rng = random.Random(rng_seed)\n",
    "    np.random.seed(rng_seed)\n",
    "\n",
    "    dataset_items = []\n",
    "    phase_counts = {\n",
    "        \"edge_case\": 0, \"opening\": 0, \"pattern\": 0,\n",
    "        \"midgame\": 0, \"endgame\": 0, \"forced_guess\": 0,\n",
    "    }\n",
    "    config_counts = {}\n",
    "    density_counts = {\"zero\": 0, \"very_sparse\": 0, \"sparse\": 0, \"medium\": 0, \"dense\": 0}\n",
    "\n",
    "    def _track_config(game):\n",
    "        key = f\"{game.rows}x{game.cols}m{game.num_mines}\"\n",
    "        config_counts[key] = config_counts.get(key, 0) + 1\n",
    "        d = game.num_mines / (game.rows * game.cols) if game.rows * game.cols > 0 else 0\n",
    "        if d == 0:\n",
    "            density_counts[\"zero\"] += 1\n",
    "        elif d <= 0.05:\n",
    "            density_counts[\"very_sparse\"] += 1\n",
    "        elif d <= 0.10:\n",
    "            density_counts[\"sparse\"] += 1\n",
    "        elif d <= 0.15:\n",
    "            density_counts[\"medium\"] += 1\n",
    "        else:\n",
    "            density_counts[\"dense\"] += 1\n",
    "\n",
    "    # Budget per phase\n",
    "    n_edge     = int(num_samples * 0.10)\n",
    "    n_opening  = int(num_samples * 0.25)\n",
    "    n_pattern  = int(num_samples * 0.15)\n",
    "    n_midgame  = int(num_samples * 0.25)\n",
    "    n_endgame  = int(num_samples * 0.15)\n",
    "    n_forced   = num_samples - n_edge - n_opening - n_pattern - n_midgame - n_endgame\n",
    "\n",
    "    print(f\"  Phase budgets: edge={n_edge}, opening={n_opening}, pattern={n_pattern}, \"\n",
    "          f\"midgame={n_midgame}, endgame={n_endgame}, forced={n_forced}\")\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 1: Edge Cases (10%) — 50+ explicit configs\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 1: Edge cases...\")\n",
    "    edge_generated = 0\n",
    "    edge_idx = 0\n",
    "    while edge_generated < n_edge:\n",
    "        ec_rows, ec_cols, ec_mines, ec_label = EDGE_CASE_CONFIGS[edge_idx % len(EDGE_CASE_CONFIGS)]\n",
    "        edge_idx += 1\n",
    "        seed = rng.randint(0, 999999)\n",
    "\n",
    "        game = MinesweeperGame(rows=ec_rows, cols=ec_cols, num_mines=ec_mines, seed=seed)\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        # 0-3 moves for variety\n",
    "        num_moves = rng.randint(0, min(3, max(0, ec_rows * ec_cols - ec_mines - 1)))\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=True)\n",
    "\n",
    "        if game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"edge_case\"] += 1\n",
    "            edge_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 2: Opening-Heavy Training (25%) — Fix 75% early death rate\n",
    "    # 75% fresh (0 moves), 25% single-move\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 2: Opening training...\")\n",
    "    opening_generated = 0\n",
    "    opening_attempts = 0\n",
    "    while opening_generated < n_opening and opening_attempts < n_opening * 5:\n",
    "        opening_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng)\n",
    "\n",
    "        seed = rng.randint(0, 999999)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "        if num_mines == 0:\n",
    "            if game.state() == \"ongoing\":\n",
    "                dataset_items.append(_build_dataset_item(game, seed, []))\n",
    "                _track_config(game)\n",
    "                phase_counts[\"opening\"] += 1\n",
    "                opening_generated += 1\n",
    "            continue\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        # 75% fresh boards, 25% single-move\n",
    "        num_moves = 0 if rng.random() < 0.75 else 1\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=False)\n",
    "\n",
    "        if game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"opening\"] += 1\n",
    "            opening_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 3: Pattern-Specific Scenarios (15%)\n",
    "    # Mix of: satisfied-number boards (60%), multi-region boards (40%)\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 3: Pattern-specific scenarios...\")\n",
    "    pattern_generated = 0\n",
    "    pattern_attempts = 0\n",
    "    while pattern_generated < n_pattern and pattern_attempts < n_pattern * 10:\n",
    "        pattern_attempts += 1\n",
    "\n",
    "        # 60% satisfied numbers, 40% multi-region\n",
    "        if rng.random() < 0.60:\n",
    "            # Satisfied numbers — need boards with mines\n",
    "            rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.20))\n",
    "            if rows < 3 or cols < 3:\n",
    "                continue\n",
    "            game, move_history, seed = _generate_satisfied_numbers_state(\n",
    "                rows, cols, num_mines, rng\n",
    "            )\n",
    "        else:\n",
    "            # Multi-region — need larger boards\n",
    "            rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.15))\n",
    "            rows = max(rows, 8)\n",
    "            cols = max(cols, 8)\n",
    "            num_mines = min(num_mines, int(rows * cols * 0.15))\n",
    "            if num_mines < 1:\n",
    "                num_mines = max(1, int(rows * cols * 0.05))\n",
    "            game, move_history, seed = _generate_multi_region_state(\n",
    "                rows, cols, num_mines, rng\n",
    "            )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"pattern\"] += 1\n",
    "            pattern_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 4: Mid-Game Logical Deduction (25%) — Core gameplay\n",
    "    # 3-15 moves played, progressive flagging, density-stratified\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 4: Mid-game deduction...\")\n",
    "    midgame_generated = 0\n",
    "    midgame_attempts = 0\n",
    "    while midgame_generated < n_midgame and midgame_attempts < n_midgame * 5:\n",
    "        midgame_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng)\n",
    "\n",
    "        if num_mines == 0:\n",
    "            continue  # Skip zero-mine for midgame\n",
    "\n",
    "        seed = rng.randint(0, 999999)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        total_safe = rows * cols - num_mines\n",
    "        max_moves = min(15, max(3, total_safe - 1))\n",
    "        num_moves = rng.randint(3, max_moves)\n",
    "\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=True)\n",
    "\n",
    "        if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"midgame\"] += 1\n",
    "            midgame_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 5: Endgame Completion (15%) — 80-98% revealed\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 5: Endgame completion...\")\n",
    "    endgame_generated = 0\n",
    "    endgame_attempts = 0\n",
    "    while endgame_generated < n_endgame and endgame_attempts < n_endgame * 10:\n",
    "        endgame_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.20))\n",
    "\n",
    "        if num_mines < 1 or rows * cols < 8:\n",
    "            continue\n",
    "\n",
    "        completion = rng.uniform(0.80, 0.95)\n",
    "        game, move_history, seed = _generate_endgame_state(\n",
    "            rows, cols, num_mines, rng, completion_target=completion\n",
    "        )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"endgame\"] += 1\n",
    "            endgame_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 6: Forced Guess Scenarios (10%) — No logical deductions\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 6: Forced guess scenarios...\")\n",
    "    forced_generated = 0\n",
    "    forced_attempts = 0\n",
    "    while forced_generated < n_forced and forced_attempts < n_forced * 15:\n",
    "        forced_attempts += 1\n",
    "        # Dense boards more likely to produce forced-guess states\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng, (0.10, 0.20))\n",
    "\n",
    "        if num_mines < 2 or rows * cols < 6:\n",
    "            continue\n",
    "\n",
    "        game, move_history, seed = _generate_forced_guess_state(\n",
    "            rows, cols, num_mines, rng\n",
    "        )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"forced_guess\"] += 1\n",
    "            forced_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # Shuffle and trim\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    rng.shuffle(dataset_items)\n",
    "    dataset_items = dataset_items[:num_samples]\n",
    "    ds = Dataset.from_list(dataset_items)\n",
    "\n",
    "    return ds, config_counts, phase_counts, density_counts\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  Generate & Analyze\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  EXHAUSTIVE DATASET GENERATION\")\n",
    "print(\"  4000 samples | 6 phases | 50+ edge cases | density-stratified\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "dataset, config_counts, phase_counts, density_counts = generate_exhaustive_dataset(\n",
    "    num_samples=1000, rng_seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(f\"Created {len(dataset)} training examples\\n\")\n",
    "\n",
    "# Phase distribution\n",
    "print(\"Phase distribution:\")\n",
    "for phase, count in phase_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {phase:14s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Density distribution\n",
    "print(f\"\\nDensity distribution:\")\n",
    "for band, count in density_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {band:14s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Board size distribution (top 20)\n",
    "print(f\"\\nBoard size distribution (top 20):\")\n",
    "sorted_configs = sorted(config_counts.items(), key=lambda x: -x[1])\n",
    "for config, count in sorted_configs[:20]:\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {config:16s}: {count:4d} ({pct:.1f}%)\")\n",
    "if len(sorted_configs) > 20:\n",
    "    print(f\"  ... and {len(sorted_configs) - 20} more unique configs\")\n",
    "print(f\"\\nTotal unique board configs: {len(config_counts)}\")\n",
    "\n",
    "# Board size statistics\n",
    "all_rows = [item[\"board_rows\"] for item in dataset]\n",
    "all_cols = [item[\"board_cols\"] for item in dataset]\n",
    "all_mines = [item[\"board_mines\"] for item in dataset]\n",
    "print(f\"\\nBoard size statistics:\")\n",
    "print(f\"  Rows:  min={min(all_rows)}, max={max(all_rows)}, mean={np.mean(all_rows):.1f}\")\n",
    "print(f\"  Cols:  min={min(all_cols)}, max={max(all_cols)}, mean={np.mean(all_cols):.1f}\")\n",
    "print(f\"  Mines: min={min(all_mines)}, max={max(all_mines)}, mean={np.mean(all_mines):.1f}\")\n",
    "densities = [m / (r * c) * 100 for r, c, m in zip(all_rows, all_cols, all_mines) if r * c > 0]\n",
    "print(f\"  Density: min={min(densities):.1f}%, max={max(densities):.1f}%, mean={np.mean(densities):.1f}%\")\n",
    "\n",
    "zero_mine_count = sum(1 for m in all_mines if m == 0)\n",
    "print(f\"  Zero-mine boards: {zero_mine_count} ({zero_mine_count/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "move_counts = [len(json.loads(item[\"move_history\"])) for item in dataset]\n",
    "print(f\"\\nMove statistics:\")\n",
    "print(f\"  Min: {min(move_counts)}, Max: {max(move_counts)}, \"\n",
    "      f\"Mean: {np.mean(move_counts):.1f}, Median: {np.median(move_counts):.1f}\")\n",
    "\n",
    "# Phase-specific move stats\n",
    "print(f\"\\nLogical deduction coverage:\")\n",
    "has_safe = 0\n",
    "has_mine = 0\n",
    "has_both = 0\n",
    "for item in dataset:\n",
    "    mh = json.loads(item[\"move_history\"])\n",
    "    has_flag = any(m.get(\"type\") == \"flag\" for m in mh)\n",
    "    has_rev = any(m.get(\"type\") == \"reveal\" for m in mh)\n",
    "    if has_flag:\n",
    "        has_mine += 1\n",
    "    if has_rev:\n",
    "        has_safe += 1\n",
    "    if has_flag and has_rev:\n",
    "        has_both += 1\n",
    "print(f\"  Samples with reveals: {has_safe} ({has_safe/len(dataset)*100:.1f}%)\")\n",
    "print(f\"  Samples with flags:   {has_mine} ({has_mine/len(dataset)*100:.1f}%)\")\n",
    "print(f\"  Samples with both:    {has_both} ({has_both/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "# Verify dataset columns\n",
    "print(f\"\\nDataset columns: {dataset.column_names}\")\n",
    "print(f\"  ✅ board_rows, board_cols, board_mines present for reward functions\")\n",
    "\n",
    "# ── Save dataset to JSON ──\n",
    "dataset_json_path = \"minesweeper_dataset.json\"\n",
    "\n",
    "json_records = []\n",
    "for item in dataset:\n",
    "    record = {\n",
    "        \"seed\": item[\"seed\"],\n",
    "        \"move_history\": item[\"move_history\"],\n",
    "        \"board_rows\": item[\"board_rows\"],\n",
    "        \"board_cols\": item[\"board_cols\"],\n",
    "        \"board_mines\": item[\"board_mines\"],\n",
    "        \"prompt_text\": item[\"prompt\"][0][\"content\"],\n",
    "    }\n",
    "    json_records.append(record)\n",
    "\n",
    "with open(dataset_json_path, \"w\") as f:\n",
    "    json.dump(json_records, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Dataset saved to {dataset_json_path} ({os.path.getsize(dataset_json_path) / 1024:.1f} KB)\")\n",
    "print(f\"   {len(json_records)} records with fields: seed, move_history, board_rows/cols/mines, prompt_text\")\n",
    "\n",
    "print(f\"\\nSample prompt ({dataset[0]['board_rows']}x{dataset[0]['board_cols']}, \"\n",
    "      f\"{dataset[0]['board_mines']} mines):\")\n",
    "print(dataset[0][\"prompt\"][0][\"content\"][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e4491",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Configure GRPO Training\n",
    "\n",
    "Set up GRPO trainer with all hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478959ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# ── Lengths ──\n",
    "# Simplified unified prompt (~300-400 tokens for most boards)\n",
    "# - Small boards (1-30): Full grid, ~200-600 tokens\n",
    "# - Large boards (31-50): Frontier zone only, ~400-800 tokens\n",
    "# 1900 + 128 = 2028 < 2048 = max_seq_length (fits comfortably)\n",
    "max_prompt_length = 1900\n",
    "max_completion_length = 128  # HACKATHON CONSTRAINT: JSON-only output\n",
    "                             # Pure JSON action is ~10-25 tokens\n",
    "\n",
    "# ── GRPO Configuration (Hybrid: LAMER + XRPO + GRPO-LEAD + S-GRPO) ──\n",
    "training_args = GRPOConfig(\n",
    "    # === Generation (LAMER: temperature=1.0 for training exploration) ===\n",
    "    temperature = 1.0,           # LAMER paper: full exploration during training\n",
    "    top_p = 0.95,\n",
    "\n",
    "    # === Optimization (XRPO: lower LR for stability with difficulty reweighting) ===\n",
    "    learning_rate = 5e-6,        # Reduced from 2e-5: XRPO reweighting + GRPO-LEAD\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.05,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    max_grad_norm = 0.5,\n",
    "\n",
    "    # === Batch sizes ===\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_generations = 8,\n",
    "\n",
    "    # === Lengths ===\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_completion_length,\n",
    "\n",
    "    # === Training duration ===\n",
    "    max_steps = 500,\n",
    "    save_steps = 100,\n",
    "\n",
    "    # === GRPO specific (LAMER: num_iterations=2 for MineSweeper) ===\n",
    "    beta = 0.04,                 # Mild KL penalty to prevent reward hacking\n",
    "    num_iterations = 2,          # LAMER paper: 2 GRPO iterations\n",
    "\n",
    "    # === Reward weighting ===\n",
    "    # [valid_json + length_penalty, gameplay + difficulty_reweight, strategic + difficulty]\n",
    "    # Increased format weight slightly since it now includes length penalty (GRPO-LEAD)\n",
    "    reward_weights = [0.20, 0.65, 0.15],\n",
    "\n",
    "    # === Ensure extra dataset columns are NOT removed ===\n",
    "    remove_unused_columns = False,\n",
    "\n",
    "    # === Output ===\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"minesweeper_grpo_v2\",\n",
    "    seed = 42,\n",
    "    bf16 = True,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Max steps:           {training_args.max_steps}\")\n",
    "print(f\"  Generations/state:   {training_args.num_generations}\")\n",
    "print(f\"  Learning rate:       {training_args.learning_rate}\")\n",
    "print(f\"  LR scheduler:       {training_args.lr_scheduler_type}\")\n",
    "print(f\"  Max grad norm:       {training_args.max_grad_norm}\")\n",
    "print(f\"  Beta (KL penalty):   {training_args.beta}\")\n",
    "print(f\"  Num iterations:      {training_args.num_iterations}\")\n",
    "print(f\"  Reward weights:      {training_args.reward_weights}\")\n",
    "print(f\"  Prompt/Completion:   {max_prompt_length}/{max_completion_length}\")\n",
    "print(f\"  Temperature:         {training_args.temperature}\")\n",
    "print(f\"  remove_unused_cols:  {training_args.remove_unused_columns}\")\n",
    "print(f\"  LoRA rank:           {lora_rank}\")\n",
    "print(f\"  Board range:         1-50 rows × 1-50 cols, 0-20% mines\")\n",
    "print()\n",
    "print(\"Prompt system: Simplified unified format (~300-400 tokens)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "# Board configs to evaluate on during training (mix of sizes from 1-50 range)\n",
    "EVAL_CONFIGS = [\n",
    "    (1, 1, 0),     # Trivial — 0 mines\n",
    "    (3, 3, 1),     # Tiny\n",
    "    (5, 5, 3),     # Small\n",
    "    (6, 6, 5),     # Standard\n",
    "    (8, 8, 10),    # Medium\n",
    "    (10, 10, 20),  # Large\n",
    "    (15, 15, 45),  # XL\n",
    "    (6, 8, 6),     # Rectangular\n",
    "    (1, 10, 2),    # Row board\n",
    "    (20, 20, 80),  # XX-Large\n",
    "]\n",
    "\n",
    "\n",
    "class MinesweeperEvalCallback(TrainerCallback):\n",
    "    \"\"\"Periodically play games during training with variable board sizes.\n",
    "\n",
    "    NO move limit — games end only on success (all safe revealed)\n",
    "    or failure (mine hit). Max iterations capped to prevent infinite loops\n",
    "    from repeated invalid actions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eval_every_steps=50, num_games=10):\n",
    "        self.eval_every_steps = eval_every_steps\n",
    "        self.num_games = min(num_games, len(EVAL_CONFIGS))\n",
    "\n",
    "    def on_step_end(self, args, state, control, model=None, processing_class=None, **kwargs):\n",
    "        if state.global_step % self.eval_every_steps != 0:\n",
    "            return\n",
    "\n",
    "        tokenizer = processing_class\n",
    "        if tokenizer is None or model is None:\n",
    "            return\n",
    "\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "\n",
    "        wins = 0\n",
    "        total_moves = 0\n",
    "        invalid_count = 0\n",
    "\n",
    "        for i in range(self.num_games):\n",
    "            rows, cols, mines = EVAL_CONFIGS[i % len(EVAL_CONFIGS)]\n",
    "            game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines,\n",
    "                                   seed=10000 + i)\n",
    "            moves = 0\n",
    "            invalids = 0\n",
    "            consecutive_invalids = 0\n",
    "            seen_actions = set()   # Fix #4: detect repeated actions\n",
    "            repeat_count = 0       # Fix #4: count consecutive repeats\n",
    "            # Safety cap: prevent infinite loops (not a move limit — just loop protection)\n",
    "            # Capped at 500 to prevent runaway 50×50 evals (was rows*cols*3+20 = 7520 for 50×50)\n",
    "            max_iterations = min(500, rows * cols + 100)\n",
    "\n",
    "            iteration = 0\n",
    "            while game.state() == \"ongoing\" and iteration < max_iterations:\n",
    "                iteration += 1\n",
    "                prompt = format_state_for_llm(game, mode=\"inference\")\n",
    "                text = tokenizer.apply_chat_template(\n",
    "                    [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True,\n",
    "                )\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                                   max_length=max_prompt_length + 100)\n",
    "                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model.generate(\n",
    "                        **inputs,\n",
    "                        temperature=0.7,  # LAMER paper: 0.7 for eval\n",
    "                        max_new_tokens=128,  # HACKATHON CONSTRAINT: JSON-only\n",
    "                        do_sample=True,\n",
    "                        top_p=0.9,\n",
    "                    )\n",
    "\n",
    "                # Decode ONLY the generated tokens (not the prompt)\n",
    "                gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "                response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "                action = parse_llm_action(response)\n",
    "\n",
    "                if action is None:\n",
    "                    invalids += 1\n",
    "                    consecutive_invalids += 1\n",
    "                    if consecutive_invalids >= 5:\n",
    "                        break  # Too many consecutive invalid actions\n",
    "                    continue\n",
    "\n",
    "                consecutive_invalids = 0\n",
    "\n",
    "                # Fix #4: Check for repeated actions (stuck detection)\n",
    "                action_key = (action['type'], action['row'], action['col'])\n",
    "                if action_key in seen_actions:\n",
    "                    repeat_count += 1\n",
    "                    if repeat_count >= 3:  # Same move 3 times = stuck\n",
    "                        break\n",
    "                else:\n",
    "                    repeat_count = 0\n",
    "                    seen_actions.add(action_key)\n",
    "\n",
    "                result = game.do_action(action)\n",
    "                if result in (\"mine\", \"win\"):\n",
    "                    moves += 1\n",
    "                    break\n",
    "                elif result == \"ok\":\n",
    "                    moves += 1\n",
    "                else:\n",
    "                    # Invalid move (out_of_bounds, already_revealed, etc.)\n",
    "                    invalids += 1\n",
    "                    consecutive_invalids += 1\n",
    "                    if consecutive_invalids >= 5:\n",
    "                        break\n",
    "\n",
    "            if game.state() == \"success\":\n",
    "                wins += 1\n",
    "            total_moves += moves\n",
    "            invalid_count += invalids\n",
    "\n",
    "        win_rate = wins / self.num_games\n",
    "        avg_moves = total_moves / self.num_games\n",
    "        print(f\"\\n[Eval @ step {state.global_step}] \"\n",
    "              f\"Win: {wins}/{self.num_games} ({win_rate*100:.0f}%) | \"\n",
    "              f\"Avg moves: {avg_moves:.1f} | \"\n",
    "              f\"Invalid: {invalid_count}\\n\")\n",
    "\n",
    "        if was_training:\n",
    "            model.train()\n",
    "\n",
    "eval_callback = MinesweeperEvalCallback(eval_every_steps=50, num_games=10)\n",
    "\n",
    "print(f\"Eval callback: {eval_callback.num_games} games every \"\n",
    "      f\"{eval_callback.eval_every_steps} steps\")\n",
    "print(f\"  No move limit — only success or failure\")\n",
    "print(f\"  Uses inference-mode prompt (60% fewer tokens)\")\n",
    "print(f\"  Configs: {len(EVAL_CONFIGS)} sizes from 1x1 to 20x20\")\n",
    "print(f\"  Max iterations capped at min(500, rows*cols+100)\")\n",
    "print(f\"  max_new_tokens=128 (HACKATHON CONSTRAINT: JSON-only output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8e106",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Train the Model\n",
    "\n",
    "Start GRPO training with reward functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d03871",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        valid_json_reward,   # Format + length penalty (GRPO-LEAD)\n",
    "        gameplay_scores,     # 12 criteria + difficulty reweight (XRPO)\n",
    "        strategic_reward,    # Deduction + center-opening + difficulty (XRPO)\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    "    callbacks = [eval_callback],  # Periodic gameplay evaluation\n",
    ")\n",
    "\n",
    "print(\"Starting GRPO training with 3 hybrid reward functions...\")\n",
    "print(\"  [1] valid_json_reward  (weight: 0.20) — format + length penalty (GRPO-LEAD)\")\n",
    "print(\"  [2] gameplay_scores    (weight: 0.65) — 12 criteria + difficulty (XRPO)\")\n",
    "print(\"  [3] strategic_reward   (weight: 0.15) — deduction + center (LAMER)\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8d025",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Trained Model\n",
    "\n",
    "Evaluate the finetuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00276c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on variable board sizes across the full competition range\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "test_configs = [\n",
    "    (1, 1, 0, 200, \"1x1 Trivial\"),\n",
    "    (3, 3, 1, 201, \"Tiny\"),\n",
    "    (5, 5, 3, 202, \"Small/Easy\"),\n",
    "    (6, 6, 5, 99,  \"Standard\"),\n",
    "    (8, 8, 10, 101, \"Medium\"),\n",
    "    (10, 10, 20, 203, \"Large 20%\"),\n",
    "    (15, 15, 45, 204, \"XL 20%\"),\n",
    "    (1, 20, 4, 205, \"Row Board\"),\n",
    "    (20, 1, 4, 206, \"Column Board\"),\n",
    "    (5, 5, 0, 207, \"Zero Mines\"),\n",
    "]\n",
    "\n",
    "for rows, cols, mines, seed, label in test_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"=== {label} ({rows}x{cols}, {mines} mines) ===\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    test_game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "\n",
    "    # Handle already-won games (0-mine boards that auto-cascade)\n",
    "    if test_game.state() != \"ongoing\":\n",
    "        print(f\"  Game auto-resolved: {test_game.state()}\")\n",
    "        continue\n",
    "\n",
    "    test_prompt = format_state_for_llm(test_game, mode=\"inference\")\n",
    "\n",
    "    test_text = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": test_prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True,\n",
    "                       max_length=max_prompt_length + 100)\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.7,  # LAMER paper: 0.7 for eval\n",
    "        max_new_tokens=128,  # HACKATHON CONSTRAINT: JSON-only\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "\n",
    "    # Decode only generated tokens\n",
    "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "    print(f\"Response: {response_text.strip()}\")\n",
    "\n",
    "    action = parse_llm_action(response_text)\n",
    "    print(f\"Parsed action: {action}\")\n",
    "\n",
    "    if action:\n",
    "        result = test_game.do_action(action)\n",
    "        print(f\"Result: {result} | Game state: {test_game.state()}\")\n",
    "    else:\n",
    "        print(\"⚠️ Failed to parse a valid action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2551f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Exhaustive Evaluation: Full Competition Range\n",
    "\n",
    "Play complete games across 37 board configurations (1×1 to 50×50, 0-20% mines).\n",
    "**No move limit** — only two outcomes: SUCCESS (all safe cells revealed) or FAILURE (mine revealed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31315fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def play_full_game(model, tokenizer, rows=6, cols=6, num_mines=5, seed=None,\n",
    "#                    verbose=False):\n",
    "#     \"\"\"Play a complete Minesweeper game, tracking detailed metrics.\n",
    "\n",
    "#     Supports any board size from 1x1 to 50x50.\n",
    "#     NO move limit — game ends ONLY on:\n",
    "#       - SUCCESS: all non-mine cells are revealed\n",
    "#       - FAILURE: any mine cell is revealed\n",
    "#     A safety iteration cap prevents infinite loops from repeated invalid actions.\n",
    "#     \"\"\"\n",
    "#     game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "#     # Edge case: game already won (e.g., 0-mine board)\n",
    "#     if game.state() != \"ongoing\":\n",
    "#         return {\n",
    "#             \"game\": game,\n",
    "#             \"moves\": 0,\n",
    "#             \"logical_moves\": 0,\n",
    "#             \"flags_correct\": 0,\n",
    "#             \"flags_wrong\": 0,\n",
    "#             \"total_invalids\": 0,\n",
    "#             \"result\": game.state(),\n",
    "#             \"progress\": game.progress(),\n",
    "#             \"config\": f\"{rows}x{cols}m{num_mines}\",\n",
    "#         }\n",
    "\n",
    "#     moves = 0\n",
    "#     consecutive_invalids = 0\n",
    "#     total_invalids = 0\n",
    "#     logical_moves = 0\n",
    "#     flags_correct = 0\n",
    "#     flags_wrong = 0\n",
    "#     seen_actions = set()   # Fix #4: detect repeated actions (stuck loop)\n",
    "#     repeat_count = 0       # Fix #4: consecutive repeat counter\n",
    "#     # Safety cap to prevent infinite loops — NOT a game move limit\n",
    "#     # Capped at 500 to prevent runaway 50×50 evals (was rows*cols*3+50 = 7550 for 50×50)\n",
    "#     max_iterations = min(500, rows * cols + 100)\n",
    "\n",
    "#     iteration = 0\n",
    "#     while game.state() == \"ongoing\" and iteration < max_iterations:\n",
    "#         iteration += 1\n",
    "#         prompt = format_state_for_llm(game, mode=\"inference\")\n",
    "#         text = tokenizer.apply_chat_template(\n",
    "#             [{\"role\": \"user\", \"content\": prompt}],\n",
    "#             tokenize=False,\n",
    "#             add_generation_prompt=True,\n",
    "#         )\n",
    "\n",
    "#         inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "#                            max_length=max_prompt_length + 100)\n",
    "#         inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             output = model.generate(\n",
    "#                 **inputs,\n",
    "#                 temperature=0.7,  # LAMER paper: 0.7 for eval\n",
    "#                 max_new_tokens=128,  # HACKATHON CONSTRAINT: JSON-only\n",
    "#                 do_sample=True,\n",
    "#                 top_p=0.9,\n",
    "#                 repetition_penalty=1.2,\n",
    "#             )\n",
    "\n",
    "#         # Decode ONLY generated tokens\n",
    "#         gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "#         response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "#         action = parse_llm_action(response)\n",
    "\n",
    "#         if action is None:\n",
    "#             consecutive_invalids += 1\n",
    "#             total_invalids += 1\n",
    "#             if consecutive_invalids >= 5:\n",
    "#                 break  # Agent is stuck — abort\n",
    "#             continue\n",
    "\n",
    "#         # Fix #4: Check for repeated actions (stuck detection)\n",
    "#         action_key = (action['type'], action['row'], action['col'])\n",
    "#         if action_key in seen_actions:\n",
    "#             repeat_count += 1\n",
    "#             if repeat_count >= 3:  # Same move 3 times = stuck\n",
    "#                 break\n",
    "#         else:\n",
    "#             repeat_count = 0\n",
    "#             seen_actions.add(action_key)\n",
    "\n",
    "#         # Track logical moves (compute BEFORE applying action)\n",
    "#         safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "#         r, c = action[\"row\"], action[\"col\"]\n",
    "#         if action[\"type\"] == \"reveal\" and (r, c) in safe_set:\n",
    "#             logical_moves += 1\n",
    "#         elif action[\"type\"] == \"flag\" and (r, c) in mine_set:\n",
    "#             logical_moves += 1\n",
    "\n",
    "#         # Track flag accuracy\n",
    "#         if action[\"type\"] == \"flag\":\n",
    "#             if 0 <= r < game.rows and 0 <= c < game.cols:\n",
    "#                 if game._board[r][c] == -1:\n",
    "#                     flags_correct += 1\n",
    "#                 else:\n",
    "#                     flags_wrong += 1\n",
    "\n",
    "#         if verbose:\n",
    "#             print(f\"  Move {moves}: {action}\")\n",
    "\n",
    "#         result = game.do_action(action)\n",
    "#         if result in (\"mine\", \"win\", \"ok\"):\n",
    "#             moves += 1\n",
    "#         elif result in (\"out_of_bounds\", \"already_revealed\", \"flagged_cell\",\n",
    "#                          \"invalid_flag\", \"invalid_format\"):\n",
    "#             # Invalid moves don't count but game stays ongoing\n",
    "#             total_invalids += 1\n",
    "#             consecutive_invalids += 1\n",
    "#             if consecutive_invalids >= 5:\n",
    "#                 break\n",
    "\n",
    "#         if result in (\"mine\", \"win\"):\n",
    "#             break\n",
    "\n",
    "#     return {\n",
    "#         \"game\": game,\n",
    "#         \"moves\": moves,\n",
    "#         \"logical_moves\": logical_moves,\n",
    "#         \"flags_correct\": flags_correct,\n",
    "#         \"flags_wrong\": flags_wrong,\n",
    "#         \"total_invalids\": total_invalids,\n",
    "#         \"result\": game.state(),\n",
    "#         \"progress\": game.progress(),\n",
    "#         \"config\": f\"{rows}x{cols}m{num_mines}\",\n",
    "#     }\n",
    "\n",
    "\n",
    "# # ──────────────────────────────────────────────────────────────────────\n",
    "# # EXHAUSTIVE Multi-Size Evaluation — Competition Spec\n",
    "# # n, m ∈ [1, 50], mines 0-20% of total cells\n",
    "# # Only two outcomes: SUCCESS or FAILURE (no timeouts)\n",
    "# # ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# EVAL_SUITE = [\n",
    "#     # (rows, cols, mines, num_games, label)\n",
    "\n",
    "#     # === Trivial / Edge Cases ===\n",
    "#     (1, 1, 0,   5,  \"1x1 trivial\"),\n",
    "#     (1, 2, 0,   5,  \"1x2 trivial\"),\n",
    "#     (2, 1, 0,   5,  \"2x1 trivial\"),\n",
    "#     (2, 2, 0,   5,  \"2x2 no mines\"),\n",
    "#     (3, 3, 0,   5,  \"3x3 no mines\"),\n",
    "#     (5, 5, 0,   5,  \"5x5 no mines\"),\n",
    "\n",
    "#     # === Tiny Boards ===\n",
    "#     (3, 3, 1,  10,  \"3x3 1 mine\"),\n",
    "#     (4, 4, 3,  10,  \"4x4 3 mines\"),\n",
    "\n",
    "#     # === Small Boards ===\n",
    "#     (5, 5, 3,  15,  \"5x5 easy\"),\n",
    "#     (5, 5, 5,  10,  \"5x5 max density\"),\n",
    "\n",
    "#     # === Standard ===\n",
    "#     (6, 6, 5,  20,  \"6x6 standard\"),\n",
    "#     (6, 6, 7,  10,  \"6x6 hard\"),\n",
    "\n",
    "#     # === Medium ===\n",
    "#     (7, 7, 7,  10,  \"7x7 medium\"),\n",
    "#     (8, 8, 10, 10,  \"8x8 medium\"),\n",
    "#     (8, 8, 12, 10,  \"8x8 max density\"),\n",
    "\n",
    "#     # === Large ===\n",
    "#     (10, 10, 10,  5, \"10x10 10%\"),\n",
    "#     (10, 10, 20, 10, \"10x10 20%\"),\n",
    "#     (15, 15, 45,  5, \"15x15 20%\"),\n",
    "\n",
    "#     # === XL ===\n",
    "#     (20, 20, 80,  3, \"20x20 20%\"),\n",
    "#     (25, 25, 125, 3, \"25x25 20%\"),\n",
    "#     (30, 30, 180, 2, \"30x30 20%\"),\n",
    "\n",
    "#     # === XXL ===\n",
    "#     (40, 40, 320, 2, \"40x40 20%\"),\n",
    "#     (50, 50, 500, 2, \"50x50 20%\"),\n",
    "\n",
    "#     # === Rectangular ===\n",
    "#     (1, 10, 2,   5, \"1x10 row\"),\n",
    "#     (10, 1, 2,   5, \"10x1 column\"),\n",
    "#     (1, 50, 10,  3, \"1x50 row\"),\n",
    "#     (50, 1, 10,  3, \"50x1 column\"),\n",
    "#     (6, 8, 6,    5, \"6x8 rect\"),\n",
    "#     (8, 6, 6,    5, \"8x6 rect\"),\n",
    "#     (5, 15, 15,  3, \"5x15 wide\"),\n",
    "#     (15, 5, 15,  3, \"15x5 tall\"),\n",
    "#     (3, 50, 30,  2, \"3x50 extreme wide\"),\n",
    "#     (50, 3, 30,  2, \"50x3 extreme tall\"),\n",
    "\n",
    "#     # === Sparse (low density) ===\n",
    "#     (10, 10, 1,  5, \"10x10 sparse\"),\n",
    "#     (20, 20, 4,  3, \"20x20 sparse\"),\n",
    "#     (50, 50, 10, 2, \"50x50 sparse\"),\n",
    "\n",
    "#     # === Progressive Difficulty (Fix #10: LAMER generalization test) ===\n",
    "#     # Same size, increasing mines — tests density scaling\n",
    "#     (10, 10, 5,  5, \"10x10 5% progressive\"),\n",
    "#     (10, 10, 15, 5, \"10x10 15% progressive\"),\n",
    "\n",
    "#     # Increasing size, same ~10% density — tests size scaling\n",
    "#     (15, 15, 23, 3, \"15x15 10% density\"),\n",
    "#     (20, 20, 40, 3, \"20x20 10% density\"),\n",
    "\n",
    "#     # Generalization to harder unseen configs\n",
    "#     (25, 25, 62, 2, \"25x25 10% generalization\"),\n",
    "#     (30, 30, 90, 2, \"30x30 10% generalization\"),\n",
    "# ]\n",
    "\n",
    "# FastLanguageModel.for_inference(model)\n",
    "# total_games = sum(n for _,_,_,n,_ in EVAL_SUITE)\n",
    "# print(f\"{'='*80}\")\n",
    "# print(f\"  EXHAUSTIVE EVALUATION — {total_games} games across {len(EVAL_SUITE)} configs\")\n",
    "# print(f\"  Competition spec: n,m ∈ [1,50], mines 0-20%, no move limit\")\n",
    "# print(f\"  Includes progressive difficulty test (LAMER generalization)\")\n",
    "# print(f\"  Only two outcomes: SUCCESS or FAILURE\")\n",
    "# print(f\"{'='*80}\\n\")\n",
    "\n",
    "# all_results = []\n",
    "# per_config_stats = {}\n",
    "\n",
    "# for rows, cols, mines, num_games, label in EVAL_SUITE:\n",
    "#     config_key = f\"{rows}x{cols}m{mines}\"\n",
    "#     wins = 0\n",
    "#     fails = 0\n",
    "#     config_results = []\n",
    "\n",
    "#     for i in range(num_games):\n",
    "#         info = play_full_game(model, tokenizer, rows=rows, cols=cols,\n",
    "#                               num_mines=mines, seed=5000 + i + hash(config_key) % 10000)\n",
    "#         config_results.append(info)\n",
    "#         all_results.append(info)\n",
    "\n",
    "#         if info[\"result\"] == \"success\":\n",
    "#             wins += 1\n",
    "#         elif info[\"result\"] == \"failed\":\n",
    "#             fails += 1\n",
    "\n",
    "#     # Per-config summary\n",
    "#     avg_moves = np.mean([r[\"moves\"] for r in config_results])\n",
    "#     avg_logical = np.mean([r[\"logical_moves\"] for r in config_results])\n",
    "#     avg_progress = np.mean([r[\"progress\"] for r in config_results])\n",
    "#     avg_invalids = np.mean([r[\"total_invalids\"] for r in config_results])\n",
    "#     stuck = sum(1 for r in config_results if r[\"result\"] == \"ongoing\")\n",
    "#     wr = wins / num_games * 100\n",
    "\n",
    "#     per_config_stats[config_key] = {\n",
    "#         \"label\": label, \"wins\": wins, \"fails\": fails, \"stuck\": stuck,\n",
    "#         \"total\": num_games, \"win_rate\": wr,\n",
    "#         \"avg_moves\": avg_moves, \"avg_progress\": avg_progress,\n",
    "#     }\n",
    "\n",
    "#     status_icon = \"✅\" if wr >= 50 else \"⚠️\" if wr >= 20 else \"❌\"\n",
    "#     print(f\"  {status_icon} {label:22s} ({config_key:12s}): \"\n",
    "#           f\"{wins:2d}/{num_games:2d} wins ({wr:5.1f}%) | \"\n",
    "#           f\"fails={fails} stuck={stuck} | \"\n",
    "#           f\"moves={avg_moves:5.1f} | logical={avg_logical:4.1f} | \"\n",
    "#           f\"progress={avg_progress:.0%} | invalids={avg_invalids:.1f}\")\n",
    "\n",
    "# # ── Overall Summary ──\n",
    "# total_games_actual = len(all_results)\n",
    "# total_wins = sum(1 for r in all_results if r[\"result\"] == \"success\")\n",
    "# total_fails = sum(1 for r in all_results if r[\"result\"] == \"failed\")\n",
    "# total_stuck = sum(1 for r in all_results if r[\"result\"] == \"ongoing\")\n",
    "# fc = sum(r[\"flags_correct\"] for r in all_results)\n",
    "# fw = sum(r[\"flags_wrong\"] for r in all_results)\n",
    "\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"  OVERALL: {total_wins}/{total_games_actual} wins ({total_wins/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"{'='*80}\")\n",
    "# print(f\"  Wins (success):    {total_wins:4d} ({total_wins/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"  Losses (failure):  {total_fails:4d} ({total_fails/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"  Stuck (loop cap):  {total_stuck:4d} ({total_stuck/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"  Avg moves:         {np.mean([r['moves'] for r in all_results]):.1f}\")\n",
    "# print(f\"  Avg progress:      {np.mean([r['progress'] for r in all_results]):.0%}\")\n",
    "# print(f\"  Avg logical moves: {np.mean([r['logical_moves'] for r in all_results]):.1f}\")\n",
    "# if fc + fw > 0:\n",
    "#     print(f\"  Flag accuracy:     {fc}/{fc+fw} ({fc/(fc+fw)*100:.1f}%)\")\n",
    "# else:\n",
    "#     print(f\"  Flags: none placed\")\n",
    "\n",
    "# # ── Category Breakdown ──\n",
    "# categories = {\n",
    "#     \"Trivial (0 mines)\": [k for k, v in per_config_stats.items() if \"m0\" in k],\n",
    "#     \"Tiny (≤4x4)\":       [k for k, v in per_config_stats.items()\n",
    "#                            if v[\"label\"].startswith((\"3x3\", \"4x4\")) and \"m0\" not in k],\n",
    "#     \"Small (5x5)\":       [k for k, v in per_config_stats.items() if k.startswith(\"5x5\")],\n",
    "#     \"Standard (6x6)\":    [k for k, v in per_config_stats.items() if k.startswith(\"6x6\")],\n",
    "#     \"Medium (7-8)\":      [k for k, v in per_config_stats.items()\n",
    "#                            if k.startswith((\"7x7\", \"8x8\"))],\n",
    "#     \"Large (10-15)\":     [k for k, v in per_config_stats.items()\n",
    "#                            if k.startswith((\"10x10\", \"15x15\"))],\n",
    "#     \"XL (20-50)\":        [k for k, v in per_config_stats.items()\n",
    "#                            if k.startswith((\"20x20\", \"25x25\", \"30x30\", \"40x40\", \"50x50\"))],\n",
    "#     \"Rectangular\":       [k for k, v in per_config_stats.items()\n",
    "#                            if \"rect\" in v[\"label\"] or \"row\" in v[\"label\"]\n",
    "#                            or \"column\" in v[\"label\"] or \"wide\" in v[\"label\"]\n",
    "#                            or \"tall\" in v[\"label\"]],\n",
    "#     \"Sparse\":            [k for k, v in per_config_stats.items() if \"sparse\" in v[\"label\"]],\n",
    "#     \"Progressive\":       [k for k, v in per_config_stats.items()\n",
    "#                            if \"progressive\" in v[\"label\"] or \"generalization\" in v[\"label\"]\n",
    "#                            or \"density\" in v[\"label\"]],\n",
    "# }\n",
    "\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"  CATEGORY BREAKDOWN\")\n",
    "# print(f\"{'='*80}\")\n",
    "# for cat_name, keys in categories.items():\n",
    "#     if not keys:\n",
    "#         continue\n",
    "#     cat_wins = sum(per_config_stats[k][\"wins\"] for k in keys)\n",
    "#     cat_total = sum(per_config_stats[k][\"total\"] for k in keys)\n",
    "#     if cat_total > 0:\n",
    "#         cat_wr = cat_wins / cat_total * 100\n",
    "#         icon = \"✅\" if cat_wr >= 50 else \"⚠️\" if cat_wr >= 20 else \"❌\"\n",
    "#         print(f\"  {icon} {cat_name:22s}: {cat_wins:3d}/{cat_total:3d} ({cat_wr:5.1f}%)\")\n",
    "# print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306cc45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Save the Model\n",
    "\n",
    "Save your trained model for competition submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LoRA adapters\n",
    "model.save_pretrained(\"my_minesweeper_model\")\n",
    "tokenizer.save_pretrained(\"my_minesweeper_model\")\n",
    "print(\"✅ LoRA adapters saved to: my_minesweeper_model/\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Save merged model in 16bit\n",
    "# Workaround for Unsloth bug: UnboundLocalError on 'copied_tokenizer_model_from_cache'\n",
    "# when using local model paths. We manually merge LoRA weights and save with HF API.\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "import os, shutil, gc\n",
    "\n",
    "merged_dir = \"my_minesweeper_model_merged\"\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Try Unsloth's native method first (works on some versions)\n",
    "    model.save_pretrained_merged(\n",
    "        merged_dir,\n",
    "        tokenizer,\n",
    "        save_method=\"merged_16bit\",\n",
    "    )\n",
    "    print(\"✅ Merged 16-bit model saved via Unsloth\")\n",
    "except (UnboundLocalError, Exception) as e:\n",
    "    print(f\"⚠️ Unsloth merge failed ({type(e).__name__}: {e})\")\n",
    "    print(\"   Falling back to manual LoRA merge...\")\n",
    "\n",
    "    try:\n",
    "        # Manual merge: get the PEFT model, merge LoRA into base weights, save\n",
    "        from peft import PeftModel\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "        # Re-load base model in float16 for merge\n",
    "        print(\"   Loading base model for merge...\")\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"/workspace/workspace/Qwen2.5-14B-Instruct\",\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        # Load LoRA adapters on top\n",
    "        print(\"   Applying LoRA adapters...\")\n",
    "        merged_model = PeftModel.from_pretrained(base_model, \"my_minesweeper_model\")\n",
    "        merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "        # Save the fully merged model\n",
    "        print(\"   Saving merged model...\")\n",
    "        merged_model.save_pretrained(merged_dir, safe_serialization=True)\n",
    "        tokenizer.save_pretrained(merged_dir)\n",
    "\n",
    "        # Cleanup\n",
    "        del base_model, merged_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"✅ Merged 16-bit model saved to: {merged_dir}/\")\n",
    "\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ BOTH merge methods failed!\")\n",
    "        print(f\"   Unsloth error: {e}\")\n",
    "        print(f\"   Manual merge error: {e2}\")\n",
    "        print(f\"   LoRA adapters are still saved at: my_minesweeper_model/\")\n",
    "        print(f\"   You can merge manually later with:\")\n",
    "        print(f\"     from peft import PeftModel\")\n",
    "        print(f\"     base = AutoModelForCausalLM.from_pretrained('<base_model_path>')\")\n",
    "        print(f\"     merged = PeftModel.from_pretrained(base, 'my_minesweeper_model')\")\n",
    "        print(f\"     merged = merged.merge_and_unload()\")\n",
    "        print(f\"     merged.save_pretrained('{merged_dir}')\")\n",
    "\n",
    "# Verify saved files\n",
    "saved_files = os.listdir(merged_dir)\n",
    "safetensors = [f for f in saved_files if f.endswith(\".safetensors\")]\n",
    "print(f\"   Files: {len(saved_files)} total, {len(safetensors)} safetensors shards\")\n",
    "print(f\"   Config: {'config.json' in saved_files}  Tokenizer: {'tokenizer.json' in saved_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaed02d",
   "metadata": {},
   "source": [
    "# Inference from Merged Model\n",
    "\n",
    "Load the saved merged model from disk (no LoRA, no Unsloth) and verify it works for Minesweeper inference.\n",
    "This tests that the model was saved correctly and can be loaded independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Load merged model from disk for inference testing\n",
    "# No Unsloth, no LoRA — pure HuggingFace transformers\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "import torch, gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "merged_dir = \"my_minesweeper_model_merged\"\n",
    "\n",
    "print(f\"Loading merged model from: {merged_dir}/\")\n",
    "print(\"  (This is a standalone model — no LoRA adapters needed)\")\n",
    "\n",
    "# Load tokenizer\n",
    "merged_tokenizer = AutoTokenizer.from_pretrained(merged_dir)\n",
    "print(f\"  ✅ Tokenizer loaded ({merged_tokenizer.vocab_size} vocab)\")\n",
    "\n",
    "# Load model\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "merged_model.eval()\n",
    "print(f\"  ✅ Model loaded on {merged_model.device}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in merged_model.parameters()):,}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Run inference on a diverse set of Minesweeper boards\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "test_configs = [\n",
    "    (1, 1, 0, 300, \"1×1 Trivial\"),\n",
    "    (3, 3, 1, 301, \"Tiny 3×3\"),\n",
    "    (5, 5, 3, 302, \"Small 5×5\"),\n",
    "    (6, 6, 5, 99,  \"Standard 6×6\"),\n",
    "    (8, 8, 10, 303, \"Medium 8×8\"),\n",
    "    (10, 10, 20, 304, \"Large 10×10\"),\n",
    "    (15, 15, 45, 305, \"XL 15×15\"),\n",
    "    (1, 20, 4, 306, \"Linear 1×20\"),\n",
    "    (5, 5, 0, 307, \"Zero Mines 5×5\"),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  MERGED MODEL INFERENCE TEST — {len(test_configs)} boards\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "results = {\"pass\": 0, \"fail\": 0, \"skip\": 0}\n",
    "\n",
    "for rows, cols, mines, seed, label in test_configs:\n",
    "    print(f\"\\n--- {label} ({rows}×{cols}, {mines} mines, seed={seed}) ---\")\n",
    "\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        print(f\"  Game auto-resolved: {game.state()}\")\n",
    "        results[\"skip\"] += 1\n",
    "        continue\n",
    "\n",
    "    # Build prompt using the same inference prompt system\n",
    "    prompt = format_state_for_llm(game, mode=\"inference\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    text = merged_tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = merged_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(merged_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = merged_model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.7,       # LAMER paper: 0.7 for eval\n",
    "            max_new_tokens=128,    # HACKATHON CONSTRAINT: JSON-only\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "        )\n",
    "\n",
    "    # Decode only generated tokens (not the prompt)\n",
    "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response = merged_tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "    print(f\"  Response: {response[:200]}{'...' if len(response) > 200 else ''}\")\n",
    "\n",
    "    action = parse_llm_action(response)\n",
    "    print(f\"  Parsed:   {action}\")\n",
    "\n",
    "    if action:\n",
    "        result = game.do_action(action)\n",
    "        state = game.state()\n",
    "        print(f\"  Result:   {result} → game {state}\")\n",
    "        if result != \"mine\":\n",
    "            results[\"pass\"] += 1\n",
    "        else:\n",
    "            results[\"fail\"] += 1\n",
    "    else:\n",
    "        print(f\"  ⚠️ Failed to parse valid action\")\n",
    "        results[\"fail\"] += 1\n",
    "\n",
    "# ── Summary ──\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  INFERENCE TEST SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Pass (valid move): {results['pass']}/{results['pass'] + results['fail']}\")\n",
    "print(f\"  Fail (bad parse/mine): {results['fail']}\")\n",
    "print(f\"  Skipped (auto-win): {results['skip']}\")\n",
    "total = results['pass'] + results['fail']\n",
    "if total > 0:\n",
    "    print(f\"  Success rate: {results['pass']/total*100:.1f}%\")\n",
    "print(f\"\\n✅ Merged model inference test complete!\")\n",
    "print(f\"   Model path: {merged_dir}/\")\n",
    "print(f\"   Ready for competition submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c190f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Fixes & Improvements Applied\n",
    "\n",
    "## 4-Paper Hybrid Integration (LAMER + XRPO + GRPO-LEAD + S-GRPO)\n",
    "\n",
    "### Paper 1: LAMER — Meta-RL for Language Agents (74% win rate on MineSweeper)\n",
    "| LAMER Finding | Implementation |\n",
    "|---------------|----------------|\n",
    "| ReAct prompting (Reason + Act) | Explicit \"think step-by-step before acting\" in system prompt |\n",
    "| Pre-computed logical hints (CoT) | SAFE/MINE cell lists injected into every prompt |\n",
    "| Center-opening strategy | Reward center on dense boards (>10%), penalize edges/corners |\n",
    "| `temperature=1.0` for training | Full exploration during GRPO generation |\n",
    "| `temperature=0.7` for eval | LAMER paper eval temperature |\n",
    "| `num_iterations=2` | LAMER paper: 2 GRPO iterations for MineSweeper |\n",
    "| STEP 1/STEP 2 reasoning | Satisfied/constrained number scanning |\n",
    "\n",
    "### Paper 2: XRPO — Adaptive Exploration with Difficulty Reweighting\n",
    "| XRPO Finding | Implementation |\n",
    "|--------------|----------------|\n",
    "| Difficulty reweighting | `_difficulty_multiplier()` → harder boards get amplified reward signal (×0.7–×1.5) |\n",
    "| Exploration heuristic | STEP 4 in prompt: prefer high-info cells, low numbers, avoid edges |\n",
    "| Novelty bonus concept | Implicit: difficulty multiplier serves similar purpose (hard=novel→stronger signal) |\n",
    "| Adaptive difficulty proxy | `0.6 × density/0.20 + 0.4 × log(size)/log(2500)` → sigmoid multiplier |\n",
    "| Safety check | Returns 1.0 for 0-mine boards and degenerate cases (Fix #2) |\n",
    "\n",
    "### Paper 3: GRPO-LEAD — Length Penalty & Explicit Wrong Penalty\n",
    "| GRPO-LEAD Finding | Implementation |\n",
    "|-------------------|----------------|\n",
    "| Group-normalized length penalty | 2-pass z-score normalization across correct responses (Fix #6) |\n",
    "| ≤200 token response cap | Instruction in training prompt: \"Total response ≤ 200 tokens\" |\n",
    "| Explicit wrong penalty | Mine reveal: -26 (was -25), wrong flag: -11 (was -10) |\n",
    "| Lower learning rate | `5e-6` (was `2e-5`) for stability with penalty terms |\n",
    "| Concise reasoning | \"2-3 sentences max\" instruction in prompt output format |\n",
    "\n",
    "### Paper 4: S-GRPO — Early Exit When Solution Found\n",
    "| S-GRPO Finding | Implementation |\n",
    "|----------------|----------------|\n",
    "| Early exit instruction | \"Once you find a logical move in Steps 1-3, STOP reasoning and output it immediately\" |\n",
    "| Reduced wasted tokens | Combined with GRPO-LEAD length penalty → shorter, focused responses |\n",
    "| Step-ordered deduction | Steps 1→2→3→4 with explicit \"stop when found\" at each logical step |\n",
    "\n",
    "## Robustness Fixes (Latest Session)\n",
    "| # | Issue | Fix | Priority |\n",
    "|---|-------|-----|----------|\n",
    "| 1 | Infinite loops in `_play_smart_moves()` | `stuck_count` with `MAX_STUCK=10` — break after 10 failed attempts | P0 |\n",
    "| 2 | Div-by-zero in `_difficulty_multiplier()` | Safety check: return 1.0 for `board_size==0` or `num_mines==0` | P3 |\n",
    "| 3 | Missing one-cell-left endgame hint | Compute exact last cell coords, inject `CRITICAL` hint with specific action | P2 |\n",
    "| 4 | Model repeating same valid move forever | `seen_actions` set + `repeat_count` in eval callback & `play_full_game` — break after 3 repeats | P1 |\n",
    "| 6 | Wrong length penalty (absolute not group) | 2-pass GRPO-LEAD: z-score normalize lengths across correct responses, clamp multiplier [0.5, 1.5] | P1 |\n",
    "| 9 | Manual merge fallback had no error handling | Nested try/except — if both Unsloth & PEFT merge fail, print recovery instructions | P3 |\n",
    "| 10 | No progressive difficulty in eval suite | Added 6 configs: same-size density scaling + same-density size scaling + generalization tests | P3 |\n",
    "\n",
    "## 50×50 Board Scalability Fixes\n",
    "| # | Issue | Fix | Impact |\n",
    "|---|-------|-----|--------|\n",
    "| S1 | Token budget mismatch (1900+128=2028, no room for reasoning) | Rebalanced to 1792+256=2048 exact fit | 50×50 Format C (~1335 tokens) fits with 457 token margin for reasoning |\n",
    "| S2 | Large boards only 10% of training data (sizes 1-50) | Boosted to 15% at sizes 30-50; bands now 25/20/20/20/15 | 3× more large board training samples |\n",
    "| S3 | Flat +100 win bonus regardless of board size | Scaled: `100 × (1 + min(1, board_size/1000))` — 50×50→+250, 6×6→+104 | Model motivated to complete large boards |\n",
    "| S4 | Eval `max_iterations` too high (rows*cols*3 = 7500 for 50×50) | Capped to `min(500, rows*cols+100)` | Prevents runaway 50×50 eval loops |\n",
    "| S5 | All eval/inference used `max_new_tokens=128` | Reverted to 128 everywhere — HACKATHON CONSTRAINT: JSON-only output, no reasoning | Pure JSON action is ~10-25 tokens, well under 128 limit |\n",
    "\n",
    "## Exhaustive Dataset Generation\n",
    "| Feature | Details |\n",
    "|---------|---------|\n",
    "| Total samples | 4000 (was 3000) |\n",
    "| Edge cases | 50+ configs (was 25) — trivial, linear, rectangular, density extremes |\n",
    "| Opening training | 25% fresh/single-move boards — train safe opening strategies |\n",
    "| Pattern-specific | 15% — satisfied-number boards + multi-region disconnected boards |\n",
    "| Mid-game deduction | 25% — 3-15 moves, progressive flagging 10%→30%→50% |\n",
    "| Endgame completion | 15% — 80-98% revealed — flag accounting, finish strategy |\n",
    "| Forced guess | 10% — no logical deductions available |\n",
    "| Progressive flagging | 10% early → 30% mid → 50% late |\n",
    "| Density stratification | 8% zero, 17% very sparse, 25% sparse, 25% medium, 25% dense |\n",
    "| Stuck prevention | `MAX_STUCK=10` in `_play_smart_moves()` (Fix #1) |\n",
    "\n",
    "## Prompt System (Hybrid: 4-Paper Master Template)\n",
    "| Feature | Paper Source | Implementation |\n",
    "|---------|-------------|----------------|\n",
    "| ReAct reasoning | LAMER | \"Think step-by-step → STEP 1-4 → Act\" |\n",
    "| Pattern recognition | XRPO | STEP 3: 1-2-1 line, 1-1 corner, zero cascade |\n",
    "| Forced-guess heuristic | XRPO | STEP 4: prefer high-info cells, low numbers, avoid edges |\n",
    "| Early exit | S-GRPO | \"Once you find a logical move in Steps 1-3, STOP\" |\n",
    "| Length control | GRPO-LEAD | \"Total response ≤ 200 tokens\", \"2-3 sentences max\" |\n",
    "| 3-tier board format | Custom | A (≤20): full grid, B (21-35): frontier, C (36-50): summary |\n",
    "| Phase-aware prompts | LAMER | Opening (center), Mid-game (deduction), Endgame (flag accounting) |\n",
    "| Edge case guidance | Custom | 0-mine, linear, tiny, large, high-density, all-flagged, last-cell |\n",
    "| One-cell-left hint | Fix #3 | Computes exact cell coords → \"Reveal (r,c) to WIN!\" or \"Flag (r,c)!\" |\n",
    "| All-remaining-mines | Fix #3 | \"ALL REMAINING N CELLS ARE MINES: Flag any!\" |\n",
    "| Inference variant | LAMER | ~60% shorter for eval/test |\n",
    "\n",
    "## Reward System (3 Functions, Hybrid)\n",
    "| Reward | Weight | Paper Enhancements |\n",
    "|--------|--------|-------------------|\n",
    "| `valid_json_reward` | 0.20 | GRPO-LEAD: group-normalized z-score length penalty (Fix #6) |\n",
    "| `gameplay_scores` | 0.65 | XRPO: difficulty reweighting (×0.7–×1.5), GRPO-LEAD: explicit wrong penalty |\n",
    "| `strategic_reward` | 0.15 | XRPO: difficulty reweighting, LAMER: center-opening |\n",
    "\n",
    "## Evaluation System\n",
    "| Feature | Details |\n",
    "|---------|---------|\n",
    "| Eval callback | 10 configs every 50 steps, temp=0.7, stuck detection (Fix #4) |\n",
    "| Exhaustive eval | 43+ configs (was 37), 1×1 to 50×50 |\n",
    "| Progressive difficulty | Same-size density scaling + same-density size scaling (Fix #10) |\n",
    "| Generalization test | 25×25 10%, 30×30 10% — harder unseen configs |\n",
    "| Stuck detection | Repeated action tracking — break after 3 same-move repeats (Fix #4) |\n",
    "| Category breakdown | Trivial, Tiny, Small, Standard, Medium, Large, XL, Rectangular, Sparse, Progressive |\n",
    "\n",
    "## Training Config (Hybrid Hyperparameters)\n",
    "| Parameter | Value | Source |\n",
    "|-----------|-------|--------|\n",
    "| temperature | 1.0 (train), 0.7 (eval) | LAMER |\n",
    "| learning_rate | 5e-6 | GRPO-LEAD (reduced for stability) |\n",
    "| num_iterations | 2 | LAMER |\n",
    "| beta (KL) | 0.04 | LAMER |\n",
    "| reward_weights | [0.20, 0.65, 0.15] | Hybrid (format↑ for length penalty) |\n",
    "| max_completion_length | 128 | GRPO-LEAD (length control) |\n",
    "| max_grad_norm | 0.5 | Gradient clipping for stability |\n",
    "| warmup_ratio | 0.05 | Stable early training |\n",
    "\n",
    "## Model Save & Inference\n",
    "| Feature | Details |\n",
    "|---------|---------|\n",
    "| LoRA save | `my_minesweeper_model/` — always succeeds |\n",
    "| Merged save | Try Unsloth → fallback PEFT merge → error recovery instructions (Fix #9) |\n",
    "| Merged inference | Standalone HF transformers load — no Unsloth/LoRA needed |\n",
    "| Inference test | 9 diverse boards, pass/fail summary |\n",
    "\n",
    "## Competition Spec Compliance\n",
    "| Requirement | Implementation |\n",
    "|-------------|---------------|\n",
    "| Board rows: 1–50 | `MIN_ROWS=1, MAX_ROWS=50` in game engine |\n",
    "| Board cols: 1–50 | `MIN_COLS=1, MAX_COLS=50` in game engine |\n",
    "| Mines: 0–20% of cells | `MAX_MINE_DENSITY=0.20`, 0 mines allowed |\n",
    "| No move limit | Only success/failure |\n",
    "| Success = all safe revealed | `_check_win()` checks `len(revealed) >= safe_cells` |\n",
    "| Failure = mine revealed | Only `_reveal_cell` hitting mine sets `_state=\"failed\"` |\n",
    "| max_new_tokens: 128 | `max_completion_length=128` in GRPOConfig |\n",
    "\n",
    "## Critical Bugs Fixed (Previous Sessions)\n",
    "| # | Bug | Fix |\n",
    "|---|-----|-----|\n",
    "\n",
    "| 1 | `do_action()` set `_state=\"failed\"` for ALL invalid moves | Only `mine` sets state to \"failed\" |\n",
    "| 8 | Random flags in training data | `_smart_flag()` only flags logically certain mines || 9 | Reward scale imbalance | Rebalanced: JSON=-10, mine=-26, win=+100 |\n",
    "\n",
    "| 2 | Reward functions signature mismatch with TRL GRPOTrainer | `(prompts, completions, **kwargs)` |\n",
    "| 9 | Reward scale imbalance | Rebalanced: JSON=-10, mine=-26, win=+100 || 8 | Random flags in training data | `_smart_flag()` only flags logically certain mines |\n",
    "\n",
    "| 3 | Hardcoded board size in rewards | `_reconstruct_game()` reads from kwargs || 7 | `remove_unused_columns` not set | Explicitly `False` |\n",
    "\n",
    "| 4 | `max_prompt_length=700` truncated prompts | Increased to 1900 || 6 | Eval decoded full output including prompt | Decodes only generated tokens |\n",
    "| 5 | Separate O(n²) passes for safe/mine cells | Combined single pass |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46952a1e-915d-4b2f-872a-2ad2d70a7155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09751230-51dc-4997-8b7b-3c87e9773895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45016553-eaa9-4a9e-9e8b-dec9ee50b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e08ad44-0c9a-498e-8b3f-7629d447b6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b786fbd-c069-454d-a1f9-7625b7bd87e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f393470-7ac1-4ce4-9508-d3a91fbe43ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e729a-7064-4928-a991-7da14ea4d087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b591455-067f-42db-bff0-5ccf0eef3ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42152a4-09c5-433b-beb7-21e406915e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc480f-a720-46cc-870a-d0175d97711a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
