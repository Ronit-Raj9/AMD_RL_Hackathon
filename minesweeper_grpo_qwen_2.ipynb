{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48060c32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper LLM Competition - Custom GRPO Training\n",
    "\n",
    "## Goal\n",
    "Finetune an LLM with LoRA using GRPO to play Minesweeper by:\n",
    "- **Input**: JSON game state (board configuration)\n",
    "- **Output**: JSON action (reveal or flag a cell)\n",
    "\n",
    "Teams will compete to train the best Minesweeper-playing LLM!\n",
    "\n",
    "## Training Approach\n",
    "- **Model**: Qwen2.5-14B-Instruct (from /root/.cache/huggingface/hub)\n",
    "- **Method**: GRPO (Group Relative Policy Optimization)\n",
    "- **Framework**: Unsloth (2-6x faster, 70% less VRAM)\n",
    "- **Hardware**: AMD MI300X GPU (192GB HBM3, ROCm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c2e56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load Model with Unsloth\n",
    "\n",
    "Load Qwen3-4B with LoRA configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1118e-9532-4aa3-a4eb-ecf1bb2abb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"./workspace/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecb51d-67e6-42e4-b739-cea6e57ab2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"unsloth/Qwen2.5-14B-Instruct\",\n",
    "    local_dir=\"./workspace/Qwen2.5-14B-Instruct\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af32493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "# Load config\n",
    "with open(\"minesweeper_config_me.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "lora_rank = config.get(\"lora_rank\", 32)\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"/workspace/workspace/Qwen2.5-14B-Instruct\",\n",
    "    load_in_4bit=False,   # AMD → 4bit disabled\n",
    "    max_seq_length=2048,  # Increased: larger boards need longer prompts\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Device: {model.device}\")\n",
    "print(f\"LoRA rank: {lora_rank} (from config)\")\n",
    "\n",
    "# ── Add newline as EOS token so generation stops after first JSON line ──\n",
    "# (replaces stop_strings which isn't supported by this GRPOConfig version)\n",
    "newline_token_id = tokenizer.encode(\"\\n\", add_special_tokens=False)[-1]\n",
    "original_eos = tokenizer.eos_token_id\n",
    "if original_eos != newline_token_id:\n",
    "    model.generation_config.eos_token_id = [original_eos, newline_token_id]\n",
    "    model.config.eos_token_id = [original_eos, newline_token_id]\n",
    "    print(f\"  ✅ Added newline (token {newline_token_id}) as additional EOS → stops after JSON line\")\n",
    "    print(f\"     EOS tokens: {model.generation_config.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f0712",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Add LoRA Adapters\n",
    "\n",
    "Add LoRA layers for efficient finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank,           # alpha = rank → scaling factor = 1.0 (stable training)\n",
    "    lora_dropout = 0.05,              # Small dropout for regularization\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "print(f\"LoRA config: rank={lora_rank}, alpha={lora_rank}, dropout=0.05\")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503f9af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper Game Implementation\n",
    "\n",
    "Custom Minesweeper environment supporting:\n",
    "- Customizable board size and mine count\n",
    "- Actions: reveal or flag cells\n",
    "- Win: reveal all safe cells\n",
    "- Lose: reveal a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Set\n",
    "import random\n",
    "import math\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Board size configuration — competition spec: n,m ∈ [1,50], mines 0-20%\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Constants\n",
    "MIN_ROWS, MAX_ROWS = 1, 50\n",
    "MIN_COLS, MAX_COLS = 1, 50\n",
    "MIN_MINE_DENSITY = 0.0    # 0% mines allowed (trivial board)\n",
    "MAX_MINE_DENSITY = 0.20   # 20% of total cells\n",
    "\n",
    "\n",
    "def sample_board_config(rng=None):\n",
    "    \"\"\"Sample a random (rows, cols, num_mines) from the full competition range.\n",
    "\n",
    "    - rows ∈ [1, 50], cols ∈ [1, 50]\n",
    "    - mines ∈ [0, floor(0.20 * rows * cols)]\n",
    "    - Uses a weighted distribution favoring smaller boards during training\n",
    "      (large boards are rare but included for coverage).\n",
    "    \"\"\"\n",
    "    rng = rng or random.Random()\n",
    "\n",
    "    # Weighted size distribution: favor small/medium, still cover large\n",
    "    size_band = rng.random()\n",
    "    if size_band < 0.30:\n",
    "        # Small: 1-8\n",
    "        rows = rng.randint(1, 8)\n",
    "        cols = rng.randint(1, 8)\n",
    "    elif size_band < 0.55:\n",
    "        # Medium: 5-15\n",
    "        rows = rng.randint(5, 15)\n",
    "        cols = rng.randint(5, 15)\n",
    "    elif size_band < 0.75:\n",
    "        # Large: 10-30\n",
    "        rows = rng.randint(10, 30)\n",
    "        cols = rng.randint(10, 30)\n",
    "    elif size_band < 0.90:\n",
    "        # XL: 20-40\n",
    "        rows = rng.randint(20, 40)\n",
    "        cols = rng.randint(20, 40)\n",
    "    else:\n",
    "        # Full range: 1-50 (including extreme cases)\n",
    "        rows = rng.randint(1, 50)\n",
    "        cols = rng.randint(1, 50)\n",
    "\n",
    "    total = rows * cols\n",
    "    max_mines = int(total * MAX_MINE_DENSITY)  # floor(0.20 * total)\n",
    "\n",
    "    if max_mines == 0:\n",
    "        num_mines = 0  # Boards too small for any mines at ≤20%\n",
    "    else:\n",
    "        num_mines = rng.randint(0, max_mines)\n",
    "\n",
    "    return rows, cols, num_mines\n",
    "\n",
    "\n",
    "def mine_density(rows, cols, num_mines):\n",
    "    \"\"\"Compute mine density as a fraction.\"\"\"\n",
    "    total = rows * cols\n",
    "    return num_mines / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MinesweeperGame:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    num_mines: int\n",
    "    seed: Optional[int] = None\n",
    "    _rng: random.Random = field(init=False, repr=False)\n",
    "    _board: List[List[int]] = field(init=False, repr=False)  # -1 = mine, 0-8 = count\n",
    "    _revealed: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _flagged: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _state: str = field(default=\"ongoing\", init=False, repr=False)\n",
    "    _move_count: int = field(default=0, init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # ── Input validation — competition spec: n,m ∈ [1,50] ──\n",
    "        if self.rows < MIN_ROWS or self.cols < MIN_COLS:\n",
    "            raise ValueError(f\"Board too small: {self.rows}x{self.cols} (min {MIN_ROWS}x{MIN_COLS})\")\n",
    "        if self.rows > MAX_ROWS or self.cols > MAX_COLS:\n",
    "            raise ValueError(f\"Board too large: {self.rows}x{self.cols} (max {MAX_ROWS}x{MAX_COLS})\")\n",
    "        if self.num_mines < 0:\n",
    "            raise ValueError(f\"num_mines cannot be negative, got {self.num_mines}\")\n",
    "        if self.num_mines >= self.rows * self.cols:\n",
    "            raise ValueError(f\"Too many mines ({self.num_mines}) for {self.rows}x{self.cols} board\")\n",
    "        # 0 mines is allowed — trivial board, instant win on first reveal cascade\n",
    "\n",
    "        self._rng = random.Random(self.seed)\n",
    "        self._board = [[0 for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "        self._place_mines()\n",
    "        self._calculate_numbers()\n",
    "\n",
    "        # ── Edge case: 0 mines → all cells are safe, auto-win on init check ──\n",
    "        self._check_win()\n",
    "\n",
    "    def _place_mines(self):\n",
    "        \"\"\"Place mines randomly on the board.\"\"\"\n",
    "        if self.num_mines == 0:\n",
    "            return  # No mines to place\n",
    "        positions = [(r, c) for r in range(self.rows) for c in range(self.cols)]\n",
    "        mine_positions = self._rng.sample(positions, self.num_mines)\n",
    "        for r, c in mine_positions:\n",
    "            self._board[r][c] = -1\n",
    "\n",
    "    def _calculate_numbers(self):\n",
    "        \"\"\"Calculate numbers for each cell based on adjacent mines.\"\"\"\n",
    "        for r in range(self.rows):\n",
    "            for c in range(self.cols):\n",
    "                if self._board[r][c] == -1:\n",
    "                    continue\n",
    "                count = 0\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if 0 <= nr < self.rows and 0 <= nc < self.cols:\n",
    "                            if self._board[nr][nc] == -1:\n",
    "                                count += 1\n",
    "                self._board[r][c] = count\n",
    "\n",
    "    def _reveal_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Reveal a cell. Returns True if valid move, False if invalid.\n",
    "        Uses iterative flood-fill to avoid recursion limit on large boards.\n",
    "        \"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed or (row, col) in self._flagged:\n",
    "            return False\n",
    "\n",
    "        stack = [(row, col)]\n",
    "        while stack:\n",
    "            r, c = stack.pop()\n",
    "            if (r, c) in self._revealed:\n",
    "                continue\n",
    "\n",
    "            self._revealed.add((r, c))\n",
    "\n",
    "            # Hit a mine!\n",
    "            if self._board[r][c] == -1:\n",
    "                self._state = \"failed\"\n",
    "                return True\n",
    "\n",
    "            # Auto-reveal neighbors if cell is 0\n",
    "            if self._board[r][c] == 0:\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < self.rows and 0 <= nc < self.cols\n",
    "                                and (nr, nc) not in self._revealed\n",
    "                                and (nr, nc) not in self._flagged):\n",
    "                            stack.append((nr, nc))\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _flag_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Flag/unflag a cell. Returns True if valid, False if invalid.\"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed:\n",
    "            return False\n",
    "\n",
    "        if (row, col) in self._flagged:\n",
    "            self._flagged.remove((row, col))\n",
    "        else:\n",
    "            self._flagged.add((row, col))\n",
    "        return True\n",
    "\n",
    "    def do_action(self, action: dict) -> str:\n",
    "        \"\"\"Execute an action and return a status string.\n",
    "\n",
    "        Returns one of:\n",
    "          'ok'               - valid move executed\n",
    "          'mine'             - revealed a mine (game over → state='failed')\n",
    "          'win'              - game won after this move (all safe cells revealed)\n",
    "          'invalid_format'   - bad action dict / missing keys / bad types\n",
    "          'out_of_bounds'    - coordinates outside the board\n",
    "          'already_revealed' - cell was already revealed\n",
    "          'flagged_cell'     - tried to reveal a flagged cell\n",
    "          'invalid_flag'     - tried to flag a revealed cell\n",
    "          'game_over'        - game was already over before this call\n",
    "\n",
    "        Only 'mine' sets state='failed'. All other invalid moves\n",
    "        return an error string but keep the game 'ongoing'.\n",
    "        NO move limit — game continues until success or failure.\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return \"game_over\"\n",
    "\n",
    "        if not isinstance(action, dict):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        action_type = action.get(\"type\")\n",
    "        row = action.get(\"row\")\n",
    "        col = action.get(\"col\")\n",
    "\n",
    "        if action_type not in (\"reveal\", \"flag\") or row is None or col is None:\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        try:\n",
    "            row, col = int(row), int(col)\n",
    "        except (ValueError, TypeError):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return \"out_of_bounds\"\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"already_revealed\"\n",
    "            if (row, col) in self._flagged:\n",
    "                return \"flagged_cell\"\n",
    "            self._reveal_cell(row, col)\n",
    "            self._move_count += 1\n",
    "        else:  # flag\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"invalid_flag\"\n",
    "            self._flag_cell(row, col)\n",
    "            self._move_count += 1\n",
    "\n",
    "        self._check_win()\n",
    "\n",
    "        if self._state == \"failed\":\n",
    "            return \"mine\"\n",
    "        if self._state == \"success\":\n",
    "            return \"win\"\n",
    "        return \"ok\"\n",
    "\n",
    "    def _check_win(self):\n",
    "        \"\"\"Check if player has won.\n",
    "\n",
    "        Win condition: ALL safe (non-mine) cells are revealed.\n",
    "        With 0 mines, ALL cells are safe → need to reveal every cell.\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return\n",
    "        total_cells = self.rows * self.cols\n",
    "        safe_cells = total_cells - self.num_mines\n",
    "        if safe_cells == 0:\n",
    "            self._state = \"success\"\n",
    "        elif len(self._revealed) >= safe_cells:\n",
    "            self._state = \"success\"\n",
    "\n",
    "    def get_visible_board(self) -> List[List[str]]:\n",
    "        \"\"\"Get board state as player sees it.\n",
    "        Uses '?' for unrevealed cells (competition standard).\n",
    "        \"\"\"\n",
    "        visible = []\n",
    "        for r in range(self.rows):\n",
    "            row = []\n",
    "            for c in range(self.cols):\n",
    "                if (r, c) in self._flagged:\n",
    "                    row.append('F')\n",
    "                elif (r, c) in self._revealed:\n",
    "                    val = self._board[r][c]\n",
    "                    row.append('*' if val == -1 else str(val))\n",
    "                else:\n",
    "                    row.append('?')\n",
    "            visible.append(row)\n",
    "        return visible\n",
    "\n",
    "    def state(self) -> str:\n",
    "        return self._state\n",
    "\n",
    "    @property\n",
    "    def move_count(self) -> int:\n",
    "        return self._move_count\n",
    "\n",
    "    def get_mine_positions(self) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"Return set of all mine positions (for reward computation).\"\"\"\n",
    "        return {(r, c) for r in range(self.rows) for c in range(self.cols)\n",
    "                if self._board[r][c] == -1}\n",
    "\n",
    "    def progress(self) -> float:\n",
    "        \"\"\"Fraction of safe cells revealed (0.0 to 1.0).\"\"\"\n",
    "        safe_cells = self.rows * self.cols - self.num_mines\n",
    "        return len(self._revealed) / safe_cells if safe_cells > 0 else 1.0\n",
    "\n",
    "    def game_phase(self) -> str:\n",
    "        \"\"\"Determine the current game phase for prompt selection.\"\"\"\n",
    "        if self._move_count == 0 and len(self._revealed) == 0:\n",
    "            return \"opening\"\n",
    "        prog = self.progress()\n",
    "        if prog >= 0.80:\n",
    "            return \"endgame\"\n",
    "        return \"midgame\"\n",
    "\n",
    "    def pretty_print(self) -> str:\n",
    "        \"\"\"Pretty print the board.\"\"\"\n",
    "        visible = self.get_visible_board()\n",
    "        lines = []\n",
    "\n",
    "        # Header — handle up to 2-digit column numbers\n",
    "        col_width = 3 if self.cols > 10 else 2\n",
    "        header = \"   \" + \" \".join(f\"{i:>{col_width-1}d}\" for i in range(self.cols))\n",
    "        lines.append(header)\n",
    "        lines.append(\"  \" + \"─\" * (self.cols * col_width + 1))\n",
    "\n",
    "        # Board\n",
    "        for r, row in enumerate(visible):\n",
    "            sep = \" \" * (col_width - 1)\n",
    "            line = f\"{r:2d}│ \" + sep.join(row)\n",
    "            lines.append(line)\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Sanity tests\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "print(\"Testing MinesweeperGame (competition spec: 1-50 boards, 0-20% mines)...\")\n",
    "\n",
    "# Basic gameplay\n",
    "g = MinesweeperGame(5, 5, 3, seed=0)\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": -1, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\", \"BUG: out_of_bounds should NOT end the game\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 99, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"flag\", \"row\": 0, \"col\": 0}) == \"ok\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0}) == \"flagged_cell\"\n",
    "assert g.state() == \"ongoing\", \"BUG: flagged_cell should NOT end the game\"\n",
    "assert g.do_action({}) == \"invalid_format\"\n",
    "assert g.state() == \"ongoing\", \"BUG: invalid_format should NOT end the game\"\n",
    "print(\"  ✅ do_action keeps game ongoing on invalid moves\")\n",
    "\n",
    "# Verify '?' is used for unrevealed cells\n",
    "board = g.get_visible_board()\n",
    "has_question = any('?' in row for row in board)\n",
    "assert has_question, \"Board should use '?' for unrevealed cells\"\n",
    "print(\"  ✅ Board uses '?' for unrevealed cells\")\n",
    "\n",
    "# Game phase tracking\n",
    "assert g.game_phase() == \"opening\" or g.move_count > 0\n",
    "print(\"  ✅ Game phase tracking works\")\n",
    "\n",
    "# ── Edge case: 0 mines board ──\n",
    "g0 = MinesweeperGame(3, 3, 0, seed=42)\n",
    "assert g0.state() == \"ongoing\"\n",
    "result = g0.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\", f\"0-mine board should win on first reveal, got {result}\"\n",
    "assert g0.state() == \"success\"\n",
    "print(\"  ✅ 0-mine board → instant win on first reveal\")\n",
    "\n",
    "# ── Edge case: 1x1 board with 0 mines ──\n",
    "g1x1 = MinesweeperGame(1, 1, 0, seed=42)\n",
    "assert g1x1.state() == \"ongoing\"\n",
    "result = g1x1.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\"\n",
    "print(\"  ✅ 1x1 board with 0 mines works\")\n",
    "\n",
    "# ── Edge case: 1x1 board — cannot have mines ──\n",
    "try:\n",
    "    MinesweeperGame(1, 1, 1, seed=42)\n",
    "    assert False, \"Should have raised ValueError\"\n",
    "except ValueError:\n",
    "    pass\n",
    "print(\"  ✅ 1x1 board with 1 mine correctly rejected\")\n",
    "\n",
    "# ── Edge case: 50x50 board ──\n",
    "g50 = MinesweeperGame(50, 50, 500, seed=42)\n",
    "assert g50.state() == \"ongoing\"\n",
    "assert g50.rows == 50 and g50.cols == 50\n",
    "assert mine_density(50, 50, 500) == 0.20\n",
    "print(\"  ✅ 50x50 board with 20% mines works\")\n",
    "\n",
    "# ── Edge cases: rectangular ──\n",
    "g1x50 = MinesweeperGame(1, 50, 10, seed=42)\n",
    "assert g1x50.rows == 1 and g1x50.cols == 50\n",
    "g50x1 = MinesweeperGame(50, 1, 10, seed=42)\n",
    "assert g50x1.rows == 50 and g50x1.cols == 1\n",
    "print(\"  ✅ 1x50 and 50x1 boards work\")\n",
    "\n",
    "# ── Edge case: 2x2 with 0 mines ──\n",
    "g2x2 = MinesweeperGame(2, 2, 0, seed=42)\n",
    "result = g2x2.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\"\n",
    "print(\"  ✅ 2x2 board with 0 mines → instant cascade win\")\n",
    "\n",
    "# Variable sizes across the full range\n",
    "for r, c, m in [(1,1,0), (2,2,0), (3,3,1), (5,5,3), (10,10,20),\n",
    "                (20,20,80), (30,30,180), (50,50,500), (1,50,10), (50,1,10)]:\n",
    "    g = MinesweeperGame(r, c, m, seed=42)\n",
    "    assert g.rows == r and g.cols == c\n",
    "    board = g.get_visible_board()\n",
    "    assert len(board) == r and len(board[0]) == c\n",
    "print(f\"  ✅ Variable board sizes (1x1 to 50x50) work\")\n",
    "\n",
    "# Test sample_board_config produces valid configs\n",
    "rng = random.Random(42)\n",
    "for _ in range(200):\n",
    "    r, c, m = sample_board_config(rng)\n",
    "    assert MIN_ROWS <= r <= MAX_ROWS\n",
    "    assert MIN_COLS <= c <= MAX_COLS\n",
    "    assert 0 <= m <= int(r * c * MAX_MINE_DENSITY)\n",
    "    g = MinesweeperGame(r, c, m, seed=42)\n",
    "print(f\"  ✅ sample_board_config produces valid configs (200 tested)\")\n",
    "\n",
    "# Test progress\n",
    "g = MinesweeperGame(5, 5, 3, seed=42)\n",
    "assert g.progress() == 0.0\n",
    "print(f\"  ✅ All game engine tests passed\")\n",
    "print(f\"  Board range: {MIN_ROWS}-{MAX_ROWS} rows × {MIN_COLS}-{MAX_COLS} cols\")\n",
    "print(f\"  Mine density: {MIN_MINE_DENSITY*100:.0f}%-{MAX_MINE_DENSITY*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617e14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Prompt System & Game Logic Helpers\n",
    "\n",
    "## Unified Prompt (single template for all board sizes)\n",
    "Same compact prompt for both training and inference. Pre-computed hints (safe/mine cells) do the heavy lifting — no verbose STEP 1-4 reasoning scaffolding.\n",
    "\n",
    "## 3-Tier Board Representation\n",
    "| Format | Board Size | Display |\n",
    "|--------|-----------|---------|\n",
    "| **A (Small)** | 1–20 | Full grid with borders and headers |\n",
    "| **B (Medium)** | 21–35 | Frontier cells + revealed number regions |\n",
    "| **C (Large)** | 36–50 | Quadrant summary + critical area snippets |\n",
    "\n",
    "## Symbol Legend\n",
    "`?`=unrevealed  `F`=flagged  `0`-`8`=revealed safe\n",
    "\n",
    "## Output Format\n",
    "```json\n",
    "{\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Minesweeper Logic Helpers — cached per game state\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _compute_safe_and_mine_cells(game: MinesweeperGame):\n",
    "    \"\"\"Compute both safe and mine cells in a SINGLE pass (O(n²) not O(n⁴)).\n",
    "\n",
    "    Returns (safe_set, mine_set) where each is a set of (row, col) tuples.\n",
    "\n",
    "    A cell is logically SAFE if any adjacent revealed number has all its\n",
    "    mines accounted for by flags (remaining_mines == 0).\n",
    "    A cell is a logically CERTAIN mine if an adjacent number has\n",
    "    remaining_mines == remaining unrevealed neighbors.\n",
    "    \"\"\"\n",
    "    safe = set()\n",
    "    mines = set()\n",
    "\n",
    "    for r in range(game.rows):\n",
    "        for c in range(game.cols):\n",
    "            if (r, c) not in game._revealed:\n",
    "                continue\n",
    "            val = game._board[r][c]\n",
    "            if val <= 0:\n",
    "                continue\n",
    "\n",
    "            flags = 0\n",
    "            unrevealed = []\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    if dr == 0 and dc == 0:\n",
    "                        continue\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if 0 <= nr < game.rows and 0 <= nc < game.cols:\n",
    "                        if (nr, nc) in game._flagged:\n",
    "                            flags += 1\n",
    "                        elif (nr, nc) not in game._revealed:\n",
    "                            unrevealed.append((nr, nc))\n",
    "\n",
    "            remaining = val - flags\n",
    "\n",
    "            if remaining == 0 and unrevealed:\n",
    "                for cell in unrevealed:\n",
    "                    safe.add(cell)\n",
    "            elif remaining > 0 and remaining == len(unrevealed):\n",
    "                for cell in unrevealed:\n",
    "                    mines.add(cell)\n",
    "\n",
    "    return safe, mines\n",
    "\n",
    "\n",
    "def _compute_safe_cells(game: MinesweeperGame) -> list:\n",
    "    \"\"\"Return list of [row, col] for logically safe cells.\"\"\"\n",
    "    safe, _ = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in safe]\n",
    "\n",
    "\n",
    "def _compute_mine_cells(game: MinesweeperGame) -> list:\n",
    "    \"\"\"Return list of [row, col] for logically certain mine cells.\"\"\"\n",
    "    _, mines = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in mines]\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Board Representation — 3-tier format (A/B/C) based on size\n",
    "# A: Small (1-20 rows/cols) — full grid\n",
    "# B: Medium (21-35 rows/cols) — revealed regions + frontier\n",
    "# C: Large (36-50 rows/cols) — critical areas + frontier summary\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _format_board_small(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Format A: Full grid display for boards ≤20 rows/cols.\"\"\"\n",
    "    board = game.get_visible_board()\n",
    "    if game.cols <= 10:\n",
    "        col_header = \"    \" + \" \".join(f\"{c}\" for c in range(game.cols))\n",
    "        separator = \"  +\" + \"-\" * (game.cols * 2 + 1) + \"+\"\n",
    "        rows_str = []\n",
    "        for r, row in enumerate(board):\n",
    "            rows_str.append(f\"{r:2d}| \" + \" \".join(row) + \" |\")\n",
    "    else:\n",
    "        col_header = \"    \" + \" \".join(f\"{c:2d}\" for c in range(game.cols))\n",
    "        separator = \"  +\" + \"-\" * (game.cols * 3) + \"+\"\n",
    "        rows_str = []\n",
    "        for r, row in enumerate(board):\n",
    "            rows_str.append(f\"{r:2d}| \" + \" \".join(f\"{v:>2s}\" for v in row) + \" |\")\n",
    "    return col_header + \"\\n\" + separator + \"\\n\" + \"\\n\".join(rows_str) + \"\\n\" + separator\n",
    "\n",
    "\n",
    "def _get_frontier_and_numbers(game: MinesweeperGame):\n",
    "    \"\"\"Get frontier cells (unrevealed cells adjacent to revealed numbers)\n",
    "    and the revealed number cells near the frontier.\"\"\"\n",
    "    frontier = set()\n",
    "    number_cells = {}\n",
    "    for r in range(game.rows):\n",
    "        for c in range(game.cols):\n",
    "            if (r, c) in game._revealed and game._board[r][c] > 0:\n",
    "                number_cells[(r, c)] = game._board[r][c]\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < game.rows and 0 <= nc < game.cols\n",
    "                                and (nr, nc) not in game._revealed):\n",
    "                            frontier.add((nr, nc))\n",
    "    return frontier, number_cells\n",
    "\n",
    "\n",
    "def _extract_critical_areas(game: MinesweeperGame, frontier, number_cells, max_areas=3):\n",
    "    \"\"\"Extract small rectangular regions around frontier clusters for display.\"\"\"\n",
    "    if not frontier:\n",
    "        return []\n",
    "    frontier_list = sorted(frontier)\n",
    "    areas = []\n",
    "    used = set()\n",
    "    for fr, fc in frontier_list:\n",
    "        if (fr, fc) in used:\n",
    "            continue\n",
    "        r_min = max(0, fr - 1)\n",
    "        r_max = min(game.rows - 1, fr + 1)\n",
    "        c_min = max(0, fc - 1)\n",
    "        c_max = min(game.cols - 1, fc + 1)\n",
    "        for fr2, fc2 in frontier_list:\n",
    "            if abs(fr2 - fr) <= 2 and abs(fc2 - fc) <= 2:\n",
    "                r_min = min(r_min, max(0, fr2 - 1))\n",
    "                r_max = max(r_max, min(game.rows - 1, fr2 + 1))\n",
    "                c_min = min(c_min, max(0, fc2 - 1))\n",
    "                c_max = max(c_max, min(game.cols - 1, fc2 + 1))\n",
    "                used.add((fr2, fc2))\n",
    "        board = game.get_visible_board()\n",
    "        col_hdr = \"    \" + \" \".join(f\"{c:2d}\" for c in range(c_min, c_max + 1))\n",
    "        sep = \"  +\" + \"-\" * ((c_max - c_min + 1) * 3) + \"+\"\n",
    "        rows_str = []\n",
    "        for r in range(r_min, r_max + 1):\n",
    "            cells = [f\"{board[r][c]:>2s}\" for c in range(c_min, c_max + 1)]\n",
    "            rows_str.append(f\"{r:2d}| \" + \" \".join(cells) + \" |\")\n",
    "        area_str = f\"Region near ({fr},{fc}):\\n{col_hdr}\\n{sep}\\n\"\n",
    "        area_str += \"\\n\".join(rows_str) + \"\\n\" + sep\n",
    "        areas.append(area_str)\n",
    "        if len(areas) >= max_areas:\n",
    "            break\n",
    "    return areas\n",
    "\n",
    "\n",
    "def _format_board_medium(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Format B: Revealed regions + frontier for boards 21-35 rows/cols.\"\"\"\n",
    "    frontier, number_cells = _get_frontier_and_numbers(game)\n",
    "    areas = _extract_critical_areas(game, frontier, number_cells, max_areas=4)\n",
    "    frontier_list = sorted(frontier)[:30]\n",
    "    flagged_list = sorted(game._flagged)[:20]\n",
    "    number_summary = [f\"({r},{c})={v}\" for (r, c), v in sorted(number_cells.items())[:30]]\n",
    "    lines = []\n",
    "    lines.append(f\"Board: {game.rows}×{game.cols} with {game.num_mines} mines \"\n",
    "                 f\"({mine_density(game.rows, game.cols, game.num_mines)*100:.1f}% density)\")\n",
    "    lines.append(\"\")\n",
    "    if areas:\n",
    "        for area in areas:\n",
    "            lines.append(area)\n",
    "            lines.append(\"\")\n",
    "    lines.append(f\"Revealed numbers: {number_summary}\")\n",
    "    lines.append(f\"Unrevealed frontier cells: {frontier_list}\")\n",
    "    if flagged_list:\n",
    "        lines.append(f\"Flagged cells: {flagged_list}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def _format_board_large(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Format C: Critical areas + frontier summary for boards 36-50 rows/cols.\"\"\"\n",
    "    frontier, number_cells = _get_frontier_and_numbers(game)\n",
    "    mid_r, mid_c = game.rows // 2, game.cols // 2\n",
    "    quadrants = {\n",
    "        \"Top-left\": (0, mid_r, 0, mid_c),\n",
    "        \"Top-right\": (0, mid_r, mid_c, game.cols),\n",
    "        \"Bottom-left\": (mid_r, game.rows, 0, mid_c),\n",
    "        \"Bottom-right\": (mid_r, game.rows, mid_c, game.cols),\n",
    "    }\n",
    "    lines = []\n",
    "    lines.append(f\"Board: {game.rows}×{game.cols} with {game.num_mines} mines \"\n",
    "                 f\"({mine_density(game.rows, game.cols, game.num_mines)*100:.1f}% density)\")\n",
    "    lines.append(\"\")\n",
    "    safe_total = game.rows * game.cols - game.num_mines\n",
    "    lines.append(f\"Revealed safe cells: {len(game._revealed)}/{safe_total} \"\n",
    "                 f\"({game.progress()*100:.1f}% complete)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Quadrant summary:\")\n",
    "    for qname, (r0, r1, c0, c1) in quadrants.items():\n",
    "        q_total = (r1 - r0) * (c1 - c0)\n",
    "        q_revealed = sum(1 for r in range(r0, r1) for c in range(c0, c1)\n",
    "                        if (r, c) in game._revealed)\n",
    "        status = \"Fully explored\" if q_revealed >= q_total * 0.9 else \\\n",
    "                 \"Mostly complete\" if q_revealed >= q_total * 0.5 else \\\n",
    "                 \"Partially explored\" if q_revealed > 0 else \"Unexplored\"\n",
    "        lines.append(f\"  {qname} ({r0}-{r1-1}, {c0}-{c1-1}): \"\n",
    "                     f\"{status}, {q_revealed}/{q_total} revealed\")\n",
    "    lines.append(\"\")\n",
    "    areas = _extract_critical_areas(game, frontier, number_cells, max_areas=3)\n",
    "    if areas:\n",
    "        lines.append(\"Frontier regions:\")\n",
    "        for area in areas:\n",
    "            lines.append(area)\n",
    "            lines.append(\"\")\n",
    "    if len(game._flagged) > 0:\n",
    "        lines.append(f\"Flags: {len(game._flagged)}/{game.num_mines} mines flagged\")\n",
    "        if len(game._flagged) == game.num_mines:\n",
    "            lines.append(\"→ All mines flagged — reveal any remaining '?' to win\")\n",
    "    frontier_list = sorted(frontier)[:20]\n",
    "    lines.append(f\"\\nUnrevealed non-flagged: \"\n",
    "                 f\"{game.rows * game.cols - len(game._revealed) - len(game._flagged)}\")\n",
    "    if frontier_list:\n",
    "        lines.append(f\"Frontier cells: {frontier_list}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def _format_board(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Select appropriate board format based on size.\"\"\"\n",
    "    if game.rows <= 20 and game.cols <= 20:\n",
    "        return _format_board_small(game)\n",
    "    elif game.rows <= 35 and game.cols <= 35:\n",
    "        return _format_board_medium(game)\n",
    "    else:\n",
    "        return _format_board_large(game)\n",
    "\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a Minesweeper AI. You MUST reply with EXACTLY one JSON object on a single line. \"\n",
    "    \"Do NOT write any text, explanation, reasoning, markdown, or code blocks. \"\n",
    "    \"Do NOT use ```json or ``` wrappers. \"\n",
    "    \"ONLY output raw JSON in this exact format: \"\n",
    "    '{\"type\":\"reveal\",\"row\":0,\"col\":0} '\n",
    "    \"Nothing before it. Nothing after it. Just the JSON object.\"\n",
    ")\n",
    "\n",
    "\n",
    "def format_state_for_llm(game: MinesweeperGame, mode=\"training\") -> str:\n",
    "    \"\"\"Convert game state to a compact prompt for the LLM.\n",
    "\n",
    "    Single unified template for both training and inference.\n",
    "    Pre-computed hints (safe/mine cells) do the heavy lifting.\n",
    "    No verbose STEP 1-4 reasoning instructions.\n",
    "\n",
    "    mode=\"training\" — includes edge case guidance\n",
    "    mode=\"inference\" — same format (consistency helps at eval time)\n",
    "    \"\"\"\n",
    "    if game.state() == \"success\":\n",
    "        return \"Game already won. No action needed.\"\n",
    "\n",
    "    rows, cols = game.rows, game.cols\n",
    "    total_cells = rows * cols\n",
    "    safe_total = total_cells - game.num_mines\n",
    "    density = mine_density(rows, cols, game.num_mines) * 100\n",
    "    revealed = len(game._revealed)\n",
    "    flags = len(game._flagged)\n",
    "    remaining_mines = game.num_mines - flags\n",
    "\n",
    "    # ── 0-mine shortcut ──\n",
    "    if game.num_mines == 0:\n",
    "        return (\n",
    "            f\"Minesweeper {rows}×{cols} board with 0 mines.\\n\"\n",
    "            \"All cells are safe. Reveal any unrevealed cell.\\n\\n\"\n",
    "            f\"Row: 0-{rows - 1}  Col: 0-{cols - 1}\\n\"\n",
    "            'Reply with ONLY this JSON, nothing else: {\"type\":\"reveal\",\"row\":<int>,\"col\":<int>}'\n",
    "        )\n",
    "\n",
    "    board_repr = _format_board(game)\n",
    "\n",
    "    # ── Pre-computed logical hints (the real value) ──\n",
    "    safe_cells = _compute_safe_cells(game)\n",
    "    mine_cells = _compute_mine_cells(game)\n",
    "\n",
    "    hints = \"\"\n",
    "    if safe_cells:\n",
    "        hints += f\"SAFE cells (100% certain — reveal one): {safe_cells[:8]}\\n\"\n",
    "    if mine_cells:\n",
    "        hints += f\"MINE cells (100% certain — flag one): {mine_cells[:8]}\\n\"\n",
    "    if not safe_cells and not mine_cells:\n",
    "        if revealed > 0:\n",
    "            hints += \"No certain moves. Guess: prefer cells near low numbers, avoid edges.\\n\"\n",
    "        else:\n",
    "            hints += \"No cells revealed yet. Make an opening move.\\n\"\n",
    "\n",
    "    # ── Edge case one-liners ──\n",
    "    edge = \"\"\n",
    "    remaining = total_cells - revealed - flags\n",
    "\n",
    "    if game.num_mines == 0:\n",
    "        edge = \"ZERO MINES: Every cell is safe. Reveal any.\\n\"\n",
    "    elif rows == 1 or cols == 1:\n",
    "        edge = f\"LINEAR BOARD: Start from ends, work inward.\\n\"\n",
    "    elif rows <= 3 and cols <= 3:\n",
    "        edge = f\"TINY BOARD: Prefer center if unrevealed.\\n\"\n",
    "\n",
    "    if remaining == 1 and remaining_mines == 0:\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if (r, c) not in game._revealed and (r, c) not in game._flagged:\n",
    "                    edge += f\"LAST CELL ({r},{c}) — all mines flagged → REVEAL to WIN!\\n\"\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "    elif remaining == 1 and remaining_mines == 1:\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if (r, c) not in game._revealed and (r, c) not in game._flagged:\n",
    "                    edge += f\"LAST CELL ({r},{c}) — it IS a mine → FLAG it!\\n\"\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "    elif remaining_mines == 0 and remaining > 0:\n",
    "        edge += f\"ALL MINES FLAGGED: All {remaining} '?' cells are SAFE → reveal any.\\n\"\n",
    "    elif remaining > 0 and remaining == remaining_mines:\n",
    "        edge += f\"ALL {remaining} REMAINING CELLS ARE MINES → flag any.\\n\"\n",
    "\n",
    "    # ── Opening hint ──\n",
    "    if revealed == 0:\n",
    "        center_r, center_c = rows // 2, cols // 2\n",
    "        edge += f\"Opening: prefer center ({center_r},{center_c}).\\n\"\n",
    "\n",
    "    # ── Build prompt ──\n",
    "    prompt = (\n",
    "        f\"Minesweeper {rows}×{cols}, {game.num_mines} mines ({density:.1f}%)\\n\"\n",
    "        f\"Revealed: {revealed}/{safe_total} | Flags: {flags}/{game.num_mines}\\n\\n\"\n",
    "        f\"{board_repr}\\n\\n\"\n",
    "        f\"?=unrevealed F=flagged 0-8=safe\\n\\n\"\n",
    "        f\"{edge}{hints}\\n\"\n",
    "        f\"Row: 0-{rows - 1}  Col: 0-{cols - 1}\\n\"\n",
    "        'Reply with ONLY raw JSON, nothing else: {\"type\":\"reveal\",\"row\":<int>,\"col\":<int>}'\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_llm_action(response: str) -> dict:\n",
    "    \"\"\"Extract a valid Minesweeper action from LLM response.\n",
    "\n",
    "    Searches for JSON objects matching the expected format.\n",
    "    Handles: extra text around JSON, string-typed integers, multiple JSON objects.\n",
    "    Returns: {\"type\": \"reveal\"/\"flag\", \"row\": int, \"col\": int} or None\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for match in re.finditer(r'\\{[^{}]*\\}', response):\n",
    "        try:\n",
    "            action = json.loads(match.group())\n",
    "            if (\"type\" in action and \"row\" in action and \"col\" in action\n",
    "                    and action[\"type\"] in (\"reveal\", \"flag\")):\n",
    "                action[\"row\"] = int(action[\"row\"])\n",
    "                action[\"col\"] = int(action[\"col\"])\n",
    "                best = action\n",
    "        except (json.JSONDecodeError, ValueError, TypeError):\n",
    "            continue\n",
    "    return best\n",
    "\n",
    "# ── Quick verification ──\n",
    "print(\"✅ Unified prompt system loaded (single template)\")\n",
    "print(\"   Kept: board formatters (3-tier A/B/C), constraint solver, parse_llm_action\")\n",
    "print(\"   Removed: 4-tier STEP 1-4 reasoning, 200 lines of tests\")\n",
    "\n",
    "# Verify basic functionality\n",
    "game_test = MinesweeperGame(6, 6, 5, seed=42)\n",
    "p = format_state_for_llm(game_test, mode=\"training\")\n",
    "print(f\"   Example 6×6 prompt: {len(p)} chars\")\n",
    "assert \"Minesweeper\" in p\n",
    "assert \"JSON\" in p\n",
    "assert parse_llm_action('{\"type\":\"reveal\",\"row\":2,\"col\":3}') == {\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "assert parse_llm_action('no json') is None\n",
    "print(\"   ✅ parse_llm_action works\")\n",
    "\n",
    "print(f\"\\n--- Example prompt (6×6) ---\\n{p}\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302a238",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Model Before Training\n",
    "\n",
    "See how the base model performs without finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=42)\n",
    "prompt = format_state_for_llm(game)\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True,\n",
    ")\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "\n",
    "print(\"=== Base Model Response ===\")\n",
    "output = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    streamer = streamer,\n",
    "    temperature = 0.7,\n",
    "    top_p = 0.9,\n",
    "    max_new_tokens = 128,\n",
    "    do_sample = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b3c5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# GRPO Reward Functions\n",
    "\n",
    "Define reward functions to guide the model's learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ca52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Helper: Reconstruct game from dataset columns\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _reconstruct_game(idx, kwargs):\n",
    "    \"\"\"Reconstruct a MinesweeperGame from dataset columns passed via GRPO kwargs.\n",
    "\n",
    "    The dataset stores: seed, move_history, board_rows, board_cols, board_mines\n",
    "    GRPOTrainer passes all non-'prompt' columns as lists in **kwargs.\n",
    "\n",
    "    Returns (game, move_history_list) or (None, None) if data is missing.\n",
    "    Handles 0-mine boards correctly.\n",
    "    \"\"\"\n",
    "    seeds = kwargs.get(\"seed\", [])\n",
    "    move_histories = kwargs.get(\"move_history\", [])\n",
    "    rows_list = kwargs.get(\"board_rows\", [])\n",
    "    cols_list = kwargs.get(\"board_cols\", [])\n",
    "    mines_list = kwargs.get(\"board_mines\", [])\n",
    "\n",
    "    if idx >= len(seeds) or idx >= len(move_histories):\n",
    "        return None, None\n",
    "\n",
    "    seed = seeds[idx]\n",
    "    rows = rows_list[idx] if idx < len(rows_list) else 6\n",
    "    cols = cols_list[idx] if idx < len(cols_list) else 6\n",
    "    num_mines = mines_list[idx] if idx < len(mines_list) else 5\n",
    "\n",
    "    mh_raw = move_histories[idx]\n",
    "    if isinstance(mh_raw, str):\n",
    "        move_history = json.loads(mh_raw)\n",
    "    else:\n",
    "        move_history = list(mh_raw)\n",
    "\n",
    "    game = MinesweeperGame(rows=int(rows), cols=int(cols),\n",
    "                           num_mines=int(num_mines), seed=int(seed))\n",
    "    for prev in move_history:\n",
    "        result = game.do_action(prev)\n",
    "        if result == \"mine\":\n",
    "            return None, None  # History hit a mine — bad data\n",
    "\n",
    "    return game, move_history\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Length penalty helper (GRPO-LEAD: α=0.15)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "LENGTH_PENALTY_ALPHA = 0.15\n",
    "\n",
    "\n",
    "def _length_penalty(response: str) -> float:\n",
    "    \"\"\"Compute length-based reward modifier (GRPO-LEAD paper).\n",
    "\n",
    "    Returns a value in [-2.0, +2.0]:\n",
    "      Pure JSON (~30 chars)    → +2.0\n",
    "      Near-pure (<60c)         → +1.5\n",
    "      Some extra text (<100c)  → +0.5\n",
    "      Moderate (100-200 chars) → -0.5\n",
    "      Verbose (>200 chars)     → -1.5 to -2.0\n",
    "    \"\"\"\n",
    "    n = len(response)\n",
    "    if n <= 40:\n",
    "        return 2.0\n",
    "    elif n <= 60:\n",
    "        return 1.5\n",
    "    elif n <= 100:\n",
    "        return 0.5 * math.exp(-LENGTH_PENALTY_ALPHA * (n - 60) / 10)\n",
    "    elif n <= 200:\n",
    "        return -0.5 - 0.5 * ((n - 100) / 100)\n",
    "    else:\n",
    "        return -1.5 - min(0.5, (n - 200) / 200)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Difficulty reweighting helper (XRPO paper)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _difficulty_multiplier(game) -> float:\n",
    "    \"\"\"Compute difficulty-based reward multiplier (XRPO paper).\n",
    "\n",
    "    Returns a value in [0.7, 1.5]:\n",
    "      Easy boards (low density, small) → ~0.7-0.9\n",
    "      Medium boards                    → ~1.0\n",
    "      Hard boards (high density, large) → ~1.2-1.5\n",
    "    \"\"\"\n",
    "    board_size = game.rows * game.cols\n",
    "\n",
    "    if board_size == 0 or game.num_mines == 0:\n",
    "        return 1.0\n",
    "\n",
    "    density = mine_density(game.rows, game.cols, game.num_mines)\n",
    "    size_factor = min(1.0, math.log(max(1, board_size)) / math.log(2500))\n",
    "    difficulty = 0.6 * (density / 0.20) + 0.4 * size_factor\n",
    "    multiplier = 0.7 + 0.8 / (1.0 + math.exp(-6.0 * (difficulty - 0.5)))\n",
    "\n",
    "    return multiplier\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 1: Valid JSON format + conciseness + length penalty (GRPO-LEAD)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def valid_json_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"GRPO-LEAD: Ultra-strict JSON-only reward with EXPONENTIAL penalties.\n",
    "\n",
    "    Exponential penalty curve: penalty = -1.0 × 1.5^((extra_chars - 3) / 5)\n",
    "      5 extra chars  → -1.0\n",
    "      10 extra chars → -2.8\n",
    "      20 extra chars → -10.1\n",
    "      30 extra chars → -28.3\n",
    "      50+ chars      → -50.0 (cap)\n",
    "\n",
    "    Two-pass approach:\n",
    "      Pass 1: Score format correctness & collect correct response lengths\n",
    "      Pass 2: Apply z-score normalized length penalty to correct responses\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    correct_lengths = []\n",
    "\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"].strip() if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            results.append((None, response, -25.0, False))\n",
    "            continue\n",
    "\n",
    "        # Check if it's PURE JSON (no extra text)\n",
    "        try:\n",
    "            parsed = json.loads(response)\n",
    "            if \"type\" in parsed and \"row\" in parsed and \"col\" in parsed:\n",
    "                if len(response) <= 50:\n",
    "                    correct_lengths.append(len(response))\n",
    "                    results.append((action, response, 10.0, True))\n",
    "                elif len(response) <= 80:\n",
    "                    correct_lengths.append(len(response))\n",
    "                    results.append((action, response, 8.0, True))\n",
    "                elif len(response) <= 120:\n",
    "                    correct_lengths.append(len(response))\n",
    "                    results.append((action, response, 5.0, True))\n",
    "                else:\n",
    "                    correct_lengths.append(len(response))\n",
    "                    results.append((action, response, 2.0, True))\n",
    "                continue\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        # JSON found but with extra text — EXPONENTIAL PENALTY\n",
    "        json_match = re.search(r'\\{[^{}]*\\}', response)\n",
    "        extra_chars = len(response) - len(json_match.group()) if json_match else len(response)\n",
    "\n",
    "        if extra_chars <= 3:\n",
    "            base = 0.5\n",
    "        else:\n",
    "            base = -1.0 * (1.5 ** ((extra_chars - 3) / 5))\n",
    "            base = max(-50.0, base)\n",
    "\n",
    "        correct_lengths.append(len(response))\n",
    "        results.append((action, response, base, True))\n",
    "\n",
    "    # ── Pass 2: Apply group-normalized length penalty (GRPO-LEAD) ──\n",
    "    scores = []\n",
    "\n",
    "    if len(correct_lengths) > 1:\n",
    "        mean_len = np.mean(correct_lengths)\n",
    "        std_len = np.std(correct_lengths) + 1e-8\n",
    "\n",
    "        for action, response, base_score, is_correct in results:\n",
    "            if not is_correct:\n",
    "                scores.append(base_score)\n",
    "            else:\n",
    "                z_score = (len(response) - mean_len) / std_len\n",
    "                length_multiplier = math.exp(-LENGTH_PENALTY_ALPHA * z_score)\n",
    "                length_multiplier = max(0.5, min(1.5, length_multiplier))\n",
    "                scores.append(base_score * length_multiplier)\n",
    "    else:\n",
    "        for action, response, base_score, is_correct in results:\n",
    "            if not is_correct:\n",
    "                scores.append(base_score)\n",
    "            else:\n",
    "                lp = _length_penalty(response)\n",
    "                scores.append(base_score + lp)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 2: Gameplay — 12-criterion scoring + center-opening (XRPO)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def gameplay_scores(prompts, completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Complete gameplay reward implementing all 12 scoring criteria\n",
    "    + center-opening bonus (folded in from strategic_reward).\n",
    "\n",
    "    1.  Flag cell that IS a mine        → +15 / +20 (logical)\n",
    "    2.  Flag cell that is NOT a mine    → -11\n",
    "    3.  Reveal cell that IS a mine      → -26\n",
    "    4.  Reveal cell that is safe        → +10 (guess) / +15 (logical)\n",
    "    5.  Flag already flagged cell       → -12\n",
    "    6.  Reveal already revealed cell    → -12\n",
    "    7.  Out of bounds                   → -15\n",
    "    8.  Total flags > total mines       → -10 (additional)\n",
    "    9.  Invalid JSON                    → -10\n",
    "    10. Win the game                    → +100 × size_scale\n",
    "    11. Reveal a flagged cell           → -8\n",
    "    12. Flag a revealed cell            → -8\n",
    "    13. Center-opening bonus (LAMER)    → +5 center, +3 near-center\n",
    "    14. Penalize flagging on fresh board → -2\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"] if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        # Criterion 9: Invalid JSON\n",
    "        if action is None:\n",
    "            scores.append(-20.0)\n",
    "            continue\n",
    "\n",
    "        game, move_history = _reconstruct_game(idx, kwargs)\n",
    "        if game is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        diff_mult = _difficulty_multiplier(game)\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        row, col = action[\"row\"], action[\"col\"]\n",
    "        action_type = action[\"type\"]\n",
    "\n",
    "        # Criterion 7: Out of bounds\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(-15.0 * diff_mult)\n",
    "            continue\n",
    "\n",
    "        # Edge case: 0-mine board\n",
    "        if game.num_mines == 0:\n",
    "            if action_type == \"reveal\":\n",
    "                if (row, col) in game._revealed:\n",
    "                    scores.append(-12.0)\n",
    "                else:\n",
    "                    game_copy = MinesweeperGame(\n",
    "                        rows=game.rows, cols=game.cols,\n",
    "                        num_mines=0, seed=kwargs.get(\"seed\", [0])[idx]\n",
    "                    )\n",
    "                    for prev in move_history:\n",
    "                        game_copy.do_action(prev)\n",
    "                    result = game_copy.do_action(action)\n",
    "                    board_size = game.rows * game.cols\n",
    "                    size_scale = 1.0 + min(1.0, board_size / 1000)\n",
    "                    win_bonus = (100.0 * size_scale) if result == \"win\" else 0.0\n",
    "                    scores.append(15.0 + win_bonus)\n",
    "            else:\n",
    "                scores.append(-10.0)\n",
    "            continue\n",
    "\n",
    "        # Compute logical deductions ONCE\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        score = 0.0\n",
    "\n",
    "        # ── Center-opening bonus (from LAMER paper, was in strategic_reward) ──\n",
    "        if len(game._revealed) == 0 and action_type == \"reveal\":\n",
    "            density_pct = mine_density(game.rows, game.cols, game.num_mines) * 100\n",
    "            center_r, center_c = game.rows // 2, game.cols // 2\n",
    "            dist_to_center = abs(row - center_r) + abs(col - center_c)\n",
    "            max_dist = center_r + center_c\n",
    "\n",
    "            if density_pct > 10:\n",
    "                if dist_to_center == 0:\n",
    "                    score += 5.0\n",
    "                elif dist_to_center <= max(1, max_dist // 4):\n",
    "                    score += 3.0\n",
    "                elif dist_to_center <= max_dist // 2:\n",
    "                    score += 1.0\n",
    "                else:\n",
    "                    score -= 2.0\n",
    "            else:\n",
    "                if dist_to_center <= max(1, max_dist // 3):\n",
    "                    score += 2.0\n",
    "\n",
    "        # Penalize flagging on a fresh board\n",
    "        if len(game._revealed) == 0 and action_type == \"flag\":\n",
    "            score -= 2.0\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            # Criterion 6: Reveal already revealed cell\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-12.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # Criterion 11: Reveal a flagged cell\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-8.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # Criterion 3: Reveal a mine\n",
    "            if game._board[row][col] == -1:\n",
    "                scores.append((-25.0 - 1.0) * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # Criterion 4: Reveal safe cell\n",
    "            if (row, col) in safe_set:\n",
    "                score += 15.0   # Logically deduced safe cell\n",
    "            else:\n",
    "                score += 10.0   # Guessed safe cell\n",
    "\n",
    "            # Small bonus for revealing near numbers (information-rich)\n",
    "            board = game.get_visible_board()\n",
    "            has_adjacent_number = False\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    nr, nc = row + dr, col + dc\n",
    "                    if 0 <= nr < game.rows and 0 <= nc < game.cols:\n",
    "                        if board[nr][nc] in ('1','2','3','4','5','6','7','8'):\n",
    "                            has_adjacent_number = True\n",
    "                            break\n",
    "                if has_adjacent_number:\n",
    "                    break\n",
    "            if has_adjacent_number:\n",
    "                score += 1.0\n",
    "\n",
    "            # Criterion 10: Check for win\n",
    "            game_copy = MinesweeperGame(\n",
    "                rows=game.rows, cols=game.cols,\n",
    "                num_mines=game.num_mines, seed=kwargs.get(\"seed\", [0])[idx]\n",
    "            )\n",
    "            for prev in move_history:\n",
    "                game_copy.do_action(prev)\n",
    "            result = game_copy.do_action(action)\n",
    "            if result == \"win\":\n",
    "                board_size = game.rows * game.cols\n",
    "                size_scale = 1.0 + min(1.0, board_size / 1000)\n",
    "                score += 100.0 * size_scale\n",
    "\n",
    "        elif action_type == \"flag\":\n",
    "            # Criterion 5: Flag already flagged cell\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-12.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # Criterion 12: Flag a revealed cell\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-8.0 * diff_mult)\n",
    "                continue\n",
    "\n",
    "            # Criterion 1: Flag a mine (correct)\n",
    "            if game._board[row][col] == -1:\n",
    "                if (row, col) in mine_set:\n",
    "                    score += 20.0   # Logically deduced mine\n",
    "                else:\n",
    "                    score += 15.0   # Correct but guessed\n",
    "\n",
    "            # Criterion 2: Flag a non-mine (wrong)\n",
    "            else:\n",
    "                score -= 10.0 + 1.0\n",
    "\n",
    "            # Criterion 8: Total flags > total mines\n",
    "            new_flag_count = len(game._flagged) + 1\n",
    "            if new_flag_count > game.num_mines:\n",
    "                score -= 10.0\n",
    "\n",
    "        # Apply difficulty multiplier (XRPO)\n",
    "        scores.append(score * diff_mult)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ── Verify reward function signatures ──\n",
    "print(\"✅ Reward functions defined (2 total):\")\n",
    "print(\"   1. valid_json_reward — format + exponential penalty (GRPO-LEAD)\")\n",
    "print(\"   2. gameplay_scores   — 12 criteria + center-opening + difficulty (XRPO)\")\n",
    "print(\"   Removed: strategic_reward (was 5% weight = noise, folded center-opening into gameplay_scores)\")\n",
    "\n",
    "# ── Smoke test ──\n",
    "test_completions_pure = [[{\"role\": \"assistant\", \"content\": '{\"type\":\"reveal\",\"row\":0,\"col\":0}'}]]\n",
    "test_completions_verbose = [[{\"role\": \"assistant\", \"content\": 'Let me analyze this board step by step. The cell at row 0, col 0 looks promising because it has several revealed neighbors. {\"type\":\"reveal\",\"row\":0,\"col\":0}'}]]\n",
    "test_prompts = [\"test\"]\n",
    "\n",
    "test_kwargs = {\n",
    "    \"seed\": [42],\n",
    "    \"move_history\": [\"[]\"],\n",
    "    \"board_rows\": [6],\n",
    "    \"board_cols\": [6],\n",
    "    \"board_mines\": [5],\n",
    "}\n",
    "\n",
    "r1p = valid_json_reward(test_prompts, test_completions_pure, **test_kwargs)\n",
    "r1v = valid_json_reward(test_prompts, test_completions_verbose, **test_kwargs)\n",
    "r2p = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs)\n",
    "\n",
    "print(f\"\\n  Pure JSON format reward:    {r1p[0]:+.2f}\")\n",
    "print(f\"  Verbose JSON format reward: {r1v[0]:+.2f}\")\n",
    "print(f\"  Gameplay reward (pure):     {r2p[0]:+.2f}\")\n",
    "print(f\"\\n  Reward gap analysis (weights [0.60, 0.40]):\")\n",
    "print(f\"    Pure JSON weighted:    {r1p[0]*0.60:+.2f} + {r2p[0]*0.40:+.2f} = {r1p[0]*0.60 + r2p[0]*0.40:+.2f}\")\n",
    "print(f\"    Gap: {(r1p[0] - r1v[0]) * 0.60:+.2f} — pure JSON DOMINATES\")\n",
    "\n",
    "# 0-mine board\n",
    "test_kwargs_zero = {\"seed\": [42], \"move_history\": [\"[]\"], \"board_rows\": [5], \"board_cols\": [5], \"board_mines\": [0]}\n",
    "r2z = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs_zero)\n",
    "print(f\"\\n  0-mine board: gameplay={r2z[0]:.1f}\")\n",
    "\n",
    "# 1x1 board\n",
    "test_kwargs_1x1 = {\"seed\": [42], \"move_history\": [\"[]\"], \"board_rows\": [1], \"board_cols\": [1], \"board_mines\": [0]}\n",
    "r2_1x1 = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs_1x1)\n",
    "print(f\"  1x1 m=0:     gameplay={r2_1x1[0]:.1f}\")\n",
    "\n",
    "# Hard board\n",
    "test_kwargs_hard = {\"seed\": [42], \"move_history\": [\"[]\"], \"board_rows\": [20], \"board_cols\": [20], \"board_mines\": [80]}\n",
    "r2h = gameplay_scores(test_prompts, test_completions_pure, **test_kwargs_hard)\n",
    "print(f\"  Hard 20x20:   gameplay={r2h[0]:.1f} (XRPO amplified)\")\n",
    "\n",
    "print(f\"\\n  ✅ Exponential JSON penalties (pure +10.0, verbose → -50.0 cap)\")\n",
    "print(f\"  ✅ Edge cases: 0-mine, 1x1, hard boards handled\")\n",
    "print(f\"  ✅ Center-opening bonus folded into gameplay_scores\")\n",
    "print(f\"  ✅ Difficulty reweighting (XRPO): harder boards → amplified signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b787f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Exhaustive Training Dataset Generation\n",
    "\n",
    "6-phase composition targeting **4000 samples** with density-stratified sampling:\n",
    "\n",
    "| Phase | Budget | Description |\n",
    "|-------|--------|-------------|\n",
    "| 1. Edge Cases | 10% | 50+ explicit configs (trivial, linear, rectangular, density extremes) |\n",
    "| 2. Opening | 25% | 75% fresh + 25% single-move — fix 75% early death rate |\n",
    "| 3. Pattern-Specific | 15% | Satisfied numbers (60%) + multi-region boards (40%) |\n",
    "| 4. Mid-Game | 25% | 3-15 moves, progressive flagging 10%→30%→50% |\n",
    "| 5. Endgame | 15% | 80-98% revealed, flag accounting, completion strategy |\n",
    "| 6. Forced Guess | 10% | No logical deductions available — probability reasoning |\n",
    "\n",
    "## Board Size Distribution (Bell-Curve Curriculum)\n",
    "| Band | Size Range | Weight | Purpose |\n",
    "|------|-----------|--------|---------|\n",
    "| Tiny | 1–5 | 10% | Edge cases, basics |\n",
    "| Small | 5–10 | 20% | Simple pattern learning |\n",
    "| **Mid** | **8–20** | **35%** | **Core curriculum ★ peak** |\n",
    "| Large | 15–30 | 20% | Generalization |\n",
    "| XL | 25–40 | 10% | Harder boards |\n",
    "| XXL | 35–50 | 5% | Edge exposure only |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  EXHAUSTIVE DATASET GENERATION\n",
    "#  Fixes: 75% early deaths, no pattern training, 0.7% endgame,\n",
    "#         no forced-guess scenarios, insufficient flag training\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Helper: Smart move selection with progressive flagging\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _smart_reveal(game, rng):\n",
    "    \"\"\"Pick a smart cell to reveal during history generation.\n",
    "    Prefers safe cells (if known) to avoid hitting mines and losing the game.\n",
    "    Falls back to random unrevealed cell.\n",
    "    \"\"\"\n",
    "    safe_set, _ = _compute_safe_and_mine_cells(game)\n",
    "    if safe_set:\n",
    "        return rng.choice(list(safe_set))\n",
    "\n",
    "    # Fallback: random unrevealed, unflagged cell\n",
    "    unrevealed = [(r, c) for r in range(game.rows) for c in range(game.cols)\n",
    "                  if (r, c) not in game._revealed and (r, c) not in game._flagged]\n",
    "    if not unrevealed:\n",
    "        return None\n",
    "    return rng.choice(unrevealed)\n",
    "\n",
    "\n",
    "def _smart_flag(game, rng):\n",
    "    \"\"\"Pick a logically certain mine to flag, or None if none available.\"\"\"\n",
    "    _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "    mine_candidates = [c for c in mine_set if c not in game._flagged]\n",
    "    if mine_candidates:\n",
    "        return rng.choice(mine_candidates)\n",
    "    return None  # Don't flag randomly — creates bad training data\n",
    "\n",
    "\n",
    "def _progressive_flag_probability(game):\n",
    "    \"\"\"Adaptive flagging based on game progress (LAMER-inspired).\n",
    "    - Early game (0-30%):  10% flagging (explore first)\n",
    "    - Mid game (30-70%):   30% flagging (deduce mines)\n",
    "    - Late game (70-100%): 50% flagging (lock in certain mines)\n",
    "    \"\"\"\n",
    "    progress = game.progress()\n",
    "    if progress < 0.30:\n",
    "        return 0.10\n",
    "    elif progress < 0.70:\n",
    "        return 0.30\n",
    "    else:\n",
    "        return 0.50\n",
    "\n",
    "\n",
    "def _play_smart_moves(game, rng, num_moves, use_progressive_flags=True):\n",
    "    \"\"\"Play num_moves smart moves on a game. Returns move_history list.\n",
    "    Uses progressive flagging strategy when enabled.\n",
    "    Returns early if game ends or gets stuck.\n",
    "\n",
    "    Fix #1: Added stuck_count to prevent infinite loops when no valid\n",
    "    moves can be found (e.g., all cells revealed/flagged but game ongoing).\n",
    "    \"\"\"\n",
    "    move_history = []\n",
    "    stuck_count = 0\n",
    "    MAX_STUCK = 10  # Abort after 10 consecutive failed attempts\n",
    "\n",
    "    for _ in range(num_moves):\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "\n",
    "        action_dict = None\n",
    "        flag_prob = _progressive_flag_probability(game) if use_progressive_flags else 0.15\n",
    "\n",
    "        # Try flagging with adaptive probability\n",
    "        if rng.random() < flag_prob:\n",
    "            flag_target = _smart_flag(game, rng)\n",
    "            if flag_target:\n",
    "                action_dict = {\"type\": \"flag\", \"row\": flag_target[0], \"col\": flag_target[1]}\n",
    "\n",
    "        # Fall back to reveal\n",
    "        if action_dict is None:\n",
    "            reveal_target = _smart_reveal(game, rng)\n",
    "            if reveal_target is None:\n",
    "                stuck_count += 1\n",
    "                if stuck_count >= MAX_STUCK:\n",
    "                    break  # Prevent infinite loop\n",
    "                continue\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": reveal_target[0], \"col\": reveal_target[1]}\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            break  # Hit a mine — stop\n",
    "\n",
    "        move_history.append(action_dict)\n",
    "        stuck_count = 0  # Reset on successful move\n",
    "\n",
    "    return move_history\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Scenario generators: endgame, forced-guess, multi-region\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _generate_endgame_state(rows, cols, num_mines, rng, completion_target=0.85):\n",
    "    \"\"\"Generate boards that are 80-98% complete.\n",
    "    Critical for teaching finishing strategy and flag accounting.\n",
    "    Returns (game, move_history) or (None, None) on failure.\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    safe_total = rows * cols - num_mines\n",
    "    if safe_total <= 1:\n",
    "        return None, None, seed\n",
    "\n",
    "    target_revealed = int(safe_total * rng.uniform(completion_target, 0.98))\n",
    "    target_revealed = max(1, min(target_revealed, safe_total - 1))\n",
    "\n",
    "    move_history = []\n",
    "    stuck_count = 0\n",
    "    max_stuck = 20\n",
    "\n",
    "    while len(game._revealed) < target_revealed and game.state() == \"ongoing\":\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        if safe_set:\n",
    "            target = rng.choice(list(safe_set))\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        else:\n",
    "            # No logical moves — reveal a random safe cell (we know the board)\n",
    "            all_safe_unrevealed = [\n",
    "                (r, c) for r in range(rows) for c in range(cols)\n",
    "                if game._board[r][c] != -1\n",
    "                and (r, c) not in game._revealed\n",
    "                and (r, c) not in game._flagged\n",
    "            ]\n",
    "            if not all_safe_unrevealed:\n",
    "                break\n",
    "            target = rng.choice(all_safe_unrevealed)\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "            stuck_count += 1\n",
    "            if stuck_count >= max_stuck:\n",
    "                break\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Optionally add some flags in endgame\n",
    "    if game.state() == \"ongoing\":\n",
    "        _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "        flaggable = [c for c in mine_set if c not in game._flagged]\n",
    "        if flaggable and rng.random() < 0.7:\n",
    "            num_flags = rng.randint(1, min(len(flaggable), 5))\n",
    "            for target in rng.sample(flaggable, num_flags):\n",
    "                action_dict = {\"type\": \"flag\", \"row\": target[0], \"col\": target[1]}\n",
    "                game.do_action(action_dict)\n",
    "                move_history.append(action_dict)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    return game, move_history, seed\n",
    "\n",
    "\n",
    "def _generate_forced_guess_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Generate a board state where no 100% certain logical moves exist.\n",
    "    These teach the model probability-based guessing.\n",
    "    Returns (game, move_history, seed) or (None, None, seed).\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    move_history = []\n",
    "    max_reveal_attempts = rows * cols\n",
    "\n",
    "    for _ in range(max_reveal_attempts):\n",
    "        if game.state() != \"ongoing\":\n",
    "            return None, None, seed\n",
    "\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        if not safe_set and not mine_set and len(game._revealed) > 0:\n",
    "            # No logical moves available — this is what we want!\n",
    "            unrevealed_count = sum(\n",
    "                1 for r in range(rows) for c in range(cols)\n",
    "                if (r, c) not in game._revealed and (r, c) not in game._flagged\n",
    "            )\n",
    "            if unrevealed_count >= 2:\n",
    "                return game, move_history, seed\n",
    "\n",
    "        if safe_set:\n",
    "            target = rng.choice(list(safe_set))\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        else:\n",
    "            # Must guess — reveal random safe cell (using board knowledge)\n",
    "            all_safe = [\n",
    "                (r, c) for r in range(rows) for c in range(cols)\n",
    "                if game._board[r][c] != -1\n",
    "                and (r, c) not in game._revealed\n",
    "                and (r, c) not in game._flagged\n",
    "            ]\n",
    "            if not all_safe:\n",
    "                break\n",
    "            target = rng.choice(all_safe)\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Fallback: return whatever state we reached (might still have logical moves)\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "def _generate_multi_region_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Create board with multiple separated revealed regions.\n",
    "    Teaches model to reason across disconnected information.\n",
    "    Returns (game, move_history, seed) or (None, None, seed).\n",
    "    \"\"\"\n",
    "    if rows < 6 or cols < 6:\n",
    "        return None, None, 0  # Need space for multiple regions\n",
    "\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    # Pick 2-4 starting points in different quadrants\n",
    "    quadrant_centers = [\n",
    "        (rows // 4, cols // 4),\n",
    "        (rows // 4, 3 * cols // 4),\n",
    "        (3 * rows // 4, cols // 4),\n",
    "        (3 * rows // 4, 3 * cols // 4),\n",
    "    ]\n",
    "    rng.shuffle(quadrant_centers)\n",
    "    num_regions = rng.randint(2, min(4, len(quadrant_centers)))\n",
    "    selected = quadrant_centers[:num_regions]\n",
    "\n",
    "    move_history = []\n",
    "    for r, c in selected:\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "        r = max(0, min(r, rows - 1))\n",
    "        c = max(0, min(c, cols - 1))\n",
    "\n",
    "        if (r, c) not in game._revealed and game._board[r][c] != -1:\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "            result = game.do_action(action_dict)\n",
    "            if result == \"mine\":\n",
    "                return None, None, seed\n",
    "            move_history.append(action_dict)\n",
    "\n",
    "        # Reveal a few logical neighbors around this region\n",
    "        for _ in range(rng.randint(1, 3)):\n",
    "            if game.state() != \"ongoing\":\n",
    "                break\n",
    "            safe_set, _ = _compute_safe_and_mine_cells(game)\n",
    "            if safe_set:\n",
    "                # Prefer safe cells near this region\n",
    "                nearby = [\n",
    "                    (sr, sc) for sr, sc in safe_set\n",
    "                    if abs(sr - r) <= rows // 3 and abs(sc - c) <= cols // 3\n",
    "                ]\n",
    "                target = rng.choice(nearby) if nearby else rng.choice(list(safe_set))\n",
    "                action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "                result = game.do_action(action_dict)\n",
    "                if result == \"mine\":\n",
    "                    return None, None, seed\n",
    "                move_history.append(action_dict)\n",
    "\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "def _generate_satisfied_numbers_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Generate board with multiple satisfied numbers (easy deductions available).\n",
    "    Satisfied number = number whose count of adjacent flags equals its value.\n",
    "    All remaining unrevealed neighbors of a satisfied number are safe.\n",
    "    Teaches basic constraint satisfaction.\n",
    "    Returns (game, move_history, seed).\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    move_history = []\n",
    "\n",
    "    # Reveal some cells first\n",
    "    num_initial = rng.randint(3, max(3, min(15, rows * cols // 4)))\n",
    "    for _ in range(num_initial):\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "        target = _smart_reveal(game, rng)\n",
    "        if target is None:\n",
    "            break\n",
    "        action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Now flag logically certain mines to create satisfied numbers\n",
    "    if game.state() == \"ongoing\":\n",
    "        for _ in range(5):\n",
    "            _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "            flaggable = [c for c in mine_set if c not in game._flagged]\n",
    "            if not flaggable:\n",
    "                break\n",
    "            target = rng.choice(flaggable)\n",
    "            action_dict = {\"type\": \"flag\", \"row\": target[0], \"col\": target[1]}\n",
    "            game.do_action(action_dict)\n",
    "            move_history.append(action_dict)\n",
    "\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Density-stratified board sampling\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "DENSITY_TARGETS = [\n",
    "    # (density_range, weight, label)\n",
    "    ((0.00, 0.00), 0.08, \"Zero mines\"),       # 8%  - trivial edge case\n",
    "    ((0.01, 0.05), 0.17, \"Very sparse\"),       # 17%\n",
    "    ((0.05, 0.10), 0.25, \"Sparse\"),            # 25%\n",
    "    ((0.10, 0.15), 0.25, \"Medium\"),            # 25%\n",
    "    ((0.15, 0.20), 0.25, \"Dense/Max\"),         # 25%\n",
    "]\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Board Size Distribution — Bell-curve centered on mid-range (8-20)\n",
    "#\n",
    "# Curriculum learning insight: mid-range boards (8-20) are the sweet\n",
    "# spot for learning patterns. Small boards teach basics, but mid-range\n",
    "# boards have enough complexity to learn deduction chains, constraint\n",
    "# satisfaction, and multi-step reasoning without the noise/sparsity\n",
    "# of huge boards. Large boards (30+) exist for generalization but\n",
    "# shouldn't dominate training.\n",
    "#\n",
    "# Distribution (bell-curve, peak at mid-range):\n",
    "#   Tiny   (1-5):    10%  — edge cases, basics\n",
    "#   Small  (5-10):   20%  — simple pattern learning\n",
    "#   Mid    (8-20):   35%  — PEAK: core pattern training ★\n",
    "#   Large  (15-30):  20%  — generalization, scaling\n",
    "#   XL     (25-40):  10%  — harder generalization\n",
    "#   XXL    (35-50):   5%  — edge exposure only\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "SIZE_BANDS = [\n",
    "    # (min_dim, max_dim, weight, label)\n",
    "    (1,   5,  0.10, \"Tiny\"),       # 10% — basics + edge cases\n",
    "    (5,  10,  0.20, \"Small\"),      # 20% — simple patterns\n",
    "    (8,  20,  0.35, \"Mid\"),        # 35% — PEAK: core curriculum ★\n",
    "    (15, 30,  0.20, \"Large\"),      # 20% — generalization\n",
    "    (25, 40,  0.10, \"XL\"),         # 10% — harder boards\n",
    "    (35, 50,  0.05, \"XXL\"),        #  5% — edge exposure only\n",
    "]\n",
    "\n",
    "\n",
    "def _sample_board_size(rng):\n",
    "    \"\"\"Sample board dimensions using bell-curve distribution.\n",
    "    Peak at mid-range (8-20) for optimal curriculum learning.\n",
    "    \"\"\"\n",
    "    weights = [w for _, _, w, _ in SIZE_BANDS]\n",
    "    idx = rng.choices(range(len(SIZE_BANDS)), weights=weights, k=1)[0]\n",
    "    lo, hi, _, _ = SIZE_BANDS[idx]\n",
    "    rows = rng.randint(lo, hi)\n",
    "    cols = rng.randint(lo, hi)\n",
    "    return rows, cols\n",
    "\n",
    "\n",
    "def _sample_board_with_density(rng, target_density_range=None):\n",
    "    \"\"\"Sample board config with explicit density control + bell-curve sizes.\n",
    "    If target_density_range is None, picks one from DENSITY_TARGETS.\n",
    "    \"\"\"\n",
    "    if target_density_range is None:\n",
    "        # Weighted random density band\n",
    "        weights = [w for _, w, _ in DENSITY_TARGETS]\n",
    "        ranges = [r for r, _, _ in DENSITY_TARGETS]\n",
    "        idx = rng.choices(range(len(DENSITY_TARGETS)), weights=weights, k=1)[0]\n",
    "        target_density_range = ranges[idx]\n",
    "\n",
    "    # Sample board size using bell-curve distribution\n",
    "    rows, cols = _sample_board_size(rng)\n",
    "\n",
    "    total = rows * cols\n",
    "    min_d, max_d = target_density_range\n",
    "\n",
    "    if min_d == 0.0 and max_d == 0.0:\n",
    "        return rows, cols, 0\n",
    "\n",
    "    min_mines = max(0, int(math.ceil(total * min_d)))\n",
    "    max_mines = min(int(total * max_d), int(total * MAX_MINE_DENSITY), total - 1)\n",
    "\n",
    "    if max_mines < min_mines:\n",
    "        num_mines = max(0, min(min_mines, total - 1))\n",
    "    else:\n",
    "        num_mines = rng.randint(min_mines, max_mines)\n",
    "\n",
    "    return rows, cols, num_mines\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Exhaustive edge-case configs (50+ scenarios)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "EDGE_CASE_CONFIGS = [\n",
    "    # (rows, cols, mines, label)\n",
    "\n",
    "    # === TRIVIAL BOARDS ===\n",
    "    (1, 1, 0,   \"1x1 trivial\"),\n",
    "    (2, 2, 0,   \"2x2 no mines\"),\n",
    "    (3, 3, 0,   \"3x3 no mines\"),\n",
    "    (4, 4, 0,   \"4x4 no mines\"),\n",
    "    (5, 5, 0,   \"5x5 no mines - cascade practice\"),\n",
    "\n",
    "    # === LINEAR BOARDS (1D Minesweeper) ===\n",
    "    (1, 5, 1,   \"1x5 single mine\"),\n",
    "    (1, 10, 2,  \"1x10 two mines\"),\n",
    "    (1, 20, 4,  \"1x20 row\"),\n",
    "    (1, 50, 10, \"1x50 maximum row\"),\n",
    "    (5, 1, 1,   \"5x1 column\"),\n",
    "    (10, 1, 2,  \"10x1 column\"),\n",
    "    (20, 1, 4,  \"20x1 column\"),\n",
    "    (50, 1, 10, \"50x1 maximum column\"),\n",
    "\n",
    "    # === TINY BOARDS ===\n",
    "    (1, 2, 0,   \"1x2 trivial\"),\n",
    "    (2, 1, 0,   \"2x1 trivial\"),\n",
    "    (2, 2, 1,   \"2x2 single mine\"),\n",
    "    (2, 3, 1,   \"2x3 mini\"),\n",
    "    (3, 2, 1,   \"3x2 mini\"),\n",
    "    (3, 3, 1,   \"3x3 single mine\"),\n",
    "    (3, 3, 2,   \"3x3 two mines\"),\n",
    "    (4, 4, 3,   \"4x4 medium density\"),\n",
    "\n",
    "    # === EXTREME RECTANGULAR ===\n",
    "    (2, 50, 20, \"2x50 ultra-wide\"),\n",
    "    (50, 2, 20, \"50x2 ultra-tall\"),\n",
    "    (3, 40, 24, \"3x40 extreme ratio\"),\n",
    "    (40, 3, 24, \"40x3 extreme ratio\"),\n",
    "    (5, 50, 50, \"5x50 max density wide\"),\n",
    "    (50, 5, 50, \"50x5 max density tall\"),\n",
    "\n",
    "    # === CLASSIC MINESWEEPER SIZES ===\n",
    "    (8, 8, 1,   \"8x8 very sparse\"),\n",
    "    (8, 8, 5,   \"8x8 sparse\"),\n",
    "    (8, 8, 10,  \"8x8 medium - classic beginner\"),\n",
    "    (8, 8, 13,  \"8x8 max density\"),\n",
    "    (16, 16, 10, \"16x16 sparse\"),\n",
    "    (16, 16, 40, \"16x16 medium - classic intermediate\"),\n",
    "    (16, 16, 51, \"16x16 max density\"),\n",
    "    (16, 30, 20, \"16x30 rectangular sparse\"),\n",
    "    (16, 30, 96, \"16x30 rectangular dense - classic expert\"),\n",
    "\n",
    "    # === LARGE BOARDS ===\n",
    "    (20, 20, 10, \"20x20 very sparse\"),\n",
    "    (20, 20, 80, \"20x20 max density\"),\n",
    "    (25, 25, 30, \"25x25 sparse\"),\n",
    "    (25, 25, 125, \"25x25 max density\"),\n",
    "    (30, 30, 50, \"30x30 sparse\"),\n",
    "    (30, 30, 180, \"30x30 max density\"),\n",
    "    (40, 40, 100, \"40x40 sparse\"),\n",
    "    (40, 40, 320, \"40x40 max density\"),\n",
    "\n",
    "    # === MAXIMUM SIZE ===\n",
    "    (50, 50, 10,  \"50x50 ultra-sparse\"),\n",
    "    (50, 50, 100, \"50x50 sparse\"),\n",
    "    (50, 50, 250, \"50x50 medium\"),\n",
    "    (50, 50, 500, \"50x50 maximum density\"),\n",
    "\n",
    "    # === DENSITY EDGE CASES ===\n",
    "    (10, 10, 0,  \"10x10 no mines\"),\n",
    "    (15, 15, 0,  \"15x15 no mines - large trivial\"),\n",
    "    (20, 20, 0,  \"20x20 no mines - huge trivial\"),\n",
    "    (10, 10, 1,  \"10x10 single mine\"),\n",
    "    (20, 20, 1,  \"20x20 single mine in large board\"),\n",
    "\n",
    "    # === MORE RECTANGULAR VARIETY ===\n",
    "    (3, 50, 30,  \"3x50 wide\"),\n",
    "    (50, 3, 30,  \"50x3 tall\"),\n",
    "    (5, 15, 15,  \"5x15 wide rect\"),\n",
    "    (15, 5, 15,  \"15x5 tall rect\"),\n",
    "    (6, 8, 6,    \"6x8 rect\"),\n",
    "    (8, 6, 6,    \"8x6 rect\"),\n",
    "    (7, 13, 18,  \"7x13 odd rect\"),\n",
    "    (13, 7, 18,  \"13x7 odd rect\"),\n",
    "    (15, 30, 90, \"15x30 wide large\"),\n",
    "]\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Dataset item builder (DRY helper)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _build_dataset_item(game, seed, move_history):\n",
    "    \"\"\"Build a single dataset item dict from a game state.\"\"\"\n",
    "    prompt_text = format_state_for_llm(game)\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_text},\n",
    "        ],\n",
    "        \"seed\": seed,\n",
    "        \"move_history\": json.dumps(move_history),\n",
    "        \"board_rows\": game.rows,\n",
    "        \"board_cols\": game.cols,\n",
    "        \"board_mines\": game.num_mines,\n",
    "    }\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  MAIN GENERATOR — 6-Phase Exhaustive Composition\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def generate_exhaustive_dataset(num_samples=1000, rng_seed=42):\n",
    "    \"\"\"\n",
    "    Comprehensive Minesweeper training dataset covering ALL scenarios.\n",
    "\n",
    "    6-Phase composition:\n",
    "      Phase 1: Edge cases           — 10%  (50+ explicit configs)\n",
    "      Phase 2: Opening-heavy        — 25%  (fresh + single-move boards)\n",
    "      Phase 3: Pattern-specific     — 15%  (satisfied numbers, multi-region)\n",
    "      Phase 4: Mid-game deduction   — 25%  (core logical reasoning)\n",
    "      Phase 5: Endgame completion   — 15%  (80-98% revealed, flag accounting)\n",
    "      Phase 6: Forced guess         — 10%  (no logical moves available)\n",
    "\n",
    "    Improvements over previous version:\n",
    "      ✅ 50+ edge case configs (was 25)\n",
    "      ✅ Progressive flagging 10%→30%→50% by game phase (was flat 15%)\n",
    "      ✅ Density-stratified board sampling\n",
    "      ✅ Dedicated endgame generator (was 0.7% late-game)\n",
    "      ✅ Forced-guess scenario training (was 0%)\n",
    "      ✅ Multi-region disconnected boards (was 0%)\n",
    "      ✅ Satisfied-number pattern training (was 0%)\n",
    "      ✅ 4000 samples (was 3000)\n",
    "    \"\"\"\n",
    "    rng = random.Random(rng_seed)\n",
    "    np.random.seed(rng_seed)\n",
    "\n",
    "    dataset_items = []\n",
    "    phase_counts = {\n",
    "        \"edge_case\": 0, \"opening\": 0, \"pattern\": 0,\n",
    "        \"midgame\": 0, \"endgame\": 0, \"forced_guess\": 0,\n",
    "    }\n",
    "    config_counts = {}\n",
    "    density_counts = {\"zero\": 0, \"very_sparse\": 0, \"sparse\": 0, \"medium\": 0, \"dense\": 0}\n",
    "\n",
    "    def _track_config(game):\n",
    "        key = f\"{game.rows}x{game.cols}m{game.num_mines}\"\n",
    "        config_counts[key] = config_counts.get(key, 0) + 1\n",
    "        d = game.num_mines / (game.rows * game.cols) if game.rows * game.cols > 0 else 0\n",
    "        if d == 0:\n",
    "            density_counts[\"zero\"] += 1\n",
    "        elif d <= 0.05:\n",
    "            density_counts[\"very_sparse\"] += 1\n",
    "        elif d <= 0.10:\n",
    "            density_counts[\"sparse\"] += 1\n",
    "        elif d <= 0.15:\n",
    "            density_counts[\"medium\"] += 1\n",
    "        else:\n",
    "            density_counts[\"dense\"] += 1\n",
    "\n",
    "    # Budget per phase\n",
    "    n_edge     = int(num_samples * 0.10)\n",
    "    n_opening  = int(num_samples * 0.25)\n",
    "    n_pattern  = int(num_samples * 0.15)\n",
    "    n_midgame  = int(num_samples * 0.25)\n",
    "    n_endgame  = int(num_samples * 0.15)\n",
    "    n_forced   = num_samples - n_edge - n_opening - n_pattern - n_midgame - n_endgame\n",
    "\n",
    "    print(f\"  Phase budgets: edge={n_edge}, opening={n_opening}, pattern={n_pattern}, \"\n",
    "          f\"midgame={n_midgame}, endgame={n_endgame}, forced={n_forced}\")\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 1: Edge Cases (10%) — 50+ explicit configs\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 1: Edge cases...\")\n",
    "    edge_generated = 0\n",
    "    edge_idx = 0\n",
    "    while edge_generated < n_edge:\n",
    "        ec_rows, ec_cols, ec_mines, ec_label = EDGE_CASE_CONFIGS[edge_idx % len(EDGE_CASE_CONFIGS)]\n",
    "        edge_idx += 1\n",
    "        seed = rng.randint(0, 999999)\n",
    "\n",
    "        game = MinesweeperGame(rows=ec_rows, cols=ec_cols, num_mines=ec_mines, seed=seed)\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        # 0-3 moves for variety\n",
    "        num_moves = rng.randint(0, min(3, max(0, ec_rows * ec_cols - ec_mines - 1)))\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=True)\n",
    "\n",
    "        if game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"edge_case\"] += 1\n",
    "            edge_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 2: Opening-Heavy Training (25%) — Fix 75% early death rate\n",
    "    # 75% fresh (0 moves), 25% single-move\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 2: Opening training...\")\n",
    "    opening_generated = 0\n",
    "    opening_attempts = 0\n",
    "    while opening_generated < n_opening and opening_attempts < n_opening * 5:\n",
    "        opening_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng)\n",
    "\n",
    "        seed = rng.randint(0, 999999)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "        if num_mines == 0:\n",
    "            if game.state() == \"ongoing\":\n",
    "                dataset_items.append(_build_dataset_item(game, seed, []))\n",
    "                _track_config(game)\n",
    "                phase_counts[\"opening\"] += 1\n",
    "                opening_generated += 1\n",
    "            continue\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        # 75% fresh boards, 25% single-move\n",
    "        num_moves = 0 if rng.random() < 0.75 else 1\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=False)\n",
    "\n",
    "        if game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"opening\"] += 1\n",
    "            opening_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 3: Pattern-Specific Scenarios (15%)\n",
    "    # Mix of: satisfied-number boards (60%), multi-region boards (40%)\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 3: Pattern-specific scenarios...\")\n",
    "    pattern_generated = 0\n",
    "    pattern_attempts = 0\n",
    "    while pattern_generated < n_pattern and pattern_attempts < n_pattern * 10:\n",
    "        pattern_attempts += 1\n",
    "\n",
    "        # 60% satisfied numbers, 40% multi-region\n",
    "        if rng.random() < 0.60:\n",
    "            # Satisfied numbers — need boards with mines\n",
    "            rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.20))\n",
    "            if rows < 3 or cols < 3:\n",
    "                continue\n",
    "            game, move_history, seed = _generate_satisfied_numbers_state(\n",
    "                rows, cols, num_mines, rng\n",
    "            )\n",
    "        else:\n",
    "            # Multi-region — need larger boards\n",
    "            rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.15))\n",
    "            rows = max(rows, 8)\n",
    "            cols = max(cols, 8)\n",
    "            num_mines = min(num_mines, int(rows * cols * 0.15))\n",
    "            if num_mines < 1:\n",
    "                num_mines = max(1, int(rows * cols * 0.05))\n",
    "            game, move_history, seed = _generate_multi_region_state(\n",
    "                rows, cols, num_mines, rng\n",
    "            )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"pattern\"] += 1\n",
    "            pattern_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 4: Mid-Game Logical Deduction (25%) — Core gameplay\n",
    "    # 3-15 moves played, progressive flagging, density-stratified\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 4: Mid-game deduction...\")\n",
    "    midgame_generated = 0\n",
    "    midgame_attempts = 0\n",
    "    while midgame_generated < n_midgame and midgame_attempts < n_midgame * 5:\n",
    "        midgame_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng)\n",
    "\n",
    "        if num_mines == 0:\n",
    "            continue  # Skip zero-mine for midgame\n",
    "\n",
    "        seed = rng.randint(0, 999999)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        total_safe = rows * cols - num_mines\n",
    "        max_moves = min(15, max(3, total_safe - 1))\n",
    "        num_moves = rng.randint(3, max_moves)\n",
    "\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=True)\n",
    "\n",
    "        if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"midgame\"] += 1\n",
    "            midgame_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 5: Endgame Completion (15%) — 80-98% revealed\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 5: Endgame completion...\")\n",
    "    endgame_generated = 0\n",
    "    endgame_attempts = 0\n",
    "    while endgame_generated < n_endgame and endgame_attempts < n_endgame * 10:\n",
    "        endgame_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.20))\n",
    "\n",
    "        if num_mines < 1 or rows * cols < 8:\n",
    "            continue\n",
    "\n",
    "        completion = rng.uniform(0.80, 0.95)\n",
    "        game, move_history, seed = _generate_endgame_state(\n",
    "            rows, cols, num_mines, rng, completion_target=completion\n",
    "        )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"endgame\"] += 1\n",
    "            endgame_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 6: Forced Guess Scenarios (10%) — No logical deductions\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 6: Forced guess scenarios...\")\n",
    "    forced_generated = 0\n",
    "    forced_attempts = 0\n",
    "    while forced_generated < n_forced and forced_attempts < n_forced * 15:\n",
    "        forced_attempts += 1\n",
    "        # Dense boards more likely to produce forced-guess states\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng, (0.10, 0.20))\n",
    "\n",
    "        if num_mines < 2 or rows * cols < 6:\n",
    "            continue\n",
    "\n",
    "        game, move_history, seed = _generate_forced_guess_state(\n",
    "            rows, cols, num_mines, rng\n",
    "        )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"forced_guess\"] += 1\n",
    "            forced_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # Shuffle and trim\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    rng.shuffle(dataset_items)\n",
    "    dataset_items = dataset_items[:num_samples]\n",
    "    ds = Dataset.from_list(dataset_items)\n",
    "\n",
    "    return ds, config_counts, phase_counts, density_counts\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  Generate & Analyze\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  EXHAUSTIVE DATASET GENERATION\")\n",
    "print(\"  4000 samples | 6 phases | 50+ edge cases | density-stratified\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "dataset, config_counts, phase_counts, density_counts = generate_exhaustive_dataset(\n",
    "    num_samples=1000, rng_seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(f\"Created {len(dataset)} training examples\\n\")\n",
    "\n",
    "# Extract arrays for analysis\n",
    "all_rows = [item[\"board_rows\"] for item in dataset]\n",
    "all_cols = [item[\"board_cols\"] for item in dataset]\n",
    "all_mines = [item[\"board_mines\"] for item in dataset]\n",
    "densities = [m / (r * c) * 100 if r * c > 0 else 0 for r, c, m in zip(all_rows, all_cols, all_mines)]\n",
    "\n",
    "# Phase distribution\n",
    "print(\"Phase distribution:\")\n",
    "for phase, count in phase_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    bar = '█' * int(pct / 2)\n",
    "    print(f\"  {phase:14s}: {count:4d} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "# Size band distribution (curriculum analysis)\n",
    "print(f\"\\nSize band distribution (bell-curve curriculum):\")\n",
    "for lo, hi, target_w, label in SIZE_BANDS:\n",
    "    count = sum(1 for r, c in zip(all_rows, all_cols) if max(r, c) >= lo and max(r, c) <= hi)\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    bar = '█' * int(pct / 2)\n",
    "    print(f\"  {label:6s} ({lo:2d}-{hi:2d}): {count:4d} ({pct:5.1f}%) target={target_w*100:.0f}% {bar}\")\n",
    "\n",
    "# Density distribution\n",
    "print(f\"\\nDensity distribution:\")\n",
    "for band, count in density_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    bar = '█' * int(pct / 2)\n",
    "    print(f\"  {band:12s}: {count:4d} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "# Prompt tier distribution\n",
    "print(f\"\\nPrompt tier distribution:\")\n",
    "tier_counts = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "for r, c in zip(all_rows, all_cols):\n",
    "    mx = max(r, c)\n",
    "    if mx <= 5: tier_counts[1] += 1\n",
    "    elif mx <= 12: tier_counts[2] += 1\n",
    "    elif mx <= 25: tier_counts[3] += 1\n",
    "    else: tier_counts[4] += 1\n",
    "tier_labels = {1: 'Tiny (≤5)', 2: 'Small (6-12)', 3: 'Medium (13-25)', 4: 'Large (26+)'}\n",
    "for tier, count in tier_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    bar = '█' * int(pct / 2)\n",
    "    print(f\"  Tier {tier} {tier_labels[tier]:16s}: {count:4d} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "zero_mine_count = sum(1 for m in all_mines if m == 0)\n",
    "print(f\"  Zero-mine boards: {zero_mine_count} ({zero_mine_count/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "move_counts = [len(json.loads(item[\"move_history\"])) for item in dataset]\n",
    "print(f\"\\nMove statistics:\")\n",
    "print(f\"  Min: {min(move_counts)}, Max: {max(move_counts)}, \"\n",
    "      f\"Mean: {np.mean(move_counts):.1f}, Median: {np.median(move_counts):.1f}\")\n",
    "print(f\"  Density: min={min(densities):.1f}%, max={max(densities):.1f}%, mean={np.mean(densities):.1f}%\")\n",
    "\n",
    "# Logical deduction coverage\n",
    "print(f\"\\nLogical deduction coverage:\")\n",
    "has_safe = 0\n",
    "has_mine = 0\n",
    "has_both = 0\n",
    "for item in dataset:\n",
    "    mh = json.loads(item[\"move_history\"])\n",
    "    has_flag = any(m.get(\"type\") == \"flag\" for m in mh)\n",
    "    has_rev = any(m.get(\"type\") == \"reveal\" for m in mh)\n",
    "    if has_flag:\n",
    "        has_mine += 1\n",
    "    if has_rev:\n",
    "        has_safe += 1\n",
    "    if has_flag and has_rev:\n",
    "        has_both += 1\n",
    "print(f\"  Samples with reveals: {has_safe} ({has_safe/len(dataset)*100:.1f}%)\")\n",
    "print(f\"  Samples with flags:   {has_mine} ({has_mine/len(dataset)*100:.1f}%)\")\n",
    "print(f\"  Samples with both:    {has_both} ({has_both/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "# Verify dataset columns\n",
    "print(f\"\\nDataset columns: {dataset.column_names}\")\n",
    "print(f\"  ✅ board_rows, board_cols, board_mines present for reward functions\")\n",
    "\n",
    "# Sample prompt\n",
    "print(f\"\\nSample prompt ({dataset[0]['board_rows']}x{dataset[0]['board_cols']}, \"\n",
    "      f\"{dataset[0]['board_mines']} mines):\")\n",
    "print(dataset[0][\"prompt\"][0][\"content\"][:300] + \"...\")\n",
    "\n",
    "# ── Save dataset to JSON ──\n",
    "dataset_json_path = \"minesweeper_dataset.json\"\n",
    "json_records = []\n",
    "for item in dataset:\n",
    "    record = {\n",
    "        \"seed\": item[\"seed\"],\n",
    "        \"move_history\": item[\"move_history\"],\n",
    "        \"board_rows\": item[\"board_rows\"],\n",
    "        \"board_cols\": item[\"board_cols\"],\n",
    "        \"board_mines\": item[\"board_mines\"],\n",
    "        \"prompt_text\": item[\"prompt\"][0][\"content\"],\n",
    "    }\n",
    "    json_records.append(record)\n",
    "\n",
    "with open(dataset_json_path, \"w\") as f:\n",
    "    json.dump(json_records, f, indent=2)\n",
    "\n",
    "print(f\"   {len(json_records)} records with fields: seed, move_history, board_rows/cols/mines, prompt_text\")\n",
    "print(f\"\\n✅ Dataset saved to {dataset_json_path} ({os.path.getsize(dataset_json_path) / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e4491",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Configure GRPO Training\n",
    "\n",
    "Set up GRPO trainer with all hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478959ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# ── Fix torch.compile recompilation limit ──\n",
    "# GRPO generates varying sequence lengths per step, each triggering a graph\n",
    "# recompile. Default cache_size_limit (8) is too low → FailOnRecompileLimitHit.\n",
    "# Raising it allows torch._dynamo to cache more compiled graphs.\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.cache_size_limit = 128\n",
    "torch._dynamo.config.optimize_ddp = False\n",
    "\n",
    "# ── Lengths ──\n",
    "# Training prompts include pre-computed hints (safe/mine cells).\n",
    "# Small boards (≤20): ~400-800 tokens (full grid + unified prompt)\n",
    "# Medium boards (21-35): ~500-900 tokens (frontier + unified prompt)\n",
    "# Large boards (36-50): ~400-800 tokens (summary + unified prompt)\n",
    "# 1900 + 128 = 2028 < 2048 = max_seq_length (fits comfortably)\n",
    "# 128 completion tokens: JSON-only output (hackathon constraint)\n",
    "max_prompt_length = 1900\n",
    "max_completion_length = 128  # HACKATHON CONSTRAINT: JSON-only, no reasoning\n",
    "                             # Pure JSON action is ~10-25 tokens, well under 128\n",
    "\n",
    "# ── GRPO Configuration (Simplified & Fast) ──\n",
    "training_args = GRPOConfig(\n",
    "    # === Generation ===\n",
    "    temperature = 1.0,           # Fixed at 1.0 (no annealing)\n",
    "    top_p = 0.95,\n",
    "\n",
    "    # === Optimization ===\n",
    "    learning_rate = 5e-5,        # 10× higher than before — loss was barely moving\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.10,         # Longer warmup for stability with higher LR\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    max_grad_norm = 0.5,\n",
    "\n",
    "    # === Batch sizes ===\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 2,   # Was 4 → 2× faster effective steps\n",
    "    num_generations = 16,        # Was 24 → faster per step, still enough variance\n",
    "\n",
    "    # === Lengths ===\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_completion_length,\n",
    "\n",
    "    # === Training duration ===\n",
    "    max_steps = 500,\n",
    "    save_steps = 100,\n",
    "\n",
    "    # === GRPO specific ===\n",
    "    beta = 0.01,                 # Was 0.03 → less KL restriction, faster learning\n",
    "    num_iterations = 1,          # Was 2 → halves compute per step\n",
    "\n",
    "    # === Ensure extra dataset columns are NOT removed ===\n",
    "    remove_unused_columns = False,\n",
    "\n",
    "    # === Output ===\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"minesweeper_grpo_v2\",\n",
    "    seed = 42,\n",
    "    bf16 = True,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  torch._dynamo.cache_size_limit = 128 (fix recompile crash)\")\n",
    "print(f\"  Temperature:         {training_args.temperature}  (fixed, no annealing)\")\n",
    "print(f\"  LR:                  {training_args.learning_rate}\")\n",
    "print(f\"  Beta (KL penalty):   {training_args.beta}\")\n",
    "print(f\"  Num iterations:      {training_args.num_iterations}\")\n",
    "print(f\"  Num generations:     {training_args.num_generations}\")\n",
    "print(f\"  Grad accum steps:    {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Warmup ratio:        {training_args.warmup_ratio}\")\n",
    "print(f\"  LoRA rank:           {lora_rank}\")\n",
    "print()\n",
    "print(\"Speed improvements vs previous:\")\n",
    "print(\"  • num_generations 24→16, num_iterations 2→1, grad_accum 4→2\")\n",
    "print(\"  • stop_strings=['\\\\n'] → outputs stop after JSON line (~14 tokens)\")\n",
    "print(\"  • Newline token added as EOS → outputs stop after JSON line (~14 tokens)\")\n",
    "print(\"  • LR 2e-5→5e-5, beta 0.03→0.01 → faster convergence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "# Board configs to evaluate on during training (mix of sizes from 1-50 range)\n",
    "EVAL_CONFIGS = [\n",
    "    (1, 1, 0),     # Trivial — 0 mines\n",
    "    (3, 3, 1),     # Tiny\n",
    "    (5, 5, 3),     # Small\n",
    "    (6, 6, 5),     # Standard\n",
    "    (8, 8, 10),    # Medium\n",
    "    (10, 10, 20),  # Large\n",
    "    (15, 15, 45),  # XL\n",
    "    (6, 8, 6),     # Rectangular\n",
    "    (1, 10, 2),    # Row board\n",
    "    (20, 20, 80),  # XX-Large\n",
    "]\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# FIX #3 (v2): Temperature Annealing Callback\n",
    "# Prevents policy collapse by starting with high exploration (1.2)\n",
    "# and annealing to focused generation (0.7) over first 70% of training.\n",
    "#\n",
    "# Schedule:  Steps 0-100: 1.2→1.0 | 100-300: 1.0→0.8 | 300-350: 0.8→0.7 | 350+: 0.7\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class TemperatureAnnealingCallback(TrainerCallback):\n",
    "    \"\"\"Anneal generation temperature during GRPO training.\n",
    "\n",
    "    Why: Fixed temp=1.0 caused policy collapse after ~20 steps.\n",
    "    - Early training: High temp (1.2) → diverse outputs → healthy reward variance\n",
    "    - Late training:  Low temp (0.7)  → converged policy → still enough variance\n",
    "\n",
    "    Linear annealing over first 70% of training, then fixed at final_temp.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_steps, initial_temp=1.2, final_temp=0.7):\n",
    "        self.max_steps = max_steps\n",
    "        self.initial_temp = initial_temp\n",
    "        self.final_temp = final_temp\n",
    "\n",
    "    def get_temperature(self, step):\n",
    "        \"\"\"Linear annealing over first 70% of training.\"\"\"\n",
    "        anneal_end = self.max_steps * 0.7\n",
    "        if step >= anneal_end:\n",
    "            return self.final_temp\n",
    "        progress = step / anneal_end\n",
    "        return self.initial_temp - (self.initial_temp - self.final_temp) * progress\n",
    "\n",
    "    def on_step_begin(self, args, state, control, **kwargs):\n",
    "        temp = self.get_temperature(state.global_step)\n",
    "\n",
    "        # Update the GRPOConfig temperature for next generation batch\n",
    "        args.temperature = temp\n",
    "\n",
    "        # Log every 25 steps\n",
    "        if state.global_step % 25 == 0:\n",
    "            print(f\"  [Step {state.global_step}] Temperature: {temp:.3f}\")\n",
    "\n",
    "        return control\n",
    "\n",
    "\n",
    "class MinesweeperEvalCallback(TrainerCallback):\n",
    "    \"\"\"Periodically play games during training with variable board sizes.\n",
    "\n",
    "    NO move limit — games end only on success (all safe revealed)\n",
    "    or failure (mine hit). Max iterations capped to prevent infinite loops\n",
    "    from repeated invalid actions.\n",
    "\n",
    "    FIX #5 (v2): Enhanced early stopping with:\n",
    "      - JSON reward degradation tracking (3 consecutive 30%+ drops)\n",
    "      - Mean length monitoring (warns >25, stops >40)\n",
    "      - Clipping ratio monitoring (warns >5%, stops >15%)\n",
    "      - reward_std collapse detection (warns <0.1, counts consecutive)\n",
    "      - Consecutive collapse counter (stops after 5 consecutive collapsed steps)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eval_every_steps=50, num_games=10):\n",
    "        self.eval_every_steps = eval_every_steps\n",
    "        self.num_games = min(num_games, len(EVAL_CONFIGS))\n",
    "        self.best_json_reward = 0.0\n",
    "        self.best_json_step = 0\n",
    "        self.degradation_warnings = 0\n",
    "        self.consecutive_collapse = 0         # v2: track consecutive reward_std < 0.1\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        \"\"\"Monitor training health and stop if degenerating.\"\"\"\n",
    "        if logs is None:\n",
    "            return\n",
    "\n",
    "        step = state.global_step\n",
    "\n",
    "        # ── MONITOR 1: Policy Collapse (reward_std) ──\n",
    "        reward_std = logs.get('reward_std')\n",
    "        if reward_std is not None:\n",
    "            if reward_std < 0.1:\n",
    "                self.consecutive_collapse += 1\n",
    "                mean_len = logs.get('completions/mean_length', 'N/A')\n",
    "                max_len = logs.get('completions/max_length', 'N/A')\n",
    "                print(f\"\\n⚠️  [Step {step}] reward_std={reward_std:.4f} — \"\n",
    "                      f\"NEAR-COLLAPSED POLICY ({self.consecutive_collapse} consecutive)\")\n",
    "                print(f\"    All {args.num_generations} generations producing nearly \"\n",
    "                      f\"identical outputs.\")\n",
    "                print(f\"    mean_length={mean_len}, max_length={max_len}\")\n",
    "\n",
    "                if self.consecutive_collapse >= 5:\n",
    "                    print(f\"\\n🛑 STOPPING TRAINING: Policy collapsed for 5 consecutive \"\n",
    "                          f\"logged steps!\")\n",
    "                    print(f\"    reward_std has been < 0.1 since step \"\n",
    "                          f\"~{step - self.consecutive_collapse}\")\n",
    "                    print(f\"    GRPO has zero gradient signal — training is wasted.\")\n",
    "                    control.should_training_stop = True\n",
    "            else:\n",
    "                self.consecutive_collapse = 0  # Reset on healthy variance\n",
    "\n",
    "        # ── MONITOR 2: JSON Reward Degradation ──\n",
    "        json_reward = logs.get('rewards/valid_json_reward/mean')\n",
    "        if json_reward is not None:\n",
    "            if json_reward > self.best_json_reward:\n",
    "                self.best_json_reward = json_reward\n",
    "                self.best_json_step = step\n",
    "                self.degradation_warnings = 0\n",
    "\n",
    "            elif self.best_json_reward > 0 and json_reward < self.best_json_reward * 0.7:\n",
    "                self.degradation_warnings += 1\n",
    "                mean_len = logs.get('completions/mean_length', 'N/A')\n",
    "                max_len = logs.get('completions/max_length', 'N/A')\n",
    "                clipped = logs.get('completions/clipped_ratio', 'N/A')\n",
    "                print(f\"\\n⚠️  [Step {step}] JSON reward DEGRADED: \"\n",
    "                      f\"{json_reward:.2f} < {self.best_json_reward:.2f} \"\n",
    "                      f\"(best @ step {self.best_json_step}) \"\n",
    "                      f\"[{self.degradation_warnings}/8 warnings]\")\n",
    "                print(f\"    mean_length={mean_len}, max_length={max_len}, \"\n",
    "                      f\"clipped={clipped}\")\n",
    "\n",
    "                if self.degradation_warnings >= 8:\n",
    "                    print(f\"\\n🛑 STOPPING TRAINING: JSON reward degraded 8 \"\n",
    "                          f\"consecutive times!\")\n",
    "                    print(f\"    Best: {self.best_json_reward:.2f} @ step \"\n",
    "                          f\"{self.best_json_step}\")\n",
    "                    print(f\"    Current: {json_reward:.2f} @ step {step}\")\n",
    "                    control.should_training_stop = True\n",
    "\n",
    "        # ── MONITOR 3: Mean Completion Length (verbosity) ──\n",
    "        mean_len = logs.get('completions/mean_length')\n",
    "        if mean_len is not None and mean_len > 25:\n",
    "            print(f\"\\n⚠️  [Step {step}] mean_length={mean_len:.1f} — \"\n",
    "                  f\"MODEL GETTING VERBOSE!\")\n",
    "            print(f\"    Expected: 15-20 tokens (pure JSON). Got: {mean_len:.1f}\")\n",
    "            if mean_len > 40:\n",
    "                self.degradation_warnings += 1\n",
    "                print(f\"    🛑 mean_length > 40 — model is adding reasoning text. \"\n",
    "                      f\"[{self.degradation_warnings}/8 warnings]\")\n",
    "                if self.degradation_warnings >= 8:\n",
    "                    print(f\"\\n🛑 STOPPING TRAINING: Model diverged into verbose \"\n",
    "                          f\"outputs!\")\n",
    "                    control.should_training_stop = True\n",
    "\n",
    "        # ── MONITOR 4: Clipping (hitting 128-token limit) ──\n",
    "        clipped = logs.get('completions/clipped_ratio')\n",
    "        if clipped is not None and clipped > 0.05:\n",
    "            print(f\"\\n⚠️  [Step {step}] clipped_ratio={clipped:.1%} — \"\n",
    "                  f\"responses hitting 128-token limit!\")\n",
    "            if clipped > 0.15:\n",
    "                self.degradation_warnings += 1\n",
    "                print(f\"    🛑 {clipped:.1%} truncated — model diverging! \"\n",
    "                      f\"[{self.degradation_warnings}/3 warnings]\")\n",
    "                if self.degradation_warnings >= 3:\n",
    "                    print(f\"\\n🛑 STOPPING TRAINING: Too many truncated responses!\")\n",
    "                    control.should_training_stop = True\n",
    "\n",
    "        return control\n",
    "\n",
    "    def on_step_end(self, args, state, control, model=None, processing_class=None, **kwargs):\n",
    "        if state.global_step % self.eval_every_steps != 0:\n",
    "            return\n",
    "\n",
    "        tokenizer = processing_class\n",
    "        if tokenizer is None or model is None:\n",
    "            return\n",
    "\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "\n",
    "        wins = 0\n",
    "        total_moves = 0\n",
    "        invalid_count = 0\n",
    "\n",
    "        for i in range(self.num_games):\n",
    "            rows, cols, mines = EVAL_CONFIGS[i % len(EVAL_CONFIGS)]\n",
    "            game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines,\n",
    "                                   seed=10000 + i)\n",
    "            moves = 0\n",
    "            invalids = 0\n",
    "            consecutive_invalids = 0\n",
    "            seen_actions = set()\n",
    "            repeat_count = 0\n",
    "            max_iterations = min(500, rows * cols + 100)\n",
    "\n",
    "            iteration = 0\n",
    "            while game.state() == \"ongoing\" and iteration < max_iterations:\n",
    "                iteration += 1\n",
    "                prompt = format_state_for_llm(game, mode=\"inference\")\n",
    "                text = tokenizer.apply_chat_template(\n",
    "                    [\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ],\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True,\n",
    "                )\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                                   max_length=max_prompt_length + 100)\n",
    "                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model.generate(\n",
    "                        **inputs,\n",
    "                        temperature=0.7,\n",
    "                        max_new_tokens=128,\n",
    "                        do_sample=True,\n",
    "                        top_p=0.9,\n",
    "                    )\n",
    "\n",
    "                gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "                response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "                action = parse_llm_action(response)\n",
    "\n",
    "                if action is None:\n",
    "                    invalids += 1\n",
    "                    consecutive_invalids += 1\n",
    "                    if consecutive_invalids >= 5:\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "                consecutive_invalids = 0\n",
    "\n",
    "                action_key = (action['type'], action['row'], action['col'])\n",
    "                if action_key in seen_actions:\n",
    "                    repeat_count += 1\n",
    "                    if repeat_count >= 3:\n",
    "                        break\n",
    "                else:\n",
    "                    repeat_count = 0\n",
    "                    seen_actions.add(action_key)\n",
    "\n",
    "                result = game.do_action(action)\n",
    "                if result in (\"mine\", \"win\"):\n",
    "                    moves += 1\n",
    "                    break\n",
    "                elif result == \"ok\":\n",
    "                    moves += 1\n",
    "                else:\n",
    "                    invalids += 1\n",
    "                    consecutive_invalids += 1\n",
    "                    if consecutive_invalids >= 5:\n",
    "                        break\n",
    "\n",
    "            if game.state() == \"success\":\n",
    "                wins += 1\n",
    "            total_moves += moves\n",
    "            invalid_count += invalids\n",
    "\n",
    "        win_rate = wins / self.num_games\n",
    "        avg_moves = total_moves / self.num_games\n",
    "        print(f\"\\n[Eval @ step {state.global_step}] \"\n",
    "              f\"Win: {wins}/{self.num_games} ({win_rate*100:.0f}%) | \"\n",
    "              f\"Avg moves: {avg_moves:.1f} | \"\n",
    "              f\"Invalid: {invalid_count}\\n\")\n",
    "\n",
    "        if was_training:\n",
    "            model.train()\n",
    "\n",
    "\n",
    "class CheckpointCallback(TrainerCallback):\n",
    "    \"\"\"Save LoRA adapters every N steps as named checkpoints.\"\"\"\n",
    "\n",
    "    def __init__(self, save_every_steps=100):\n",
    "        self.save_every_steps = save_every_steps\n",
    "\n",
    "    def on_step_end(self, args, state, control, model=None, processing_class=None, **kwargs):\n",
    "        if state.global_step % self.save_every_steps != 0 or state.global_step == 0:\n",
    "            return\n",
    "\n",
    "        ckpt_dir = f\"minesweeper_ckpt_step{state.global_step}\"\n",
    "        model.save_pretrained(ckpt_dir)\n",
    "        if processing_class is not None:\n",
    "            processing_class.save_pretrained(ckpt_dir)\n",
    "        print(f\"\\n💾 [Step {state.global_step}] Checkpoint saved → {ckpt_dir}/\\n\")\n",
    "\n",
    "\n",
    "# ── Instantiate callbacks ──\n",
    "eval_callback = MinesweeperEvalCallback(eval_every_steps=50, num_games=10)\n",
    "ckpt_callback = CheckpointCallback(save_every_steps=100)\n",
    "temp_callback = TemperatureAnnealingCallback(max_steps=500, initial_temp=1.2, final_temp=0.7)\n",
    "\n",
    "print(f\"Callbacks configured:\")\n",
    "print(f\"  1. MinesweeperEvalCallback: {eval_callback.num_games} games every \"\n",
    "      f\"{eval_callback.eval_every_steps} steps\")\n",
    "print(f\"     No move limit — only success or failure\")\n",
    "print(f\"     Configs: {len(EVAL_CONFIGS)} sizes from 1x1 to 20x20\")\n",
    "print(f\"  2. CheckpointCallback: LoRA adapters saved every {ckpt_callback.save_every_steps} steps\")\n",
    "print(f\"     Saves to: minesweeper_ckpt_step{{100,200,300,400,500}}/\")\n",
    "print(f\"  3. TemperatureAnnealingCallback: {temp_callback.initial_temp} → \"\n",
    "      f\"{temp_callback.final_temp} over first 70% of {temp_callback.max_steps} steps\")\n",
    "print(f\"     Schedule: 1.2→1.0 (step 0-100) | 1.0→0.8 (100-300) | 0.8→0.7 (300-350) | 0.7 fixed\")\n",
    "print()\n",
    "print(\"Early stopping monitors:\")\n",
    "print(\"  ✅ MONITOR 1: reward_std < 0.1 → stops after 5 consecutive collapsed steps\")\n",
    "print(\"  ✅ MONITOR 2: JSON reward 30%+ drop → stops after 8 consecutive warnings\")\n",
    "print(\"  ✅ MONITOR 3: mean_length > 25 warns, >40 adds degradation warning\")\n",
    "print(\"  ✅ MONITOR 4: clipped_ratio > 5% warns, >15% adds degradation warning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8e106",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Train the Model\n",
    "\n",
    "Start GRPO training with reward functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d03871",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        valid_json_reward,   # Format + exponential penalty\n",
    "        gameplay_scores,     # 12 criteria + center-opening + difficulty\n",
    "    ],\n",
    "    reward_weights = [0.60, 0.40],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    "    callbacks = [eval_callback, ckpt_callback, temp_callback],\n",
    ")\n",
    "\n",
    "print(\"Starting GRPO training...\")\n",
    "print(\"  [1] valid_json_reward  (weight: 0.60)\")\n",
    "print(\"  [2] gameplay_scores    (weight: 0.40)\")\n",
    "print(\"  Temperature: 1.2 → 0.7 (annealing)\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8d025",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Trained Model\n",
    "\n",
    "Evaluate the finetuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00276c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on variable board sizes across the full competition range\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "test_configs = [\n",
    "    (1, 1, 0, 200, \"1x1 Trivial\"),\n",
    "    (3, 3, 1, 201, \"Tiny\"),\n",
    "    (5, 5, 3, 202, \"Small/Easy\"),\n",
    "    (6, 6, 5, 99,  \"Standard\"),\n",
    "    (8, 8, 10, 101, \"Medium\"),\n",
    "    (10, 10, 20, 203, \"Large 20%\"),\n",
    "    (15, 15, 45, 204, \"XL 20%\"),\n",
    "    (1, 20, 4, 205, \"Row Board\"),\n",
    "    (20, 1, 4, 206, \"Column Board\"),\n",
    "    (5, 5, 0, 207, \"Zero Mines\"),\n",
    "]\n",
    "\n",
    "for rows, cols, mines, seed, label in test_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"=== {label} ({rows}x{cols}, {mines} mines) ===\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    test_game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "\n",
    "    # Handle already-won games (0-mine boards that auto-cascade)\n",
    "    if test_game.state() != \"ongoing\":\n",
    "        print(f\"  Game auto-resolved: {test_game.state()}\")\n",
    "        continue\n",
    "\n",
    "    test_prompt = format_state_for_llm(test_game, mode=\"inference\")\n",
    "\n",
    "    test_text = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": test_prompt},\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True,\n",
    "                       max_length=max_prompt_length + 100)\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.7,  # LAMER paper: 0.7 for eval\n",
    "        max_new_tokens=128,  # HACKATHON CONSTRAINT: JSON-only\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "\n",
    "    # Decode only generated tokens\n",
    "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "    print(f\"Response: {response_text.strip()}\")\n",
    "\n",
    "    action = parse_llm_action(response_text)\n",
    "    print(f\"Parsed action: {action}\")\n",
    "\n",
    "    if action:\n",
    "        result = test_game.do_action(action)\n",
    "        print(f\"Result: {result} | Game state: {test_game.state()}\")\n",
    "    else:\n",
    "        print(\"⚠️ Failed to parse a valid action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaeaa5b",
   "metadata": {},
   "source": [
    "# Save the Model\n",
    "\n",
    "Save your trained model for competition submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa19985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LoRA adapters\n",
    "model.save_pretrained(\"my_minesweeper_model\")\n",
    "tokenizer.save_pretrained(\"my_minesweeper_model\")\n",
    "print(\"✅ LoRA adapters saved to: my_minesweeper_model/\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Save merged model in 16bit\n",
    "# Workaround for Unsloth bug: UnboundLocalError on 'copied_tokenizer_model_from_cache'\n",
    "# when using local model paths. We manually merge LoRA weights and save with HF API.\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "import os, shutil, gc\n",
    "\n",
    "merged_dir = \"my_minesweeper_model_merged\"\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Try Unsloth's native method first (works on some versions)\n",
    "    model.save_pretrained_merged(\n",
    "        merged_dir,\n",
    "        tokenizer,\n",
    "        save_method=\"merged_16bit\",\n",
    "    )\n",
    "    print(\"✅ Merged 16-bit model saved via Unsloth\")\n",
    "except (UnboundLocalError, Exception) as e:\n",
    "    print(f\"⚠️ Unsloth merge failed ({type(e).__name__}: {e})\")\n",
    "    print(\"   Falling back to manual LoRA merge...\")\n",
    "\n",
    "    try:\n",
    "        # Manual merge: get the PEFT model, merge LoRA into base weights, save\n",
    "        from peft import PeftModel\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "        # Re-load base model in float16 for merge\n",
    "        print(\"   Loading base model for merge...\")\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"/workspace/workspace/Qwen2.5-14B-Instruct\",\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        # Load LoRA adapters on top\n",
    "        print(\"   Applying LoRA adapters...\")\n",
    "        merged_model = PeftModel.from_pretrained(base_model, \"my_minesweeper_model\")\n",
    "        merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "        # Save the fully merged model\n",
    "        print(\"   Saving merged model...\")\n",
    "        merged_model.save_pretrained(merged_dir, safe_serialization=True)\n",
    "        tokenizer.save_pretrained(merged_dir)\n",
    "\n",
    "        # Cleanup\n",
    "        del base_model, merged_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"✅ Merged 16-bit model saved to: {merged_dir}/\")\n",
    "\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ BOTH merge methods failed!\")\n",
    "        print(f\"   Unsloth error: {e}\")\n",
    "        print(f\"   Manual merge error: {e2}\")\n",
    "        print(f\"   LoRA adapters are still saved at: my_minesweeper_model/\")\n",
    "        print(f\"   You can merge manually later with:\")\n",
    "        print(f\"     from peft import PeftModel\")\n",
    "        print(f\"     base = AutoModelForCausalLM.from_pretrained('<base_model_path>')\")\n",
    "        print(f\"     merged = PeftModel.from_pretrained(base, 'my_minesweeper_model')\")\n",
    "        print(f\"     merged = merged.merge_and_unload()\")\n",
    "        print(f\"     merged.save_pretrained('{merged_dir}')\")\n",
    "\n",
    "# Verify saved files\n",
    "saved_files = os.listdir(merged_dir)\n",
    "safetensors = [f for f in saved_files if f.endswith(\".safetensors\")]\n",
    "print(f\"   Files: {len(saved_files)} total, {len(safetensors)} safetensors shards\")\n",
    "print(f\"   Config: {'config.json' in saved_files}  Tokenizer: {'tokenizer.json' in saved_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2551f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Exhaustive Evaluation: Full Competition Range\n",
    "\n",
    "Play complete games across 37 board configurations (1×1 to 50×50, 0-20% mines).\n",
    "**No move limit** — only two outcomes: SUCCESS (all safe cells revealed) or FAILURE (mine revealed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31315fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_full_game(model, tokenizer, rows=6, cols=6, num_mines=5, seed=None,\n",
    "                   verbose=False):\n",
    "    \"\"\"Play a complete Minesweeper game, tracking detailed metrics.\n",
    "\n",
    "    Supports any board size from 1x1 to 50x50.\n",
    "    NO move limit — game ends ONLY on:\n",
    "      - SUCCESS: all non-mine cells are revealed\n",
    "      - FAILURE: any mine cell is revealed\n",
    "    A safety iteration cap prevents infinite loops from repeated invalid actions.\n",
    "    \"\"\"\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    # Edge case: game already won (e.g., 0-mine board)\n",
    "    if game.state() != \"ongoing\":\n",
    "        return {\n",
    "            \"game\": game,\n",
    "            \"moves\": 0,\n",
    "            \"logical_moves\": 0,\n",
    "            \"flags_correct\": 0,\n",
    "            \"flags_wrong\": 0,\n",
    "            \"total_invalids\": 0,\n",
    "            \"result\": game.state(),\n",
    "            \"progress\": game.progress(),\n",
    "            \"config\": f\"{rows}x{cols}m{num_mines}\",\n",
    "        }\n",
    "\n",
    "    moves = 0\n",
    "    consecutive_invalids = 0\n",
    "    total_invalids = 0\n",
    "    logical_moves = 0\n",
    "    flags_correct = 0\n",
    "    flags_wrong = 0\n",
    "    seen_actions = set()   # Fix #4: detect repeated actions (stuck loop)\n",
    "    repeat_count = 0       # Fix #4: consecutive repeat counter\n",
    "    # Safety cap to prevent infinite loops — NOT a game move limit\n",
    "    # Capped at 500 to prevent runaway 50×50 evals (was rows*cols*3+50 = 7550 for 50×50)\n",
    "    max_iterations = min(500, rows * cols + 100)\n",
    "\n",
    "    iteration = 0\n",
    "    while game.state() == \"ongoing\" and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        prompt = format_state_for_llm(game, mode=\"inference\")\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                           max_length=max_prompt_length + 100)\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                temperature=0.7,  # LAMER paper: 0.7 for eval\n",
    "                max_new_tokens=128,  # HACKATHON CONSTRAINT: JSON-only\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # Decode ONLY generated tokens\n",
    "        gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "        response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            consecutive_invalids += 1\n",
    "            total_invalids += 1\n",
    "            if consecutive_invalids >= 5:\n",
    "                break  # Agent is stuck — abort\n",
    "            continue\n",
    "\n",
    "        # Fix #4: Check for repeated actions (stuck detection)\n",
    "        action_key = (action['type'], action['row'], action['col'])\n",
    "        if action_key in seen_actions:\n",
    "            repeat_count += 1\n",
    "            if repeat_count >= 3:  # Same move 3 times = stuck\n",
    "                break\n",
    "        else:\n",
    "            repeat_count = 0\n",
    "            seen_actions.add(action_key)\n",
    "\n",
    "        # Track logical moves (compute BEFORE applying action)\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "        r, c = action[\"row\"], action[\"col\"]\n",
    "        if action[\"type\"] == \"reveal\" and (r, c) in safe_set:\n",
    "            logical_moves += 1\n",
    "        elif action[\"type\"] == \"flag\" and (r, c) in mine_set:\n",
    "            logical_moves += 1\n",
    "\n",
    "        # Track flag accuracy\n",
    "        if action[\"type\"] == \"flag\":\n",
    "            if 0 <= r < game.rows and 0 <= c < game.cols:\n",
    "                if game._board[r][c] == -1:\n",
    "                    flags_correct += 1\n",
    "                else:\n",
    "                    flags_wrong += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  Move {moves}: {action}\")\n",
    "\n",
    "        result = game.do_action(action)\n",
    "        if result in (\"mine\", \"win\", \"ok\"):\n",
    "            moves += 1\n",
    "        elif result in (\"out_of_bounds\", \"already_revealed\", \"flagged_cell\",\n",
    "                         \"invalid_flag\", \"invalid_format\"):\n",
    "            # Invalid moves don't count but game stays ongoing\n",
    "            total_invalids += 1\n",
    "            consecutive_invalids += 1\n",
    "            if consecutive_invalids >= 5:\n",
    "                break\n",
    "\n",
    "        if result in (\"mine\", \"win\"):\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"game\": game,\n",
    "        \"moves\": moves,\n",
    "        \"logical_moves\": logical_moves,\n",
    "        \"flags_correct\": flags_correct,\n",
    "        \"flags_wrong\": flags_wrong,\n",
    "        \"total_invalids\": total_invalids,\n",
    "        \"result\": game.state(),\n",
    "        \"progress\": game.progress(),\n",
    "        \"config\": f\"{rows}x{cols}m{num_mines}\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# EXHAUSTIVE Multi-Size Evaluation — Competition Spec\n",
    "# n, m ∈ [1, 50], mines 0-20% of total cells\n",
    "# Only two outcomes: SUCCESS or FAILURE (no timeouts)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "EVAL_SUITE = [\n",
    "    # (rows, cols, mines, num_games, label)\n",
    "\n",
    "    # === Trivial / Edge Cases ===\n",
    "    (1, 1, 0,   5,  \"1x1 trivial\"),\n",
    "    (1, 2, 0,   5,  \"1x2 trivial\"),\n",
    "    (2, 1, 0,   5,  \"2x1 trivial\"),\n",
    "    (2, 2, 0,   5,  \"2x2 no mines\"),\n",
    "    (3, 3, 0,   5,  \"3x3 no mines\"),\n",
    "    (5, 5, 0,   5,  \"5x5 no mines\"),\n",
    "\n",
    "    # === Tiny Boards ===\n",
    "    (3, 3, 1,  10,  \"3x3 1 mine\"),\n",
    "    (4, 4, 3,  10,  \"4x4 3 mines\"),\n",
    "\n",
    "    # === Small Boards ===\n",
    "    (5, 5, 3,  15,  \"5x5 easy\"),\n",
    "    (5, 5, 5,  10,  \"5x5 max density\"),\n",
    "\n",
    "    # === Standard ===\n",
    "    (6, 6, 5,  20,  \"6x6 standard\"),\n",
    "    (6, 6, 7,  10,  \"6x6 hard\"),\n",
    "\n",
    "    # === Medium ===\n",
    "    (7, 7, 7,  10,  \"7x7 medium\"),\n",
    "    (8, 8, 10, 10,  \"8x8 medium\"),\n",
    "    (8, 8, 12, 10,  \"8x8 max density\"),\n",
    "\n",
    "    # === Large ===\n",
    "    (10, 10, 10,  5, \"10x10 10%\"),\n",
    "    (10, 10, 20, 10, \"10x10 20%\"),\n",
    "    (15, 15, 45,  5, \"15x15 20%\"),\n",
    "\n",
    "    # === XL ===\n",
    "    (20, 20, 80,  3, \"20x20 20%\"),\n",
    "    (25, 25, 125, 3, \"25x25 20%\"),\n",
    "    (30, 30, 180, 2, \"30x30 20%\"),\n",
    "\n",
    "    # === XXL ===\n",
    "    (40, 40, 320, 2, \"40x40 20%\"),\n",
    "    (50, 50, 500, 2, \"50x50 20%\"),\n",
    "\n",
    "    # === Rectangular ===\n",
    "    (1, 10, 2,   5, \"1x10 row\"),\n",
    "    (10, 1, 2,   5, \"10x1 column\"),\n",
    "    (1, 50, 10,  3, \"1x50 row\"),\n",
    "    (50, 1, 10,  3, \"50x1 column\"),\n",
    "    (6, 8, 6,    5, \"6x8 rect\"),\n",
    "    (8, 6, 6,    5, \"8x6 rect\"),\n",
    "    (5, 15, 15,  3, \"5x15 wide\"),\n",
    "    (15, 5, 15,  3, \"15x5 tall\"),\n",
    "    (3, 50, 30,  2, \"3x50 extreme wide\"),\n",
    "    (50, 3, 30,  2, \"50x3 extreme tall\"),\n",
    "\n",
    "    # === Sparse (low density) ===\n",
    "    (10, 10, 1,  5, \"10x10 sparse\"),\n",
    "    (20, 20, 4,  3, \"20x20 sparse\"),\n",
    "    (50, 50, 10, 2, \"50x50 sparse\"),\n",
    "\n",
    "    # === Progressive Difficulty (Fix #10: LAMER generalization test) ===\n",
    "    # Same size, increasing mines — tests density scaling\n",
    "    (10, 10, 5,  5, \"10x10 5% progressive\"),\n",
    "    (10, 10, 15, 5, \"10x10 15% progressive\"),\n",
    "\n",
    "    # Increasing size, same ~10% density — tests size scaling\n",
    "    (15, 15, 23, 3, \"15x15 10% density\"),\n",
    "    (20, 20, 40, 3, \"20x20 10% density\"),\n",
    "\n",
    "    # Generalization to harder unseen configs\n",
    "    (25, 25, 62, 2, \"25x25 10% generalization\"),\n",
    "    (30, 30, 90, 2, \"30x30 10% generalization\"),\n",
    "]\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "total_games = sum(n for _,_,_,n,_ in EVAL_SUITE)\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  EXHAUSTIVE EVALUATION — {total_games} games across {len(EVAL_SUITE)} configs\")\n",
    "print(f\"  Competition spec: n,m ∈ [1,50], mines 0-20%, no move limit\")\n",
    "print(f\"  Includes progressive difficulty test (LAMER generalization)\")\n",
    "print(f\"  Only two outcomes: SUCCESS or FAILURE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "all_results = []\n",
    "per_config_stats = {}\n",
    "\n",
    "for rows, cols, mines, num_games, label in EVAL_SUITE:\n",
    "    config_key = f\"{rows}x{cols}m{mines}\"\n",
    "    wins = 0\n",
    "    fails = 0\n",
    "    config_results = []\n",
    "\n",
    "    for i in range(num_games):\n",
    "        info = play_full_game(model, tokenizer, rows=rows, cols=cols,\n",
    "                              num_mines=mines, seed=5000 + i + hash(config_key) % 10000)\n",
    "        config_results.append(info)\n",
    "        all_results.append(info)\n",
    "\n",
    "        if info[\"result\"] == \"success\":\n",
    "            wins += 1\n",
    "        elif info[\"result\"] == \"failed\":\n",
    "            fails += 1\n",
    "\n",
    "    # Per-config summary\n",
    "    avg_moves = np.mean([r[\"moves\"] for r in config_results])\n",
    "    avg_logical = np.mean([r[\"logical_moves\"] for r in config_results])\n",
    "    avg_progress = np.mean([r[\"progress\"] for r in config_results])\n",
    "    avg_invalids = np.mean([r[\"total_invalids\"] for r in config_results])\n",
    "    stuck = sum(1 for r in config_results if r[\"result\"] == \"ongoing\")\n",
    "    wr = wins / num_games * 100\n",
    "\n",
    "    per_config_stats[config_key] = {\n",
    "        \"label\": label, \"wins\": wins, \"fails\": fails, \"stuck\": stuck,\n",
    "        \"total\": num_games, \"win_rate\": wr,\n",
    "        \"avg_moves\": avg_moves, \"avg_progress\": avg_progress,\n",
    "    }\n",
    "\n",
    "    status_icon = \"✅\" if wr >= 50 else \"⚠️\" if wr >= 20 else \"❌\"\n",
    "    print(f\"  {status_icon} {label:22s} ({config_key:12s}): \"\n",
    "          f\"{wins:2d}/{num_games:2d} wins ({wr:5.1f}%) | \"\n",
    "          f\"fails={fails} stuck={stuck} | \"\n",
    "          f\"moves={avg_moves:5.1f} | logical={avg_logical:4.1f} | \"\n",
    "          f\"progress={avg_progress:.0%} | invalids={avg_invalids:.1f}\")\n",
    "\n",
    "# ── Overall Summary ──\n",
    "total_games_actual = len(all_results)\n",
    "total_wins = sum(1 for r in all_results if r[\"result\"] == \"success\")\n",
    "total_fails = sum(1 for r in all_results if r[\"result\"] == \"failed\")\n",
    "total_stuck = sum(1 for r in all_results if r[\"result\"] == \"ongoing\")\n",
    "fc = sum(r[\"flags_correct\"] for r in all_results)\n",
    "fw = sum(r[\"flags_wrong\"] for r in all_results)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  OVERALL: {total_wins}/{total_games_actual} wins ({total_wins/total_games_actual*100:.1f}%)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Wins (success):    {total_wins:4d} ({total_wins/total_games_actual*100:.1f}%)\")\n",
    "print(f\"  Losses (failure):  {total_fails:4d} ({total_fails/total_games_actual*100:.1f}%)\")\n",
    "print(f\"  Stuck (loop cap):  {total_stuck:4d} ({total_stuck/total_games_actual*100:.1f}%)\")\n",
    "print(f\"  Avg moves:         {np.mean([r['moves'] for r in all_results]):.1f}\")\n",
    "print(f\"  Avg progress:      {np.mean([r['progress'] for r in all_results]):.0%}\")\n",
    "print(f\"  Avg logical moves: {np.mean([r['logical_moves'] for r in all_results]):.1f}\")\n",
    "if fc + fw > 0:\n",
    "    print(f\"  Flag accuracy:     {fc}/{fc+fw} ({fc/(fc+fw)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"  Flags: none placed\")\n",
    "\n",
    "# ── Category Breakdown ──\n",
    "categories = {\n",
    "    \"Trivial (0 mines)\": [k for k, v in per_config_stats.items() if \"m0\" in k],\n",
    "    \"Tiny (≤4x4)\":       [k for k, v in per_config_stats.items()\n",
    "                           if v[\"label\"].startswith((\"3x3\", \"4x4\")) and \"m0\" not in k],\n",
    "    \"Small (5x5)\":       [k for k, v in per_config_stats.items() if k.startswith(\"5x5\")],\n",
    "    \"Standard (6x6)\":    [k for k, v in per_config_stats.items() if k.startswith(\"6x6\")],\n",
    "    \"Medium (7-8)\":      [k for k, v in per_config_stats.items()\n",
    "                           if k.startswith((\"7x7\", \"8x8\"))],\n",
    "    \"Large (10-15)\":     [k for k, v in per_config_stats.items()\n",
    "                           if k.startswith((\"10x10\", \"15x15\"))],\n",
    "    \"XL (20-50)\":        [k for k, v in per_config_stats.items()\n",
    "                           if k.startswith((\"20x20\", \"25x25\", \"30x30\", \"40x40\", \"50x50\"))],\n",
    "    \"Rectangular\":       [k for k, v in per_config_stats.items()\n",
    "                           if \"rect\" in v[\"label\"] or \"row\" in v[\"label\"]\n",
    "                           or \"column\" in v[\"label\"] or \"wide\" in v[\"label\"]\n",
    "                           or \"tall\" in v[\"label\"]],\n",
    "    \"Sparse\":            [k for k, v in per_config_stats.items() if \"sparse\" in v[\"label\"]],\n",
    "    \"Progressive\":       [k for k, v in per_config_stats.items()\n",
    "                           if \"progressive\" in v[\"label\"] or \"generalization\" in v[\"label\"]\n",
    "                           or \"density\" in v[\"label\"]],\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  CATEGORY BREAKDOWN\")\n",
    "print(f\"{'='*80}\")\n",
    "for cat_name, keys in categories.items():\n",
    "    if not keys:\n",
    "        continue\n",
    "    cat_wins = sum(per_config_stats[k][\"wins\"] for k in keys)\n",
    "    cat_total = sum(per_config_stats[k][\"total\"] for k in keys)\n",
    "    if cat_total > 0:\n",
    "        cat_wr = cat_wins / cat_total * 100\n",
    "        icon = \"✅\" if cat_wr >= 50 else \"⚠️\" if cat_wr >= 20 else \"❌\"\n",
    "        print(f\"  {icon} {cat_name:22s}: {cat_wins:3d}/{cat_total:3d} ({cat_wr:5.1f}%)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaed02d",
   "metadata": {},
   "source": [
    "# Inference from Merged Model\n",
    "\n",
    "Load the saved merged model from disk (no LoRA, no Unsloth) and verify it works for Minesweeper inference.\n",
    "This tests that the model was saved correctly and can be loaded independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Load merged model from disk for inference testing\n",
    "# No Unsloth, no LoRA — pure HuggingFace transformers\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "import torch, gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "merged_dir = \"my_minesweeper_model_merged\"\n",
    "\n",
    "print(f\"Loading merged model from: {merged_dir}/\")\n",
    "print(\"  (This is a standalone model — no LoRA adapters needed)\")\n",
    "\n",
    "# Load tokenizer\n",
    "merged_tokenizer = AutoTokenizer.from_pretrained(merged_dir)\n",
    "print(f\"  ✅ Tokenizer loaded ({merged_tokenizer.vocab_size} vocab)\")\n",
    "\n",
    "# Load model\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "merged_model.eval()\n",
    "print(f\"  ✅ Model loaded on {merged_model.device}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in merged_model.parameters()):,}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Run inference on a diverse set of Minesweeper boards\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "test_configs = [\n",
    "    (1, 1, 0, 300, \"1×1 Trivial\"),\n",
    "    (3, 3, 1, 301, \"Tiny 3×3\"),\n",
    "    (5, 5, 3, 302, \"Small 5×5\"),\n",
    "    (6, 6, 5, 99,  \"Standard 6×6\"),\n",
    "    (8, 8, 10, 303, \"Medium 8×8\"),\n",
    "    (10, 10, 20, 304, \"Large 10×10\"),\n",
    "    (15, 15, 45, 305, \"XL 15×15\"),\n",
    "    (1, 20, 4, 306, \"Linear 1×20\"),\n",
    "    (5, 5, 0, 307, \"Zero Mines 5×5\"),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  MERGED MODEL INFERENCE TEST — {len(test_configs)} boards\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "results = {\"pass\": 0, \"fail\": 0, \"skip\": 0}\n",
    "\n",
    "for rows, cols, mines, seed, label in test_configs:\n",
    "    print(f\"\\n--- {label} ({rows}×{cols}, {mines} mines, seed={seed}) ---\")\n",
    "\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        print(f\"  Game auto-resolved: {game.state()}\")\n",
    "        results[\"skip\"] += 1\n",
    "        continue\n",
    "\n",
    "    # Build prompt using the same inference prompt system\n",
    "    prompt = format_state_for_llm(game, mode=\"inference\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    text = merged_tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = merged_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(merged_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = merged_model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.7,       # LAMER paper: 0.7 for eval\n",
    "            max_new_tokens=128,    # HACKATHON CONSTRAINT: JSON-only\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "        )\n",
    "\n",
    "    # Decode only generated tokens (not the prompt)\n",
    "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response = merged_tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "    print(f\"  Response: {response[:200]}{'...' if len(response) > 200 else ''}\")\n",
    "\n",
    "    action = parse_llm_action(response)\n",
    "    print(f\"  Parsed:   {action}\")\n",
    "\n",
    "    if action:\n",
    "        result = game.do_action(action)\n",
    "        state = game.state()\n",
    "        print(f\"  Result:   {result} → game {state}\")\n",
    "        if result != \"mine\":\n",
    "            results[\"pass\"] += 1\n",
    "        else:\n",
    "            results[\"fail\"] += 1\n",
    "    else:\n",
    "        print(f\"  ⚠️ Failed to parse valid action\")\n",
    "        results[\"fail\"] += 1\n",
    "\n",
    "# ── Summary ──\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  INFERENCE TEST SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Pass (valid move): {results['pass']}/{results['pass'] + results['fail']}\")\n",
    "print(f\"  Fail (bad parse/mine): {results['fail']}\")\n",
    "print(f\"  Skipped (auto-win): {results['skip']}\")\n",
    "total = results['pass'] + results['fail']\n",
    "if total > 0:\n",
    "    print(f\"  Success rate: {results['pass']/total*100:.1f}%\")\n",
    "print(f\"\\n✅ Merged model inference test complete!\")\n",
    "print(f\"   Model path: {merged_dir}/\")\n",
    "print(f\"   Ready for competition submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c190f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Training Notes\n",
    "\n",
    "## Reward Functions (2 total)\n",
    "\n",
    "| # | Function | Weight | Source |\n",
    "|---|----------|--------|--------|\n",
    "| 1 | `valid_json_reward` | 0.60 | GRPO-LEAD: exponential length penalty |\n",
    "| 2 | `gameplay_scores` | 0.40 | XRPO: 12 criteria + center-opening + difficulty |\n",
    "\n",
    "**Removed:** `strategic_reward` (was 5% weight = noise, ran constraint solver redundantly). Center-opening bonus folded into `gameplay_scores`.\n",
    "\n",
    "## Key Config\n",
    "\n",
    "| Parameter | Value | Source |\n",
    "|-----------|-------|--------|\n",
    "| temperature | 1.2→0.7 (annealed) | Prevents collapse |\n",
    "| learning_rate | 5e-5 | Higher for faster convergence |\n",
    "| num_iterations | 1 | Halved for speed |\n",
    "| beta (KL) | 0.01 | Less KL restriction |\n",
    "| num_generations | 16 | Faster per step |\n",
    "| grad_accum_steps | 2 | 2× faster effective steps |\n",
    "| reward_weights | [0.60, 0.40] | Format dominates |\n",
    "| max_completion_length | 128 | Hackathon constraint |\n",
    "| Format penalties | Exponential | -1.0 × 1.5^((extra-3)/5) |\n",
    "\n",
    "## Early Stopping (4 monitors)\n",
    "\n",
    "| Monitor | Warn | Stop |\n",
    "|---------|------|------|\n",
    "| reward_std | < 0.1 | 5 consecutive collapsed steps |\n",
    "| JSON reward | 30% drop | 8 consecutive warnings |\n",
    "| mean_length | > 25 tokens | > 40 tokens |\n",
    "| clipped_ratio | > 5% | > 15% |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
