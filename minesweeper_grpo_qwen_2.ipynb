{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48060c32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper LLM Competition - Custom GRPO Training\n",
    "\n",
    "## Goal\n",
    "Finetune an LLM with LoRA using GRPO to play Minesweeper by:\n",
    "- **Input**: JSON game state (board configuration)\n",
    "- **Output**: JSON action (reveal or flag a cell)\n",
    "\n",
    "Teams will compete to train the best Minesweeper-playing LLM!\n",
    "\n",
    "## Training Approach\n",
    "- **Model**: Qwen2.5-14B-Instruct (from /root/.cache/huggingface/hub)\n",
    "- **Method**: GRPO (Group Relative Policy Optimization)\n",
    "- **Framework**: Unsloth (2-6x faster, 70% less VRAM)\n",
    "- **Hardware**: AMD MI300X GPU (192GB HBM3, ROCm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c2e56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load Model with Unsloth\n",
    "\n",
    "Load Qwen3-4B with LoRA configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e1118e-9532-4aa3-a4eb-ecf1bb2abb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"./workspace/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ecb51d-67e6-42e4-b739-cea6e57ab2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignored error while writing commit hash to /root/.cache/huggingface/models--unsloth--Qwen2.5-14B-Instruct/refs/main: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--unsloth--Qwen2.5-14B-Instruct'.\n",
      "[2026-02-14 12:21:41] WARNING _snapshot_download.py:300: Ignored error while writing commit hash to /root/.cache/huggingface/models--unsloth--Qwen2.5-14B-Instruct/refs/main: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--unsloth--Qwen2.5-14B-Instruct'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/workspace/Qwen2.5-14B-Instruct'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"unsloth/Qwen2.5-14B-Instruct\",\n",
    "    local_dir=\"./workspace/Qwen2.5-14B-Instruct\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af32493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "==((====))==  Unsloth 2025.10.6: Fast Qwen2 patching. Transformers: 4.56.2. vLLM: 0.11.1rc2.dev161+g8a297115e.rocm700.\n",
      "   \\\\   /|    . Num GPUs = 1. Max memory: 255.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+gitb2fb688. ROCm Toolkit: 7.0.51831-a3e329ad8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02af46566cd4473087c192a21fb727c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "# Load config\n",
    "with open(\"minesweeper_config_me.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "lora_rank = config.get(\"lora_rank\", 32)\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"/workspace/workspace/Qwen2.5-14B-Instruct\",\n",
    "    load_in_4bit=False,   # AMD → 4bit disabled\n",
    "    max_seq_length=2048,  # Increased: larger boards need longer prompts\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Device: {model.device}\")\n",
    "print(f\"LoRA rank: {lora_rank} (from config)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f0712",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Add LoRA Adapters\n",
    "\n",
    "Add LoRA layers for efficient finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd54ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.10.6 patched 48 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA config: rank=32, alpha=32, dropout=0.05\n",
      "trainable params: 137,625,600 || all params: 14,907,659,264 || trainable%: 0.9232\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank,           # alpha = rank → scaling factor = 1.0 (stable training)\n",
    "    lora_dropout = 0.05,              # Small dropout for regularization\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "print(f\"LoRA config: rank={lora_rank}, alpha={lora_rank}, dropout=0.05\")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503f9af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper Game Implementation\n",
    "\n",
    "Custom Minesweeper environment supporting:\n",
    "- Customizable board size and mine count\n",
    "- Actions: reveal or flag cells\n",
    "- Win: reveal all safe cells\n",
    "- Lose: reveal a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Set\n",
    "import random\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Board size configurations for training and evaluation\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "BOARD_CONFIGS = [\n",
    "    # (rows, cols, num_mines, weight) — weight controls sampling probability\n",
    "    (5, 5,  3, 0.10),   # Small / easy\n",
    "    (5, 5,  5, 0.05),   # Small / hard\n",
    "    (6, 6,  5, 0.20),   # Default (competition likely uses this)\n",
    "    (6, 6,  7, 0.10),   # Default / hard\n",
    "    (7, 7,  7, 0.10),   # Medium\n",
    "    (7, 7, 10, 0.05),   # Medium / hard\n",
    "    (8, 8,  8, 0.10),   # Larger\n",
    "    (8, 8, 10, 0.10),   # Larger / hard\n",
    "    (9, 9, 10, 0.10),   # Large\n",
    "    (10,10,12, 0.05),   # Extra large\n",
    "    (6, 8,  6, 0.03),   # Rectangular\n",
    "    (8, 6,  6, 0.02),   # Rectangular (tall)\n",
    "]\n",
    "\n",
    "def sample_board_config(rng=None):\n",
    "    \"\"\"Sample a (rows, cols, num_mines) tuple from BOARD_CONFIGS.\"\"\"\n",
    "    rng = rng or random.Random()\n",
    "    weights = [w for _, _, _, w in BOARD_CONFIGS]\n",
    "    chosen = rng.choices(BOARD_CONFIGS, weights=weights, k=1)[0]\n",
    "    return chosen[0], chosen[1], chosen[2]\n",
    "\n",
    "\n",
    "def mine_density(rows, cols, num_mines):\n",
    "    \"\"\"Compute mine density as a fraction.\"\"\"\n",
    "    return num_mines / (rows * cols)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MinesweeperGame:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    num_mines: int\n",
    "    seed: Optional[int] = None\n",
    "    _rng: random.Random = field(init=False, repr=False)\n",
    "    _board: List[List[int]] = field(init=False, repr=False)  # -1 = mine, 0-8 = count\n",
    "    _revealed: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _flagged: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _state: str = field(default=\"ongoing\", init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # ── Input validation ──\n",
    "        if self.rows < 2 or self.cols < 2:\n",
    "            raise ValueError(f\"Board too small: {self.rows}x{self.cols} (min 2x2)\")\n",
    "        if self.rows > 30 or self.cols > 30:\n",
    "            raise ValueError(f\"Board too large: {self.rows}x{self.cols} (max 30x30)\")\n",
    "        if self.num_mines < 1:\n",
    "            raise ValueError(f\"Need at least 1 mine, got {self.num_mines}\")\n",
    "        if self.num_mines >= self.rows * self.cols:\n",
    "            raise ValueError(f\"Too many mines ({self.num_mines}) for {self.rows}x{self.cols} board\")\n",
    "        if mine_density(self.rows, self.cols, self.num_mines) > 0.50:\n",
    "            pass  # Allow but warn — very hard boards\n",
    "\n",
    "        self._rng = random.Random(self.seed)\n",
    "        self._board = [[0 for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "        self._place_mines()\n",
    "        self._calculate_numbers()\n",
    "\n",
    "    def _place_mines(self):\n",
    "        \"\"\"Place mines randomly on the board.\"\"\"\n",
    "        positions = [(r, c) for r in range(self.rows) for c in range(self.cols)]\n",
    "        mine_positions = self._rng.sample(positions, self.num_mines)\n",
    "        for r, c in mine_positions:\n",
    "            self._board[r][c] = -1\n",
    "\n",
    "    def _calculate_numbers(self):\n",
    "        \"\"\"Calculate numbers for each cell based on adjacent mines.\"\"\"\n",
    "        for r in range(self.rows):\n",
    "            for c in range(self.cols):\n",
    "                if self._board[r][c] == -1:\n",
    "                    continue\n",
    "                count = 0\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if 0 <= nr < self.rows and 0 <= nc < self.cols:\n",
    "                            if self._board[nr][nc] == -1:\n",
    "                                count += 1\n",
    "                self._board[r][c] = count\n",
    "\n",
    "    def _reveal_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Reveal a cell. Returns True if valid move, False if invalid.\n",
    "        Uses iterative flood-fill to avoid recursion limit on large boards.\n",
    "        \"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed or (row, col) in self._flagged:\n",
    "            return False\n",
    "\n",
    "        stack = [(row, col)]\n",
    "        while stack:\n",
    "            r, c = stack.pop()\n",
    "            if (r, c) in self._revealed:\n",
    "                continue\n",
    "\n",
    "            self._revealed.add((r, c))\n",
    "\n",
    "            # Hit a mine!\n",
    "            if self._board[r][c] == -1:\n",
    "                self._state = \"failed\"\n",
    "                return True\n",
    "\n",
    "            # Auto-reveal neighbors if cell is 0\n",
    "            if self._board[r][c] == 0:\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < self.rows and 0 <= nc < self.cols\n",
    "                                and (nr, nc) not in self._revealed\n",
    "                                and (nr, nc) not in self._flagged):\n",
    "                            stack.append((nr, nc))\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _flag_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Flag/unflag a cell. Returns True if valid, False if invalid.\"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed:\n",
    "            return False\n",
    "\n",
    "        if (row, col) in self._flagged:\n",
    "            self._flagged.remove((row, col))\n",
    "        else:\n",
    "            self._flagged.add((row, col))\n",
    "        return True\n",
    "\n",
    "    def do_action(self, action: dict) -> str:\n",
    "        \"\"\"Execute an action and return a status string.\n",
    "\n",
    "        Returns one of:\n",
    "          'ok'               - valid move executed\n",
    "          'mine'             - revealed a mine (game over → state='failed')\n",
    "          'win'              - game won after this move\n",
    "          'invalid_format'   - bad action dict / missing keys / bad types\n",
    "          'out_of_bounds'    - coordinates outside the board\n",
    "          'already_revealed' - cell was already revealed\n",
    "          'flagged_cell'     - tried to reveal a flagged cell\n",
    "          'invalid_flag'     - tried to flag a revealed cell\n",
    "          'game_over'        - game was already over before this call\n",
    "\n",
    "        FIX: Only 'mine' sets state='failed'. All other invalid moves\n",
    "        return an error string but keep the game 'ongoing' so the agent\n",
    "        can retry or the reward function can distinguish error types.\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return \"game_over\"\n",
    "\n",
    "        if not isinstance(action, dict):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        action_type = action.get(\"type\")\n",
    "        row = action.get(\"row\")\n",
    "        col = action.get(\"col\")\n",
    "\n",
    "        if action_type not in (\"reveal\", \"flag\") or row is None or col is None:\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        try:\n",
    "            row, col = int(row), int(col)\n",
    "        except (ValueError, TypeError):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return \"out_of_bounds\"\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"already_revealed\"\n",
    "            if (row, col) in self._flagged:\n",
    "                return \"flagged_cell\"\n",
    "            self._reveal_cell(row, col)\n",
    "        else:  # flag\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"invalid_flag\"\n",
    "            self._flag_cell(row, col)\n",
    "\n",
    "        self._check_win()\n",
    "\n",
    "        if self._state == \"failed\":\n",
    "            return \"mine\"\n",
    "        if self._state == \"success\":\n",
    "            return \"win\"\n",
    "        return \"ok\"\n",
    "\n",
    "    def _check_win(self):\n",
    "        \"\"\"Check if player has won.\n",
    "\n",
    "        Win condition: ALL safe cells are revealed.\n",
    "        Alternative win: all mines are correctly flagged AND all safe\n",
    "        cells are revealed. (In standard Minesweeper, revealing all\n",
    "        safe cells is sufficient — flags are optional.)\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return\n",
    "        total_cells = self.rows * self.cols\n",
    "        safe_cells = total_cells - self.num_mines\n",
    "        if len(self._revealed) >= safe_cells:\n",
    "            # Verify no mines were revealed (shouldn't happen if state is ongoing)\n",
    "            self._state = \"success\"\n",
    "\n",
    "    def get_visible_board(self) -> List[List[str]]:\n",
    "        \"\"\"Get board state as player sees it.\"\"\"\n",
    "        visible = []\n",
    "        for r in range(self.rows):\n",
    "            row = []\n",
    "            for c in range(self.cols):\n",
    "                if (r, c) in self._flagged:\n",
    "                    row.append('F')\n",
    "                elif (r, c) in self._revealed:\n",
    "                    val = self._board[r][c]\n",
    "                    row.append('*' if val == -1 else str(val))\n",
    "                else:\n",
    "                    row.append('.')\n",
    "            visible.append(row)\n",
    "        return visible\n",
    "\n",
    "    def state(self) -> str:\n",
    "        return self._state\n",
    "\n",
    "    def get_mine_positions(self) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"Return set of all mine positions (for reward computation).\"\"\"\n",
    "        return {(r, c) for r in range(self.rows) for c in range(self.cols)\n",
    "                if self._board[r][c] == -1}\n",
    "\n",
    "    def progress(self) -> float:\n",
    "        \"\"\"Fraction of safe cells revealed (0.0 to 1.0).\"\"\"\n",
    "        safe_cells = self.rows * self.cols - self.num_mines\n",
    "        return len(self._revealed) / safe_cells if safe_cells > 0 else 1.0\n",
    "\n",
    "    def pretty_print(self) -> str:\n",
    "        \"\"\"Pretty print the board.\"\"\"\n",
    "        visible = self.get_visible_board()\n",
    "        lines = []\n",
    "\n",
    "        # Header\n",
    "        header = \"   \" + \" \".join(f\"{i:2d}\" for i in range(self.cols))\n",
    "        lines.append(header)\n",
    "        lines.append(\"  \" + \"─\" * (self.cols * 3 + 1))\n",
    "\n",
    "        # Board\n",
    "        for r, row in enumerate(visible):\n",
    "            line = f\"{r:2d}│ \" + \"  \".join(row)\n",
    "            lines.append(line)\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ── Quick sanity tests ──\n",
    "print(\"Testing MinesweeperGame...\")\n",
    "g = MinesweeperGame(5, 5, 3, seed=0)\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": -1, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\", \"BUG: out_of_bounds should NOT end the game\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 99, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"flag\", \"row\": 0, \"col\": 0}) == \"ok\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0}) == \"flagged_cell\"\n",
    "assert g.state() == \"ongoing\", \"BUG: flagged_cell should NOT end the game\"\n",
    "assert g.do_action({}) == \"invalid_format\"\n",
    "assert g.state() == \"ongoing\", \"BUG: invalid_format should NOT end the game\"\n",
    "print(\"  ✅ do_action keeps game ongoing on invalid moves (fixed)\")\n",
    "\n",
    "# Test variable sizes\n",
    "for r, c, m in [(5,5,3), (6,6,5), (8,8,10), (10,10,12), (6,8,6)]:\n",
    "    g = MinesweeperGame(r, c, m, seed=42)\n",
    "    assert g.rows == r and g.cols == c\n",
    "    board = g.get_visible_board()\n",
    "    assert len(board) == r and len(board[0]) == c\n",
    "print(f\"  ✅ Variable board sizes work\")\n",
    "\n",
    "# Test progress\n",
    "g = MinesweeperGame(5, 5, 3, seed=42)\n",
    "assert g.progress() == 0.0\n",
    "print(f\"  ✅ All game engine tests passed\")\n",
    "print(f\"  Board configs available: {len(BOARD_CONFIGS)} different sizes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617e14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# JSON Input/Output Format\n",
    "\n",
    "## Input Format (Game State)\n",
    "The prompt includes board state for **variable board sizes** (5×5 to 10×10):\n",
    "- Compact row-per-line format with row indices\n",
    "- Board dimensions, mine count, remaining mines\n",
    "- Pre-computed logical hints (safe cells, mine cells)\n",
    "\n",
    "## Output Format (Action)\n",
    "```json\n",
    "{\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "```\n",
    "or\n",
    "```json\n",
    "{\"type\": \"flag\", \"row\": 1, \"col\": 4}\n",
    "```\n",
    "\n",
    "## Dataset Columns (for reward function reconstruction)\n",
    "| Column | Type | Purpose |\n",
    "|--------|------|---------|\n",
    "| `prompt` | list[dict] | Chat-formatted prompt |\n",
    "| `seed` | int | RNG seed to reconstruct game |\n",
    "| `move_history` | str (JSON) | Previous moves as JSON list |\n",
    "| `board_rows` | int | Number of rows |\n",
    "| `board_cols` | int | Number of columns |\n",
    "| `board_mines` | int | Number of mines |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert Minesweeper solver. Output ONE action as JSON only.\n",
      "\n",
      "RULES:\n",
      "- Numbers show how many of their 8 neighbors are mines.\n",
      "- Subtract flagged neighbors from the number to find remaining mines.\n",
      "- If remaining mines == remaining unrevealed neighbors → all are mines → FLAG.\n",
      "- If remaining mines == 0 → all unrevealed neighbors are safe → REVEAL.\n",
      "- Never reveal a flagged cell or flag a revealed cell.\n",
      "- Prefer logically deducible moves over guessing.\n",
      "\n",
      "{\n",
      "  \"board\": [\n",
      "    [\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\"\n",
      "    ],\n",
      "    [\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\"\n",
      "    ],\n",
      "    [\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\"\n",
      "    ],\n",
      "    [\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\"\n",
      "    ],\n",
      "    [\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\"\n",
      "    ],\n",
      "    [\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\",\n",
      "      \".\"\n",
      "    ]\n",
      "  ],\n",
      "  \"rows\": 6,\n",
      "  \"cols\": 6,\n",
      "  \"mines\": 5,\n",
      "  \"flags_placed\": 0,\n",
      "  \"cells_revealed\": 0,\n",
      "  \"remaining_mines\": 5\n",
      "}\n",
      "\n",
      "\".\"=unrevealed \"F\"=flagged \"0\"-\"8\"=adjacent mine count\n",
      "\n",
      "No cells can be logically deduced — pick the least risky unrevealed cell.\n",
      "\n",
      "Respond ONLY with a JSON object:\n",
      "{\"type\":\"reveal\"|\"flag\",\"row\":<int>,\"col\":<int>}\n",
      "\n",
      "--- Prompt length: 1270 chars ---\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Minesweeper Logic Helpers — cached per game state\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _compute_safe_and_mine_cells(game: MinesweeperGame):\n",
    "    \"\"\"Compute both safe and mine cells in a SINGLE pass (O(n²) not O(n⁴)).\n",
    "\n",
    "    Returns (safe_set, mine_set) where each is a set of (row, col) tuples.\n",
    "\n",
    "    A cell is logically SAFE if any adjacent revealed number has all its\n",
    "    mines accounted for by flags (remaining_mines == 0).\n",
    "    A cell is a logically CERTAIN mine if an adjacent number has\n",
    "    remaining_mines == remaining unrevealed neighbors.\n",
    "    \"\"\"\n",
    "    safe = set()\n",
    "    mines = set()\n",
    "\n",
    "    for r in range(game.rows):\n",
    "        for c in range(game.cols):\n",
    "            if (r, c) not in game._revealed:\n",
    "                continue\n",
    "            val = game._board[r][c]\n",
    "            if val <= 0:\n",
    "                continue\n",
    "\n",
    "            flags = 0\n",
    "            unrevealed = []\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    if dr == 0 and dc == 0:\n",
    "                        continue\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if 0 <= nr < game.rows and 0 <= nc < game.cols:\n",
    "                        if (nr, nc) in game._flagged:\n",
    "                            flags += 1\n",
    "                        elif (nr, nc) not in game._revealed:\n",
    "                            unrevealed.append((nr, nc))\n",
    "\n",
    "            remaining = val - flags\n",
    "\n",
    "            # All mines accounted for → remaining unrevealed are safe\n",
    "            if remaining == 0 and unrevealed:\n",
    "                for cell in unrevealed:\n",
    "                    safe.add(cell)\n",
    "            # Remaining mines == remaining unknowns → all are mines\n",
    "            elif remaining > 0 and remaining == len(unrevealed):\n",
    "                for cell in unrevealed:\n",
    "                    mines.add(cell)\n",
    "\n",
    "    return safe, mines\n",
    "\n",
    "\n",
    "def _compute_safe_cells(game: MinesweeperGame) -> list:\n",
    "    \"\"\"Return list of [row, col] for logically safe cells.\"\"\"\n",
    "    safe, _ = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in safe]\n",
    "\n",
    "\n",
    "def _compute_mine_cells(game: MinesweeperGame) -> list:\n",
    "    \"\"\"Return list of [row, col] for logically certain mine cells.\"\"\"\n",
    "    _, mines = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in mines]\n",
    "\n",
    "\n",
    "def _is_logically_safe(game: MinesweeperGame, row: int, col: int) -> bool:\n",
    "    \"\"\"Check if (row, col) is logically safe.\"\"\"\n",
    "    safe, _ = _compute_safe_and_mine_cells(game)\n",
    "    return (row, col) in safe\n",
    "\n",
    "\n",
    "def _is_logically_mine(game: MinesweeperGame, row: int, col: int) -> bool:\n",
    "    \"\"\"Check if (row, col) is logically a mine.\"\"\"\n",
    "    _, mines = _compute_safe_and_mine_cells(game)\n",
    "    return (row, col) in mines\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Prompt formatting — concise, hint-enriched, variable board sizes\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert Minesweeper solver. Given a board state, output exactly ONE action as a JSON object. No explanation, no markdown, no extra text.\"\"\"\n",
    "\n",
    "def format_state_for_llm(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Convert game state to an optimized prompt for LLM.\n",
    "\n",
    "    Supports any board size. Prompt is kept compact to stay within\n",
    "    max_prompt_length even for larger boards (up to ~10x10).\n",
    "    \"\"\"\n",
    "    board = game.get_visible_board()\n",
    "\n",
    "    # Compact board representation: one string per row instead of nested lists\n",
    "    board_str = \"\\n\".join(\n",
    "        f\"  {r:2d}: \" + \" \".join(row) for r, row in enumerate(board)\n",
    "    )\n",
    "    col_header = \"      \" + \" \".join(f\"{c}\" for c in range(game.cols))\n",
    "\n",
    "    safe_cells = _compute_safe_cells(game)\n",
    "    mine_cells = _compute_mine_cells(game)\n",
    "\n",
    "    hint_lines = []\n",
    "    if safe_cells:\n",
    "        hint_lines.append(f\"SAFE cells (reveal one): {safe_cells[:5]}\")\n",
    "    if mine_cells:\n",
    "        hint_lines.append(f\"MINE cells (flag one): {mine_cells[:5]}\")\n",
    "    if not safe_cells and not mine_cells:\n",
    "        hint_lines.append(\"No logical deductions — choose lowest-risk unrevealed cell.\")\n",
    "\n",
    "    hint_section = \"\\n\".join(hint_lines)\n",
    "\n",
    "    prompt = f\"\"\"Minesweeper {game.rows}x{game.cols}, {game.num_mines} mines, {game.num_mines - len(game._flagged)} remaining.\n",
    "Revealed: {len(game._revealed)}/{game.rows * game.cols - game.num_mines} safe cells.\n",
    "\n",
    "{col_header}\n",
    "{board_str}\n",
    "\n",
    "Legend: .=unrevealed F=flagged 0-8=adjacent mines\n",
    "\n",
    "RULES:\n",
    "- Number = count of adjacent mines (8 neighbors).\n",
    "- remaining_mines_for_number = number - adjacent_flags.\n",
    "- If remaining=0 → all unrevealed neighbors are SAFE → reveal one.\n",
    "- If remaining = unrevealed_neighbor_count → all are MINES → flag one.\n",
    "- Never reveal a flagged cell. Never flag a revealed cell.\n",
    "\n",
    "{hint_section}\n",
    "\n",
    "Output ONLY: {{\"type\":\"reveal\"|\"flag\",\"row\":<int>,\"col\":<int>}}\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_llm_action(response: str) -> dict:\n",
    "    \"\"\"Extract JSON action from LLM response.\n",
    "\n",
    "    Finds all JSON-like objects and returns the LAST one matching the\n",
    "    expected schema (type + row + col). LLMs typically place their\n",
    "    final answer at the end.\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for match in re.finditer(r'\\{[^{}]*\\}', response):\n",
    "        try:\n",
    "            action = json.loads(match.group())\n",
    "            if (\"type\" in action and \"row\" in action and \"col\" in action\n",
    "                    and action[\"type\"] in (\"reveal\", \"flag\")):\n",
    "                # Ensure row/col are ints\n",
    "                action[\"row\"] = int(action[\"row\"])\n",
    "                action[\"col\"] = int(action[\"col\"])\n",
    "                best = action\n",
    "        except (json.JSONDecodeError, ValueError, TypeError):\n",
    "            continue\n",
    "    return best\n",
    "\n",
    "\n",
    "# ── Quick tests ──\n",
    "for rows, cols, mines in [(5,5,3), (6,6,5), (8,8,10), (10,10,12)]:\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=42)\n",
    "    prompt = format_state_for_llm(game)\n",
    "    assert f\"{rows}x{cols}\" in prompt\n",
    "    assert f\"{mines} mines\" in prompt\n",
    "    print(f\"  {rows}x{cols} prompt: {len(prompt)} chars\")\n",
    "\n",
    "# Test parse_llm_action edge cases\n",
    "assert parse_llm_action('{\"type\":\"reveal\",\"row\":2,\"col\":3}') == {\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "assert parse_llm_action('blah blah {\"type\":\"flag\",\"row\":\"1\",\"col\":\"2\"} done') == {\"type\": \"flag\", \"row\": 1, \"col\": 2}\n",
    "assert parse_llm_action('no json here') is None\n",
    "assert parse_llm_action('{\"type\":\"invalid\",\"row\":0,\"col\":0}') is None\n",
    "\n",
    "# Show example prompt\n",
    "game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=42)\n",
    "game.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "prompt = format_state_for_llm(game)\n",
    "print(f\"\\n=== Example 6x6 prompt ({len(prompt)} chars) ===\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302a238",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Model Before Training\n",
    "\n",
    "See how the base model performs without finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6fd8563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Base Model Response ===\n",
      "{\"type\":\"reveal\",\"row\":0,\"col\":0}<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=42)\n",
    "prompt = format_state_for_llm(game)\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": prompt}],\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True,\n",
    ")\n",
    "\n",
    "print(\"=== Base Model Response ===\")\n",
    "output = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.7,\n",
    "    top_p = 0.9,\n",
    "    max_new_tokens = 128,\n",
    "    do_sample = True,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b3c5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# GRPO Reward Functions\n",
    "\n",
    "Define reward functions to guide the model's learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ca52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All reward functions defined:\n",
      "   1. valid_json_reward   — format + conciseness\n",
      "   2. gameplay_scores     — all 12 criteria\n",
      "   3. strategic_reward    — logical deduction bonuses\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Helper: Reconstruct game from dataset columns\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _reconstruct_game(idx, kwargs):\n",
    "    \"\"\"Reconstruct a MinesweeperGame from dataset columns passed via GRPO kwargs.\n",
    "\n",
    "    The dataset stores: seed, move_history, board_rows, board_cols, board_mines\n",
    "    GRPOTrainer passes all non-'prompt' columns as lists in **kwargs.\n",
    "\n",
    "    Returns (game, move_history_list) or (None, None) if data is missing.\n",
    "    \"\"\"\n",
    "    seeds = kwargs.get(\"seed\", [])\n",
    "    move_histories = kwargs.get(\"move_history\", [])\n",
    "    rows_list = kwargs.get(\"board_rows\", [])\n",
    "    cols_list = kwargs.get(\"board_cols\", [])\n",
    "    mines_list = kwargs.get(\"board_mines\", [])\n",
    "\n",
    "    if idx >= len(seeds) or idx >= len(move_histories):\n",
    "        return None, None\n",
    "\n",
    "    seed = seeds[idx]\n",
    "    rows = rows_list[idx] if idx < len(rows_list) else 6\n",
    "    cols = cols_list[idx] if idx < len(cols_list) else 6\n",
    "    num_mines = mines_list[idx] if idx < len(mines_list) else 5\n",
    "\n",
    "    mh_raw = move_histories[idx]\n",
    "    if isinstance(mh_raw, str):\n",
    "        move_history = json.loads(mh_raw)\n",
    "    else:\n",
    "        move_history = list(mh_raw)\n",
    "\n",
    "    game = MinesweeperGame(rows=int(rows), cols=int(cols),\n",
    "                           num_mines=int(num_mines), seed=int(seed))\n",
    "    for prev in move_history:\n",
    "        result = game.do_action(prev)\n",
    "        if result == \"mine\":\n",
    "            return None, None  # History hit a mine — bad data\n",
    "\n",
    "    return game, move_history\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 1: Valid JSON format + conciseness\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def valid_json_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"Reward valid JSON action format. Also rewards conciseness.\n",
    "\n",
    "    TRL GRPOTrainer calls: reward_func(prompts=..., completions=..., **kwargs)\n",
    "    completions is a list of list-of-dicts (chat format).\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"].strip() if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            scores.append(-3.0)\n",
    "            continue\n",
    "\n",
    "        # Bonus for pure JSON (no extra text)\n",
    "        try:\n",
    "            parsed = json.loads(response)\n",
    "            if \"type\" in parsed and \"row\" in parsed and \"col\" in parsed:\n",
    "                scores.append(3.0)  # Perfect — pure JSON only\n",
    "                continue\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        # Valid JSON but with extra surrounding text\n",
    "        json_match = re.search(r'\\{[^{}]*\\}', response)\n",
    "        extra_chars = len(response) - len(json_match.group()) if json_match else len(response)\n",
    "        if extra_chars < 10:\n",
    "            scores.append(2.5)\n",
    "        elif extra_chars < 50:\n",
    "            scores.append(1.0)\n",
    "        elif extra_chars < 200:\n",
    "            scores.append(0.0)\n",
    "        else:\n",
    "            scores.append(-1.0)  # Too verbose\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 2: Gameplay — complete 12-criterion scoring\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def gameplay_scores(prompts, completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Complete gameplay reward implementing all 12 scoring criteria.\n",
    "    Uses variable board sizes from dataset columns.\n",
    "\n",
    "    1.  Flag cell that IS a mine        → +15 / +20 (logical)\n",
    "    2.  Flag cell that is NOT a mine    → -10\n",
    "    3.  Reveal cell that IS a mine      → -25\n",
    "    4.  Reveal cell that is safe        → +10 (guess) / +15 (logical)\n",
    "    5.  Flag already flagged cell       → -12\n",
    "    6.  Reveal already revealed cell    → -12\n",
    "    7.  Out of bounds                   → -15\n",
    "    8.  Total flags > total mines       → -10 (additional)\n",
    "    9.  Invalid JSON                    → -10\n",
    "    10. Win the game                    → +100\n",
    "    11. Reveal a flagged cell           → -8\n",
    "    12. Flag a revealed cell            → -8\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"] if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        # ── Criterion 9: Invalid JSON ──\n",
    "        if action is None:\n",
    "            scores.append(-10.0)\n",
    "            continue\n",
    "\n",
    "        # ── Reconstruct game state from dataset columns ──\n",
    "        game, move_history = _reconstruct_game(idx, kwargs)\n",
    "        if game is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        row, col = action[\"row\"], action[\"col\"]\n",
    "        action_type = action[\"type\"]\n",
    "\n",
    "        # ── Criterion 7: Out of bounds ──\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(-15.0)\n",
    "            continue\n",
    "\n",
    "        # ── Compute logical deductions ONCE ──\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        score = 0.0\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            # ── Criterion 6: Reveal already revealed cell ──\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-12.0)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 11: Reveal a flagged cell ──\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-8.0)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 3: Reveal a mine ──\n",
    "            if game._board[row][col] == -1:\n",
    "                scores.append(-25.0)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 4: Reveal safe cell ──\n",
    "            if (row, col) in safe_set:\n",
    "                score += 15.0   # Logically deduced safe cell\n",
    "            else:\n",
    "                score += 10.0   # Guessed safe cell\n",
    "\n",
    "            # Small bonus for revealing near numbers (information-rich)\n",
    "            board = game.get_visible_board()\n",
    "            has_adjacent_number = False\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    nr, nc = row + dr, col + dc\n",
    "                    if 0 <= nr < game.rows and 0 <= nc < game.cols:\n",
    "                        if board[nr][nc] in ('1','2','3','4','5','6','7','8'):\n",
    "                            has_adjacent_number = True\n",
    "                            break\n",
    "                if has_adjacent_number:\n",
    "                    break\n",
    "            if has_adjacent_number:\n",
    "                score += 1.0\n",
    "\n",
    "            # ── Criterion 10: Check for win ──\n",
    "            game_copy = MinesweeperGame(\n",
    "                rows=game.rows, cols=game.cols,\n",
    "                num_mines=game.num_mines, seed=kwargs.get(\"seed\", [0])[idx]\n",
    "            )\n",
    "            for prev in move_history:\n",
    "                game_copy.do_action(prev)\n",
    "            result = game_copy.do_action(action)\n",
    "            if result == \"win\":\n",
    "                score += 100.0\n",
    "\n",
    "        elif action_type == \"flag\":\n",
    "            # ── Criterion 5: Flag already flagged cell ──\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-12.0)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 12: Flag a revealed cell ──\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-8.0)\n",
    "                continue\n",
    "\n",
    "            # ── Criterion 1: Flag a mine (correct) ──\n",
    "            if game._board[row][col] == -1:\n",
    "                if (row, col) in mine_set:\n",
    "                    score += 20.0   # Logically deduced mine\n",
    "                else:\n",
    "                    score += 15.0   # Correct but guessed\n",
    "\n",
    "            # ── Criterion 2: Flag a non-mine (wrong) ──\n",
    "            else:\n",
    "                score -= 10.0\n",
    "\n",
    "            # ── Criterion 8: Total flags > total mines ──\n",
    "            new_flag_count = len(game._flagged) + 1\n",
    "            if new_flag_count > game.num_mines:\n",
    "                score -= 10.0\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 3: Strategic play — rewards logical deduction over guessing\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def strategic_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"Reward strategic play patterns:\n",
    "    - Choosing logically deducible moves when available\n",
    "    - Opening in corners/edges (lower mine probability on fresh boards)\n",
    "    - Penalize ignoring available deductions\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"] if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        game, move_history = _reconstruct_game(idx, kwargs)\n",
    "        if game is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        row, col = action[\"row\"], action[\"col\"]\n",
    "        action_type = action[\"type\"]\n",
    "        score = 0.0\n",
    "\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # ── Compute logical deductions ONCE ──\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        # ── Fresh game opening strategy ──\n",
    "        if len(game._revealed) == 0 and action_type == \"reveal\":\n",
    "            corners = [(0, 0), (0, game.cols - 1),\n",
    "                       (game.rows - 1, 0), (game.rows - 1, game.cols - 1)]\n",
    "            edges = ([(0, c) for c in range(game.cols)] +\n",
    "                     [(game.rows-1, c) for c in range(game.cols)] +\n",
    "                     [(r, 0) for r in range(game.rows)] +\n",
    "                     [(r, game.cols-1) for r in range(game.rows)])\n",
    "            if (row, col) in corners:\n",
    "                score += 3.0   # Corners have only 3 neighbors → lowest risk\n",
    "            elif (row, col) in edges:\n",
    "                score += 1.0   # Edges have 5 neighbors → moderate risk\n",
    "\n",
    "        # ── Reward choosing logically deducible moves ──\n",
    "        if action_type == \"reveal\" and (row, col) in safe_set:\n",
    "            score += 5.0   # Chose a provably safe cell\n",
    "        elif action_type == \"flag\" and (row, col) in mine_set:\n",
    "            score += 5.0   # Chose a provably mine cell\n",
    "        elif safe_set or mine_set:\n",
    "            # Deducible moves existed but agent didn't pick one\n",
    "            score -= 3.0\n",
    "\n",
    "        # ── Penalize flagging on a fresh board (no info to deduce) ──\n",
    "        if len(game._revealed) == 0 and action_type == \"flag\":\n",
    "            score -= 2.0\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ── Verify reward function signatures ──\n",
    "print(\"✅ All reward functions defined with correct TRL signature:\")\n",
    "print(\"   1. valid_json_reward(prompts, completions, **kwargs)\")\n",
    "print(\"   2. gameplay_scores(prompts, completions, **kwargs)\")\n",
    "print(\"   3. strategic_reward(prompts, completions, **kwargs)\")\n",
    "print()\n",
    "\n",
    "# ── Smoke test: simulate what GRPOTrainer passes ──\n",
    "test_completions = [[{\"role\": \"assistant\", \"content\": '{\"type\":\"reveal\",\"row\":0,\"col\":0}'}]]\n",
    "test_prompts = [\"test\"]\n",
    "test_kwargs = {\n",
    "    \"seed\": [42],\n",
    "    \"move_history\": [\"[]\"],\n",
    "    \"board_rows\": [6],\n",
    "    \"board_cols\": [6],\n",
    "    \"board_mines\": [5],\n",
    "}\n",
    "r1 = valid_json_reward(test_prompts, test_completions, **test_kwargs)\n",
    "r2 = gameplay_scores(test_prompts, test_completions, **test_kwargs)\n",
    "r3 = strategic_reward(test_prompts, test_completions, **test_kwargs)\n",
    "print(f\"  Smoke test rewards: format={r1[0]:.1f}, gameplay={r2[0]:.1f}, strategic={r3[0]:.1f}\")\n",
    "print(f\"  ✅ All reward functions work with kwargs (seed, move_history, board_rows/cols/mines)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b787f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Create Training Dataset\n",
    "\n",
    "Generate diverse game states for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c0d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training dataset with curriculum learning...\n",
      "Created 2000 training examples (all ongoing games)\n",
      "\n",
      "  Fresh games (0 moves): 637 (31.9%)\n",
      "  Early game (1-2):      833 (41.6%)\n",
      "  Mid game (3-8):        516 (25.8%)\n",
      "  Late game (9+):        14 (0.7%)\n",
      "  Avg moves per state:   1.9\n",
      "\n",
      "Example training prompt (first 300 chars):\n",
      "You are an expert Minesweeper solver. Output ONE action as JSON only.\n",
      "\n",
      "RULES:\n",
      "- Numbers show how many of their 8 neighbors are mines.\n",
      "- Subtract flagged neighbors from the number to find remaining mines.\n",
      "- If remaining mines == remaining unrevealed neighbors → all are mines → FLAG.\n",
      "- If remaining mi...\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def _smart_reveal(game, rng):\n",
    "    \"\"\"Pick a smart cell to reveal during history generation.\n",
    "    Prefers safe cells (if known) to avoid hitting mines and losing the game.\n",
    "    Falls back to random unrevealed cell.\n",
    "    \"\"\"\n",
    "    safe_set, _ = _compute_safe_and_mine_cells(game)\n",
    "    if safe_set:\n",
    "        return rng.choice(list(safe_set))\n",
    "\n",
    "    # Fallback: random unrevealed, unflagged cell\n",
    "    unrevealed = [(r, c) for r in range(game.rows) for c in range(game.cols)\n",
    "                  if (r, c) not in game._revealed and (r, c) not in game._flagged]\n",
    "    if not unrevealed:\n",
    "        return None\n",
    "    return rng.choice(unrevealed)\n",
    "\n",
    "\n",
    "def _smart_flag(game, rng):\n",
    "    \"\"\"Pick a logically certain mine to flag, or None if none available.\"\"\"\n",
    "    _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "    mine_candidates = [c for c in mine_set if c not in game._flagged]\n",
    "    if mine_candidates:\n",
    "        return rng.choice(mine_candidates)\n",
    "    return None  # Don't flag randomly — creates bad training data\n",
    "\n",
    "\n",
    "def generate_game_states(num_samples=3000, rng_seed=42):\n",
    "    \"\"\"\n",
    "    Generate diverse Minesweeper game states with:\n",
    "\n",
    "    1. VARIABLE BOARD SIZES — sampled from BOARD_CONFIGS\n",
    "    2. CURRICULUM LEARNING — fresh/early/mid/late distribution\n",
    "    3. SMART move history — uses logical deduction to avoid mines\n",
    "    4. FLAG states — only flags logically certain mines (no random flags)\n",
    "    5. EDGE CASES — includes games with:\n",
    "       - Boards where all neighbors of revealed cells are mines\n",
    "       - Boards with zero-cascades (large reveals)\n",
    "       - High mine density boards\n",
    "       - Rectangular boards\n",
    "\n",
    "    Stores: seed, move_history, board_rows, board_cols, board_mines\n",
    "    so reward functions can reconstruct the EXACT game state.\n",
    "    \"\"\"\n",
    "    np.random.seed(rng_seed)\n",
    "    rng = random.Random(rng_seed)\n",
    "\n",
    "    dataset_items = []\n",
    "    attempts = 0\n",
    "    max_attempts = num_samples * 10  # More attempts for harder configs\n",
    "\n",
    "    # Move-count distribution for curriculum\n",
    "    move_bins = [\n",
    "        (0, 0, 0.12),    # Fresh — learn opening strategy\n",
    "        (1, 2, 0.22),    # Early — learn basic deduction\n",
    "        (3, 8, 0.40),    # Mid   — learn constraint satisfaction\n",
    "        (9, 25, 0.18),   # Late  — learn endgame / flagging\n",
    "        (1, 1, 0.08),    # Single-move — learn from minimal info\n",
    "    ]\n",
    "\n",
    "    # Counters for distribution tracking\n",
    "    config_counts = {}\n",
    "    phase_counts = {\"fresh\": 0, \"early\": 0, \"mid\": 0, \"late\": 0, \"single\": 0}\n",
    "\n",
    "    while len(dataset_items) < num_samples and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "\n",
    "        # ── Sample board configuration ──\n",
    "        rows, cols, num_mines = sample_board_config(rng)\n",
    "        config_key = f\"{rows}x{cols}m{num_mines}\"\n",
    "        config_counts[config_key] = config_counts.get(config_key, 0) + 1\n",
    "\n",
    "        # ── Sample game phase ──\n",
    "        phase_rand = rng.random()\n",
    "        cumulative = 0\n",
    "        min_moves, max_moves_range = 0, 0\n",
    "        phase_name = \"fresh\"\n",
    "        for i, (mn, mx, prob) in enumerate(move_bins):\n",
    "            cumulative += prob\n",
    "            if phase_rand < cumulative:\n",
    "                min_moves, max_moves_range = mn, mx\n",
    "                phase_name = [\"fresh\", \"early\", \"mid\", \"late\", \"single\"][i]\n",
    "                break\n",
    "\n",
    "        # Scale move count by board size (larger boards need more moves for mid/late)\n",
    "        total_safe = rows * cols - num_mines\n",
    "        if phase_name in (\"mid\", \"late\"):\n",
    "            max_moves_range = min(max_moves_range, total_safe - 1)\n",
    "\n",
    "        if max_moves_range < min_moves:\n",
    "            max_moves_range = min_moves\n",
    "        num_moves = rng.randint(min_moves, max_moves_range)\n",
    "\n",
    "        seed = rng.randint(0, 999999)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "        move_history = []\n",
    "\n",
    "        for move_i in range(num_moves):\n",
    "            if game.state() != \"ongoing\":\n",
    "                break\n",
    "\n",
    "            # ── Decide action: reveal vs flag ──\n",
    "            # Flag only if we have logical certainty (15% chance when possible)\n",
    "            action_dict = None\n",
    "            if rng.random() < 0.15:\n",
    "                flag_target = _smart_flag(game, rng)\n",
    "                if flag_target:\n",
    "                    action_dict = {\"type\": \"flag\", \"row\": flag_target[0], \"col\": flag_target[1]}\n",
    "\n",
    "            if action_dict is None:\n",
    "                reveal_target = _smart_reveal(game, rng)\n",
    "                if reveal_target is None:\n",
    "                    break\n",
    "                action_dict = {\"type\": \"reveal\", \"row\": reveal_target[0], \"col\": reveal_target[1]}\n",
    "\n",
    "            result = game.do_action(action_dict)\n",
    "            if result == \"mine\":\n",
    "                break  # Hit a mine — discard this game\n",
    "            move_history.append(action_dict)\n",
    "\n",
    "        # Only keep ongoing games with valid state\n",
    "        if game.state() == \"ongoing\":\n",
    "            prompt_text = format_state_for_llm(game)\n",
    "            dataset_items.append({\n",
    "                \"prompt\": [{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                \"seed\": seed,\n",
    "                \"move_history\": json.dumps(move_history),\n",
    "                \"board_rows\": rows,\n",
    "                \"board_cols\": cols,\n",
    "                \"board_mines\": num_mines,\n",
    "            })\n",
    "            phase_counts[phase_name] = phase_counts.get(phase_name, 0) + 1\n",
    "\n",
    "    dataset_items = dataset_items[:num_samples]\n",
    "    ds = Dataset.from_list(dataset_items)\n",
    "\n",
    "    return ds, config_counts, phase_counts\n",
    "\n",
    "\n",
    "# ── Generate training dataset ──\n",
    "print(\"Generating training dataset with variable board sizes + curriculum...\")\n",
    "dataset, config_counts, phase_counts = generate_game_states(num_samples=3000, rng_seed=42)\n",
    "print(f\"Created {len(dataset)} training examples\\n\")\n",
    "\n",
    "# Distribution analysis\n",
    "print(\"Board size distribution:\")\n",
    "for config, count in sorted(config_counts.items(), key=lambda x: -x[1]):\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {config:12s}: {count:4d} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPhase distribution:\")\n",
    "for phase, count in phase_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {phase:8s}: {count:4d} ({pct:.1f}%)\")\n",
    "\n",
    "move_counts = [len(json.loads(item[\"move_history\"])) for item in dataset]\n",
    "print(f\"\\nMove statistics:\")\n",
    "print(f\"  Min: {min(move_counts)}, Max: {max(move_counts)}, \"\n",
    "      f\"Mean: {np.mean(move_counts):.1f}, Median: {np.median(move_counts):.1f}\")\n",
    "\n",
    "# Verify dataset columns\n",
    "print(f\"\\nDataset columns: {dataset.column_names}\")\n",
    "print(f\"  ✅ board_rows, board_cols, board_mines present for reward functions\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample prompt ({dataset[0]['board_rows']}x{dataset[0]['board_cols']}, \"\n",
    "      f\"{dataset[0]['board_mines']} mines):\")\n",
    "print(dataset[0][\"prompt\"][0][\"content\"][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e4491",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Configure GRPO Training\n",
    "\n",
    "Set up GRPO trainer with all hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478959ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 8\n",
      "Training configuration:\n",
      "  Model:               Qwen2.5-14B-Instruct\n",
      "  Max steps:           500\n",
      "  Generations/state:   8\n",
      "  Learning rate:       2e-05\n",
      "  LR scheduler:       SchedulerType.COSINE\n",
      "  Max grad norm:       0.5\n",
      "  Loss type:           bnpo\n",
      "  Beta (KL penalty):   0.001\n",
      "  Reward weights:      [0.15, 0.7, 0.15]\n",
      "  Prompt/Completion:   700/200\n",
      "  Temperature:         0.9\n",
      "  Top-p:               0.95\n",
      "  LoRA rank:           32\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# ── Lengths ──\n",
    "# A 10x10 board with hints can be ~900 tokens. 1400 gives safe margin.\n",
    "max_prompt_length = 1400\n",
    "max_completion_length = 128  # Pure JSON output is ~40 tokens; 128 is generous\n",
    "\n",
    "# ── GRPO Configuration ──\n",
    "training_args = GRPOConfig(\n",
    "    # === Generation ===\n",
    "    temperature = 0.9,           # Exploration during training\n",
    "    top_p = 0.95,\n",
    "\n",
    "    # === Optimization ===\n",
    "    learning_rate = 2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.05,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    max_grad_norm = 0.5,\n",
    "\n",
    "    # === Batch sizes ===\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_generations = 8,\n",
    "\n",
    "    # === Lengths ===\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_completion_length,\n",
    "\n",
    "    # === Training duration ===\n",
    "    max_steps = 500,\n",
    "    save_steps = 100,\n",
    "\n",
    "    # === GRPO specific ===\n",
    "    beta = 0.04,                 # Mild KL penalty to prevent reward hacking\n",
    "    num_iterations = 1,\n",
    "\n",
    "    # === Reward weighting (gameplay >> format >> strategy) ===\n",
    "    reward_weights = [0.15, 0.70, 0.15],\n",
    "\n",
    "    # === Ensure extra dataset columns are NOT removed ===\n",
    "    remove_unused_columns = False,\n",
    "\n",
    "    # === Output ===\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"minesweeper_grpo_v2\",\n",
    "    seed = 42,\n",
    "    bf16 = True,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Max steps:           {training_args.max_steps}\")\n",
    "print(f\"  Generations/state:   {training_args.num_generations}\")\n",
    "print(f\"  Learning rate:       {training_args.learning_rate}\")\n",
    "print(f\"  LR scheduler:       {training_args.lr_scheduler_type}\")\n",
    "print(f\"  Max grad norm:       {training_args.max_grad_norm}\")\n",
    "print(f\"  Beta (KL penalty):   {training_args.beta}\")\n",
    "print(f\"  Reward weights:      {training_args.reward_weights}\")\n",
    "print(f\"  Prompt/Completion:   {max_prompt_length}/{max_completion_length}\")\n",
    "print(f\"  Temperature:         {training_args.temperature}\")\n",
    "print(f\"  remove_unused_cols:  {training_args.remove_unused_columns}\")\n",
    "print(f\"  LoRA rank:           {lora_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25da67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval callback: 10 games every 50 steps (temp=0.3 for deterministic eval)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "# Board configs to evaluate on during training (mix of sizes)\n",
    "EVAL_CONFIGS = [\n",
    "    (6, 6, 5),   # Standard\n",
    "    (6, 6, 5),   # Standard x2\n",
    "    (5, 5, 3),   # Small\n",
    "    (7, 7, 7),   # Medium\n",
    "    (8, 8, 10),  # Large\n",
    "    (6, 6, 5),   # Standard x3\n",
    "    (6, 6, 5),   # Standard x4\n",
    "    (9, 9, 10),  # Extra large\n",
    "    (6, 8, 6),   # Rectangular\n",
    "    (8, 8, 8),   # Large / moderate density\n",
    "]\n",
    "\n",
    "\n",
    "class MinesweeperEvalCallback(TrainerCallback):\n",
    "    \"\"\"Periodically play games during training with variable board sizes.\"\"\"\n",
    "\n",
    "    def __init__(self, eval_every_steps=50, num_games=10):\n",
    "        self.eval_every_steps = eval_every_steps\n",
    "        self.num_games = min(num_games, len(EVAL_CONFIGS))\n",
    "\n",
    "    def on_step_end(self, args, state, control, model=None, processing_class=None, **kwargs):\n",
    "        if state.global_step % self.eval_every_steps != 0:\n",
    "            return\n",
    "\n",
    "        tokenizer = processing_class\n",
    "        if tokenizer is None or model is None:\n",
    "            return\n",
    "\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "\n",
    "        wins = 0\n",
    "        total_moves = 0\n",
    "        invalid_count = 0\n",
    "\n",
    "        for i in range(self.num_games):\n",
    "            rows, cols, mines = EVAL_CONFIGS[i % len(EVAL_CONFIGS)]\n",
    "            game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines,\n",
    "                                   seed=10000 + i)\n",
    "            moves = 0\n",
    "            invalids = 0\n",
    "            max_moves = rows * cols  # Scale max moves with board size\n",
    "\n",
    "            while game.state() == \"ongoing\" and moves < max_moves:\n",
    "                prompt = format_state_for_llm(game)\n",
    "                text = tokenizer.apply_chat_template(\n",
    "                    [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True,\n",
    "                )\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                                   max_length=max_prompt_length + 100)\n",
    "                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model.generate(\n",
    "                        **inputs,\n",
    "                        temperature=0.3,\n",
    "                        max_new_tokens=128,\n",
    "                        do_sample=True,\n",
    "                        top_p=0.8,\n",
    "                    )\n",
    "\n",
    "                # Decode ONLY the generated tokens (not the prompt)\n",
    "                gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "                response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "                action = parse_llm_action(response)\n",
    "\n",
    "                if action is None:\n",
    "                    invalids += 1\n",
    "                    if invalids >= 3:\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "                invalids = 0\n",
    "                result = game.do_action(action)\n",
    "                if result in (\"mine\", \"win\"):\n",
    "                    moves += 1\n",
    "                    break\n",
    "                elif result == \"ok\":\n",
    "                    moves += 1\n",
    "                # For invalid moves (game stays ongoing), don't count as a move\n",
    "\n",
    "            if game.state() == \"success\":\n",
    "                wins += 1\n",
    "            total_moves += moves\n",
    "            invalid_count += invalids\n",
    "\n",
    "        win_rate = wins / self.num_games\n",
    "        avg_moves = total_moves / self.num_games\n",
    "        print(f\"\\n[Eval @ step {state.global_step}] \"\n",
    "              f\"Win: {wins}/{self.num_games} ({win_rate*100:.0f}%) | \"\n",
    "              f\"Avg moves: {avg_moves:.1f} | \"\n",
    "              f\"Invalid: {invalid_count}\\n\")\n",
    "\n",
    "        if was_training:\n",
    "            model.train()\n",
    "\n",
    "\n",
    "eval_callback = MinesweeperEvalCallback(eval_every_steps=50, num_games=10)\n",
    "print(f\"Eval callback: {eval_callback.num_games} games every \"\n",
    "      f\"{eval_callback.eval_every_steps} steps (variable board sizes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8e106",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Train the Model\n",
    "\n",
    "Start GRPO training with reward functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d03871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GRPO training with 3 reward functions...\n",
      "  [1] valid_json_reward  (weight: 0.15)\n",
      "  [2] gameplay_scores    (weight: 0.70)\n",
      "  [3] strategic_reward   (weight: 0.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,000 | Num Epochs = 1 | Total steps = 500\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 137,625,600 of 14,907,659,264 (0.92% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9/500 00:38 < 45:13, 0.18 it/s, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / valid_json_reward / mean</th>\n",
       "      <th>rewards / valid_json_reward / std</th>\n",
       "      <th>rewards / gameplay_scores / mean</th>\n",
       "      <th>rewards / gameplay_scores / std</th>\n",
       "      <th>rewards / strategic_reward / mean</th>\n",
       "      <th>rewards / strategic_reward / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.775000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.310527</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.524001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>18.008959</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.813925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-3.412500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.625000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.625000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.023024</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>19.423962</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.813925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.428125</td>\n",
       "      <td>1.177424</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.468750</td>\n",
       "      <td>16.329241</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.155264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.621875</td>\n",
       "      <td>2.184623</td>\n",
       "      <td>14.625000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.625000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.028749</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>11.830754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.565625</td>\n",
       "      <td>2.722260</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.343750</td>\n",
       "      <td>16.736303</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.540002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.637500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>4.158163</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.319824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        valid_json_reward,   # Reward valid JSON format + conciseness\n",
    "        gameplay_scores,     # Core gameplay (all 12 criteria)\n",
    "        strategic_reward,    # Logical deduction bonuses\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    "    callbacks = [eval_callback],  # Periodic gameplay evaluation\n",
    ")\n",
    "\n",
    "print(\"Starting GRPO training with 3 reward functions...\")\n",
    "print(\"  [1] valid_json_reward  (weight: 0.15)\")\n",
    "print(\"  [2] gameplay_scores    (weight: 0.70)\")\n",
    "print(\"  [3] strategic_reward   (weight: 0.15)\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8d025",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Trained Model\n",
    "\n",
    "Evaluate the finetuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00276c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on multiple board sizes\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "test_configs = [\n",
    "    (6, 6, 5, 99, \"Standard\"),\n",
    "    (5, 5, 3, 100, \"Small/Easy\"),\n",
    "    (8, 8, 10, 101, \"Large/Hard\"),\n",
    "    (7, 7, 7, 102, \"Medium\"),\n",
    "]\n",
    "\n",
    "for rows, cols, mines, seed, label in test_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"=== {label} ({rows}x{cols}, {mines} mines) ===\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    test_game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "    test_prompt = format_state_for_llm(test_game)\n",
    "\n",
    "    test_text = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": test_prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True,\n",
    "                       max_length=max_prompt_length + 100)\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.3,\n",
    "        max_new_tokens=128,\n",
    "        do_sample=True,\n",
    "        top_p=0.8,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "\n",
    "    # Decode only generated tokens\n",
    "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "    print(f\"Response: {response_text.strip()}\")\n",
    "\n",
    "    action = parse_llm_action(response_text)\n",
    "    print(f\"Parsed action: {action}\")\n",
    "\n",
    "    if action:\n",
    "        result = test_game.do_action(action)\n",
    "        print(f\"Result: {result} | Game state: {test_game.state()}\")\n",
    "    else:\n",
    "        print(\"⚠️ Failed to parse a valid action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2551f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Evaluation: Play Complete Games\n",
    "\n",
    "Test the model on multiple complete games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31315fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_full_game(model, tokenizer, rows=6, cols=6, num_mines=5, seed=None,\n",
    "                   max_moves=None, verbose=False):\n",
    "    \"\"\"Play a complete Minesweeper game, tracking detailed metrics.\n",
    "\n",
    "    Supports any board size. max_moves defaults to rows*cols if not specified.\n",
    "    \"\"\"\n",
    "    if max_moves is None:\n",
    "        max_moves = rows * cols  # Scale with board size\n",
    "\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "    moves = 0\n",
    "    invalid_streak = 0\n",
    "    total_invalids = 0\n",
    "    logical_moves = 0\n",
    "    flags_correct = 0\n",
    "    flags_wrong = 0\n",
    "\n",
    "    while game.state() == \"ongoing\" and moves < max_moves:\n",
    "        prompt = format_state_for_llm(game)\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": prompt}],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                           max_length=max_prompt_length + 100)\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                temperature=0.3,\n",
    "                max_new_tokens=128,\n",
    "                do_sample=True,\n",
    "                top_p=0.8,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # Decode ONLY generated tokens\n",
    "        gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "        response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            invalid_streak += 1\n",
    "            total_invalids += 1\n",
    "            if invalid_streak >= 3:\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        invalid_streak = 0\n",
    "\n",
    "        # Track logical moves (compute BEFORE applying action)\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "        r, c = action[\"row\"], action[\"col\"]\n",
    "        if action[\"type\"] == \"reveal\" and (r, c) in safe_set:\n",
    "            logical_moves += 1\n",
    "        elif action[\"type\"] == \"flag\" and (r, c) in mine_set:\n",
    "            logical_moves += 1\n",
    "\n",
    "        # Track flag accuracy\n",
    "        if action[\"type\"] == \"flag\":\n",
    "            if 0 <= r < game.rows and 0 <= c < game.cols:\n",
    "                if game._board[r][c] == -1:\n",
    "                    flags_correct += 1\n",
    "                else:\n",
    "                    flags_wrong += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  Move {moves}: {action}\")\n",
    "\n",
    "        result = game.do_action(action)\n",
    "        if result in (\"mine\", \"win\", \"ok\"):\n",
    "            moves += 1\n",
    "        elif result in (\"out_of_bounds\", \"already_revealed\", \"flagged_cell\",\n",
    "                         \"invalid_flag\", \"invalid_format\"):\n",
    "            # Invalid moves don't count but game stays ongoing\n",
    "            total_invalids += 1\n",
    "            invalid_streak += 1\n",
    "            if invalid_streak >= 3:\n",
    "                break\n",
    "\n",
    "        if result in (\"mine\", \"win\"):\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"game\": game,\n",
    "        \"moves\": moves,\n",
    "        \"logical_moves\": logical_moves,\n",
    "        \"flags_correct\": flags_correct,\n",
    "        \"flags_wrong\": flags_wrong,\n",
    "        \"total_invalids\": total_invalids,\n",
    "        \"result\": game.state(),\n",
    "        \"progress\": game.progress(),\n",
    "        \"config\": f\"{rows}x{cols}m{num_mines}\",\n",
    "    }\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Comprehensive Multi-Size Evaluation\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "EVAL_SUITE = [\n",
    "    # (rows, cols, mines, num_games, label)\n",
    "    (5, 5, 3,  15, \"Small/Easy\"),\n",
    "    (6, 6, 5,  30, \"Standard\"),\n",
    "    (6, 6, 7,  10, \"Standard/Hard\"),\n",
    "    (7, 7, 7,  15, \"Medium\"),\n",
    "    (8, 8, 10, 15, \"Large/Hard\"),\n",
    "    (9, 9, 10, 10, \"XL\"),\n",
    "    (6, 8, 6,   5, \"Rectangular\"),\n",
    "]\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  COMPREHENSIVE EVALUATION — {sum(n for _,_,_,n,_ in EVAL_SUITE)} games across {len(EVAL_SUITE)} configs\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "all_results = []\n",
    "per_config_stats = {}\n",
    "\n",
    "for rows, cols, mines, num_games, label in EVAL_SUITE:\n",
    "    config_key = f\"{rows}x{cols}m{mines}\"\n",
    "    wins = 0\n",
    "    config_results = []\n",
    "\n",
    "    for i in range(num_games):\n",
    "        info = play_full_game(model, tokenizer, rows=rows, cols=cols,\n",
    "                              num_mines=mines, seed=5000 + i + hash(config_key) % 1000)\n",
    "        config_results.append(info)\n",
    "        all_results.append(info)\n",
    "\n",
    "        if info[\"result\"] == \"success\":\n",
    "            wins += 1\n",
    "\n",
    "    # Per-config summary\n",
    "    avg_moves = np.mean([r[\"moves\"] for r in config_results])\n",
    "    avg_logical = np.mean([r[\"logical_moves\"] for r in config_results])\n",
    "    avg_progress = np.mean([r[\"progress\"] for r in config_results])\n",
    "    avg_invalids = np.mean([r[\"total_invalids\"] for r in config_results])\n",
    "    wr = wins / num_games * 100\n",
    "\n",
    "    per_config_stats[config_key] = {\n",
    "        \"label\": label, \"wins\": wins, \"total\": num_games,\n",
    "        \"win_rate\": wr, \"avg_moves\": avg_moves, \"avg_progress\": avg_progress,\n",
    "    }\n",
    "\n",
    "    print(f\"  {label:16s} ({config_key:8s}): \"\n",
    "          f\"{wins:2d}/{num_games:2d} wins ({wr:5.1f}%) | \"\n",
    "          f\"moves={avg_moves:4.1f} | logical={avg_logical:4.1f} | \"\n",
    "          f\"progress={avg_progress:.0%} | invalids={avg_invalids:.1f}\")\n",
    "\n",
    "# ── Overall Summary ──\n",
    "total_games = len(all_results)\n",
    "total_wins = sum(1 for r in all_results if r[\"result\"] == \"success\")\n",
    "total_fails = sum(1 for r in all_results if r[\"result\"] == \"failed\")\n",
    "total_ongoing = sum(1 for r in all_results if r[\"result\"] == \"ongoing\")\n",
    "fc = sum(r[\"flags_correct\"] for r in all_results)\n",
    "fw = sum(r[\"flags_wrong\"] for r in all_results)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  OVERALL: {total_wins}/{total_games} wins ({total_wins/total_games*100:.1f}%)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Wins:     {total_wins:4d} ({total_wins/total_games*100:.1f}%)\")\n",
    "print(f\"  Losses:   {total_fails:4d} ({total_fails/total_games*100:.1f}%)\")\n",
    "print(f\"  Timeout:  {total_ongoing:4d} ({total_ongoing/total_games*100:.1f}%)\")\n",
    "print(f\"  Avg moves:    {np.mean([r['moves'] for r in all_results]):.1f}\")\n",
    "print(f\"  Avg progress: {np.mean([r['progress'] for r in all_results]):.0%}\")\n",
    "print(f\"  Avg logical:  {np.mean([r['logical_moves'] for r in all_results]):.1f}\")\n",
    "if fc + fw > 0:\n",
    "    print(f\"  Flag accuracy: {fc}/{fc+fw} ({fc/(fc+fw)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"  Flags: none placed\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306cc45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Save the Model\n",
    "\n",
    "Save your trained model for competition submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LoRA adapters\n",
    "model.save_pretrained(\"my_minesweeper_model\")\n",
    "tokenizer.save_pretrained(\"my_minesweeper_model\")\n",
    "print(\"✅ LoRA adapters saved to: my_minesweeper_model/\")\n",
    "\n",
    "# Save merged model in 16bit (local file name which will be used for eval)\n",
    "if True:\n",
    "    model.save_pretrained_merged(\n",
    "        \"my_minesweeper_model_merged\",\n",
    "        tokenizer,\n",
    "        save_method = \"merged_16bit\"\n",
    "    )\n",
    "    print(\"✅ Merged 16-bit model saved to: my_minesweeper_model_merged/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c190f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Fixes & Improvements Applied\n",
    "\n",
    "## Critical Bugs Fixed\n",
    "| # | Bug | Fix |\n",
    "|---|-----|-----|\n",
    "| 1 | `do_action()` set `_state=\"failed\"` for ALL invalid moves (out-of-bounds, already-revealed, etc.) — game ended on typos | Only `mine` sets state to \"failed\"; other invalid moves return error string but keep game \"ongoing\" |\n",
    "| 2 | Reward functions used `**kwargs` to get `seed`/`move_history` — but GRPOTrainer only passes `completions` as positional; extra dataset columns need `prompts, completions, **kwargs` signature | Changed all reward function signatures to `(prompts, completions, **kwargs)` matching TRL's actual calling convention |\n",
    "| 3 | `gameplay_scores` and `strategic_reward` hardcoded `MinesweeperGame(rows=6, cols=6, num_mines=5)` — no variable board support | Added `board_rows`, `board_cols`, `board_mines` to dataset; `_reconstruct_game()` reads them from kwargs |\n",
    "| 4 | `max_prompt_length=700` truncated prompts with hints on 6x6 boards; larger boards would be destroyed | Increased to 1400 tokens; prompts made more compact |\n",
    "| 5 | `_compute_safe_cells` and `_compute_mine_cells` were separate O(n²) passes, called multiple times per reward evaluation (O(n⁴) total) | Combined into `_compute_safe_and_mine_cells()` — single pass, returns both sets |\n",
    "| 6 | Eval callback decoded FULL output including prompt before parsing | Now decodes only generated tokens: `output[0][input_ids.shape[1]:]` |\n",
    "| 7 | Win-by-flagging was impossible: `_check_win()` only checked revealed cells | Documented: standard Minesweeper wins by revealing all safe cells (flags optional) — this is correct behavior |\n",
    "| 8 | `remove_unused_columns` not explicitly set — could strip `seed`/`move_history` columns | Explicitly set `remove_unused_columns=False` in GRPOConfig |\n",
    "| 9 | Dataset only flagged random cells (often non-mines) creating confusing training data | `_smart_flag()` only flags logically certain mines; `_smart_reveal()` prefers safe cells |\n",
    "| 10 | Invalid JSON scored -50 in gameplay_scores + -5 in valid_json_reward = -35.75 weighted (worse than hitting a mine at -17.5) | Rebalanced: invalid JSON = -10 in gameplay, -3 in format. Mine = -25. Proper severity ordering |\n",
    "\n",
    "## Design Improvements\n",
    "| # | Change | Impact |\n",
    "|---|--------|--------|\n",
    "| 11 | Variable board sizes: 12 configs (5×5 to 10×10, rectangular) with weighted sampling | Model generalizes to any board size |\n",
    "| 12 | 3000 training samples (up from 2000) with board diversity | More coverage |\n",
    "| 13 | Smart move history generation using logical deduction | Cleaner training data; games don't end early from random mine hits |\n",
    "| 14 | Multi-size evaluation suite: 100 games across 7 board configs | Robust performance measurement |\n",
    "| 15 | `beta=0.04` mild KL penalty (was 0.0) | Prevents reward hacking / policy drift |\n",
    "| 16 | `max_completion_length=128` (was 200) | JSON output is ~40 tokens; tighter limit |\n",
    "| 17 | `max_seq_length=2048` (was 1024) | Supports larger board prompts |\n",
    "| 18 | Compact board representation in prompt (row-per-line vs nested JSON) | Fewer tokens for same information |\n",
    "| 19 | `parse_llm_action` now coerces row/col to int | Handles string numbers like \"2\" |\n",
    "| 20 | Edge/corner opening bonus scaled for variable board sizes | Better opening strategy across sizes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46952a1e-915d-4b2f-872a-2ad2d70a7155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09751230-51dc-4997-8b7b-3c87e9773895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45016553-eaa9-4a9e-9e8b-dec9ee50b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e08ad44-0c9a-498e-8b3f-7629d447b6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b786fbd-c069-454d-a1f9-7625b7bd87e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f393470-7ac1-4ce4-9508-d3a91fbe43ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e729a-7064-4928-a991-7da14ea4d087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b591455-067f-42db-bff0-5ccf0eef3ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42152a4-09c5-433b-beb7-21e406915e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc480f-a720-46cc-870a-d0175d97711a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
