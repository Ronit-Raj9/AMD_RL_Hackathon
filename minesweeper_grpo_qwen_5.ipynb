{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48060c32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper LLM Competition - Custom GRPO Training\n",
    "\n",
    "## Goal\n",
    "Finetune an LLM with LoRA using GRPO to play Minesweeper by:\n",
    "- **Input**: JSON game state (board configuration)\n",
    "- **Output**: JSON action (reveal or flag a cell)\n",
    "\n",
    "Teams will compete to train the best Minesweeper-playing LLM!\n",
    "\n",
    "## Training Approach\n",
    "- **Model**: Qwen2.5-14B-Instruct (from /root/.cache/huggingface/hub)\n",
    "- **Method**: GRPO (Group Relative Policy Optimization)\n",
    "- **Framework**: Unsloth (2-6x faster, 70% less VRAM)\n",
    "- **Hardware**: AMD MI300X GPU (192GB HBM3, ROCm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c2e56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load Model with Unsloth\n",
    "\n",
    "Load Qwen3-4B with LoRA configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1118e-9532-4aa3-a4eb-ecf1bb2abb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./workspace/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"./workspace/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecb51d-67e6-42e4-b739-cea6e57ab2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"unsloth/Qwen2.5-14B-Instruct\",\n",
    "    local_dir=\"./workspace/Qwen2.5-14B-Instruct\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af32493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "# Load config\n",
    "with open(\"minesweeper_config_me.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "lora_rank = config.get(\"lora_rank\", 32)\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"/workspace/workspace/Qwen2.5-14B-Instruct\",\n",
    "    load_in_4bit=False,   # AMD → 4bit disabled\n",
    "    max_seq_length=2048,  # Increased: larger boards need longer prompts\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Device: {model.device}\")\n",
    "print(f\"LoRA rank: {lora_rank} (from config)\")\n",
    "\n",
    "# ── Add newline as EOS token so generation stops after first JSON line ──\n",
    "# (replaces stop_strings which isn't supported by this GRPOConfig version)\n",
    "newline_token_id = tokenizer.encode(\"\\n\", add_special_tokens=False)[-1]\n",
    "original_eos = tokenizer.eos_token_id\n",
    "if original_eos != newline_token_id:\n",
    "    model.generation_config.eos_token_id = [original_eos, newline_token_id]\n",
    "    model.config.eos_token_id = [original_eos, newline_token_id]\n",
    "    print(f\"  ✅ Added newline (token {newline_token_id}) as additional EOS → stops after JSON line\")\n",
    "    print(f\"     EOS tokens: {model.generation_config.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f0712",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Add LoRA Adapters\n",
    "\n",
    "Add LoRA layers for efficient finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank,           # alpha = rank → scaling factor = 1.0 (stable training)\n",
    "    lora_dropout = 0.05,              # Small dropout for regularization\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "print(f\"LoRA config: rank={lora_rank}, alpha={lora_rank}, dropout=0.05\")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503f9af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Minesweeper Game Implementation\n",
    "\n",
    "Custom Minesweeper environment supporting:\n",
    "- Customizable board size and mine count\n",
    "- Actions: reveal or flag cells\n",
    "- Win: reveal all safe cells\n",
    "- Lose: reveal a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Set\n",
    "import random\n",
    "import math\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Board size configuration — competition spec: n,m ∈ [1,50], mines 0-20%\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Constants\n",
    "MIN_ROWS, MAX_ROWS = 1, 50\n",
    "MIN_COLS, MAX_COLS = 1, 50\n",
    "MIN_MINE_DENSITY = 0.0    # 0% mines allowed (trivial board)\n",
    "MAX_MINE_DENSITY = 0.20   # 20% of total cells\n",
    "\n",
    "\n",
    "def sample_board_config(rng=None):\n",
    "    \"\"\"Sample a random (rows, cols, num_mines) from the full competition range.\n",
    "\n",
    "    - rows ∈ [1, 50], cols ∈ [1, 50]\n",
    "    - mines ∈ [0, floor(0.20 * rows * cols)]\n",
    "    - Uses a weighted distribution favoring smaller boards during training\n",
    "      (large boards are rare but included for coverage).\n",
    "    \"\"\"\n",
    "    rng = rng or random.Random()\n",
    "\n",
    "    # Weighted size distribution: favor small/medium, still cover large\n",
    "    size_band = rng.random()\n",
    "    if size_band < 0.30:\n",
    "        # Small: 1-8\n",
    "        rows = rng.randint(1, 8)\n",
    "        cols = rng.randint(1, 8)\n",
    "    elif size_band < 0.55:\n",
    "        # Medium: 5-15\n",
    "        rows = rng.randint(5, 15)\n",
    "        cols = rng.randint(5, 15)\n",
    "    elif size_band < 0.75:\n",
    "        # Large: 10-30\n",
    "        rows = rng.randint(10, 30)\n",
    "        cols = rng.randint(10, 30)\n",
    "    elif size_band < 0.90:\n",
    "        # XL: 20-40\n",
    "        rows = rng.randint(20, 40)\n",
    "        cols = rng.randint(20, 40)\n",
    "    else:\n",
    "        # Full range: 1-50 (including extreme cases)\n",
    "        rows = rng.randint(1, 50)\n",
    "        cols = rng.randint(1, 50)\n",
    "\n",
    "    total = rows * cols\n",
    "    max_mines = int(total * MAX_MINE_DENSITY)  # floor(0.20 * total)\n",
    "\n",
    "    if max_mines == 0:\n",
    "        num_mines = 0  # Boards too small for any mines at ≤20%\n",
    "    else:\n",
    "        num_mines = rng.randint(0, max_mines)\n",
    "\n",
    "    return rows, cols, num_mines\n",
    "\n",
    "\n",
    "def mine_density(rows, cols, num_mines):\n",
    "    \"\"\"Compute mine density as a fraction.\"\"\"\n",
    "    total = rows * cols\n",
    "    return num_mines / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MinesweeperGame:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    num_mines: int\n",
    "    seed: Optional[int] = None\n",
    "    _rng: random.Random = field(init=False, repr=False)\n",
    "    _board: List[List[int]] = field(init=False, repr=False)  # -1 = mine, 0-8 = count\n",
    "    _revealed: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _flagged: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _state: str = field(default=\"ongoing\", init=False, repr=False)\n",
    "    _move_count: int = field(default=0, init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # ── Input validation — competition spec: n,m ∈ [1,50] ──\n",
    "        if self.rows < MIN_ROWS or self.cols < MIN_COLS:\n",
    "            raise ValueError(f\"Board too small: {self.rows}x{self.cols} (min {MIN_ROWS}x{MIN_COLS})\")\n",
    "        if self.rows > MAX_ROWS or self.cols > MAX_COLS:\n",
    "            raise ValueError(f\"Board too large: {self.rows}x{self.cols} (max {MAX_ROWS}x{MAX_COLS})\")\n",
    "        if self.num_mines < 0:\n",
    "            raise ValueError(f\"num_mines cannot be negative, got {self.num_mines}\")\n",
    "        if self.num_mines >= self.rows * self.cols:\n",
    "            raise ValueError(f\"Too many mines ({self.num_mines}) for {self.rows}x{self.cols} board\")\n",
    "        # 0 mines is allowed — trivial board, instant win on first reveal cascade\n",
    "\n",
    "        self._rng = random.Random(self.seed)\n",
    "        self._board = [[0 for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "        self._place_mines()\n",
    "        self._calculate_numbers()\n",
    "\n",
    "        # ── Edge case: 0 mines → all cells are safe, auto-win on init check ──\n",
    "        self._check_win()\n",
    "\n",
    "    def _place_mines(self):\n",
    "        \"\"\"Place mines randomly on the board.\"\"\"\n",
    "        if self.num_mines == 0:\n",
    "            return  # No mines to place\n",
    "        positions = [(r, c) for r in range(self.rows) for c in range(self.cols)]\n",
    "        mine_positions = self._rng.sample(positions, self.num_mines)\n",
    "        for r, c in mine_positions:\n",
    "            self._board[r][c] = -1\n",
    "\n",
    "    def _calculate_numbers(self):\n",
    "        \"\"\"Calculate numbers for each cell based on adjacent mines.\"\"\"\n",
    "        for r in range(self.rows):\n",
    "            for c in range(self.cols):\n",
    "                if self._board[r][c] == -1:\n",
    "                    continue\n",
    "                count = 0\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if 0 <= nr < self.rows and 0 <= nc < self.cols:\n",
    "                            if self._board[nr][nc] == -1:\n",
    "                                count += 1\n",
    "                self._board[r][c] = count\n",
    "\n",
    "    def _reveal_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Reveal a cell. Returns True if valid move, False if invalid.\n",
    "        Uses iterative flood-fill to avoid recursion limit on large boards.\n",
    "        \"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed or (row, col) in self._flagged:\n",
    "            return False\n",
    "\n",
    "        stack = [(row, col)]\n",
    "        while stack:\n",
    "            r, c = stack.pop()\n",
    "            if (r, c) in self._revealed:\n",
    "                continue\n",
    "40\n",
    "            self._revealed.add((r, c))\n",
    "\n",
    "            # Hit a mine!\n",
    "            if self._board[r][c] == -1:\n",
    "                self._state = \"failed\"\n",
    "                return True\n",
    "\n",
    "            # Auto-reveal neighbors if cell is 0\n",
    "            if self._board[r][c] == 0:\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < self.rows and 0 <= nc < self.cols\n",
    "                                and (nr, nc) not in self._revealed\n",
    "                                and (nr, nc) not in self._flagged):\n",
    "                            stack.append((nr, nc))\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _flag_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Flag/unflag a cell. Returns True if valid, False if invalid.\"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed:\n",
    "            return False\n",
    "\n",
    "        if (row, col) in self._flagged:\n",
    "            self._flagged.remove((row, col))\n",
    "        else:\n",
    "            self._flagged.add((row, col))\n",
    "        return True\n",
    "\n",
    "    def do_action(self, action: dict) -> str:\n",
    "        \"\"\"Execute an action and return a status string.\n",
    "\n",
    "        Returns one of:\n",
    "          'ok'               - valid move executed\n",
    "          'mine'             - revealed a mine (game over → state='failed')\n",
    "          'win'              - game won after this move (all safe cells revealed)\n",
    "          'invalid_format'   - bad action dict / missing keys / bad types\n",
    "          'out_of_bounds'    - coordinates outside the board\n",
    "          'already_revealed' - cell was already revealed\n",
    "          'flagged_cell'     - tried to reveal a flagged cell\n",
    "          'invalid_flag'     - tried to flag a revealed cell\n",
    "          'game_over'        - game was already over before this call\n",
    "\n",
    "        Only 'mine' sets state='failed'. All other invalid moves\n",
    "        return an error string but keep the game 'ongoing'.\n",
    "        NO move limit — game continues until success or failure.\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return \"game_over\"\n",
    "\n",
    "        if not isinstance(action, dict):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        action_type = action.get(\"type\")\n",
    "        row = action.get(\"row\")\n",
    "        col = action.get(\"col\")\n",
    "\n",
    "        if action_type not in (\"reveal\", \"flag\") or row is None or col is None:\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        try:\n",
    "            row, col = int(row), int(col)\n",
    "        except (ValueError, TypeError):\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return \"out_of_bounds\"\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"already_revealed\"\n",
    "            if (row, col) in self._flagged:\n",
    "                return \"flagged_cell\"\n",
    "            self._reveal_cell(row, col)\n",
    "            self._move_count += 1\n",
    "        else:  # flag\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"invalid_flag\"\n",
    "            self._flag_cell(row, col)\n",
    "            self._move_count += 1\n",
    "\n",
    "        self._check_win()\n",
    "\n",
    "        if self._state == \"failed\":\n",
    "            return \"mine\"\n",
    "        if self._state == \"success\":\n",
    "            return \"win\"\n",
    "        return \"ok\"\n",
    "\n",
    "    def _check_win(self):\n",
    "        \"\"\"Check if player has won.\n",
    "\n",
    "        Win condition: ALL safe (non-mine) cells are revealed.\n",
    "        With 0 mines, ALL cells are safe → need to reveal every cell.\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return\n",
    "        total_cells = self.rows * self.cols\n",
    "        safe_cells = total_cells - self.num_mines\n",
    "        if safe_cells == 0:\n",
    "            self._state = \"success\"\n",
    "        elif len(self._revealed) >= safe_cells:\n",
    "            self._state = \"success\"\n",
    "\n",
    "    def get_visible_board(self) -> List[List[str]]:\n",
    "        \"\"\"Get board state as player sees it.\n",
    "        Uses '?' for unrevealed cells (competition standard).\n",
    "        \"\"\"\n",
    "        visible = []\n",
    "        for r in range(self.rows):\n",
    "            row = []\n",
    "            for c in range(self.cols):\n",
    "                if (r, c) in self._flagged:\n",
    "                    row.append('F')\n",
    "                elif (r, c) in self._revealed:\n",
    "                    val = self._board[r][c]\n",
    "                    row.append('*' if val == -1 else str(val))\n",
    "                else:\n",
    "                    row.append('?')\n",
    "            visible.append(row)\n",
    "        return visible\n",
    "\n",
    "    def state(self) -> str:\n",
    "        return self._state\n",
    "\n",
    "    @property\n",
    "    def move_count(self) -> int:\n",
    "        return self._move_count\n",
    "\n",
    "    def get_mine_positions(self) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"Return set of all mine positions (for reward computation).\"\"\"\n",
    "        return {(r, c) for r in range(self.rows) for c in range(self.cols)\n",
    "                if self._board[r][c] == -1}\n",
    "\n",
    "    def progress(self) -> float:\n",
    "        \"\"\"Fraction of safe cells revealed (0.0 to 1.0).\"\"\"\n",
    "        safe_cells = self.rows * self.cols - self.num_mines\n",
    "        return len(self._revealed) / safe_cells if safe_cells > 0 else 1.0\n",
    "\n",
    "    def game_phase(self) -> str:\n",
    "        \"\"\"Determine the current game phase for prompt selection.\"\"\"\n",
    "        if self._move_count == 0 and len(self._revealed) == 0:\n",
    "            return \"opening\"\n",
    "        prog = self.progress()\n",
    "        if prog >= 0.80:\n",
    "            return \"endgame\"\n",
    "        return \"midgame\"\n",
    "\n",
    "    def pretty_print(self) -> str:\n",
    "        \"\"\"Pretty print the board.\"\"\"\n",
    "        visible = self.get_visible_board()\n",
    "        lines = []\n",
    "\n",
    "        # Header — handle up to 2-digit column numbers\n",
    "        col_width = 3 if self.cols > 10 else 2\n",
    "        header = \"   \" + \" \".join(f\"{i:>{col_width-1}d}\" for i in range(self.cols))\n",
    "        lines.append(header)\n",
    "        lines.append(\"  \" + \"─\" * (self.cols * col_width + 1))\n",
    "\n",
    "        # Board\n",
    "        for r, row in enumerate(visible):\n",
    "            sep = \" \" * (col_width - 1)\n",
    "            line = f\"{r:2d}│ \" + sep.join(row)\n",
    "            lines.append(line)\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Sanity tests\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "print(\"Testing MinesweeperGame (competition spec: 1-50 boards, 0-20% mines)...\")\n",
    "\n",
    "# Basic gameplay\n",
    "g = MinesweeperGame(5, 5, 3, seed=0)\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": -1, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\", \"BUG: out_of_bounds should NOT end the game\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 99, \"col\": 0}) == \"out_of_bounds\"\n",
    "assert g.state() == \"ongoing\"\n",
    "assert g.do_action({\"type\": \"flag\", \"row\": 0, \"col\": 0}) == \"ok\"\n",
    "assert g.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0}) == \"flagged_cell\"\n",
    "assert g.state() == \"ongoing\", \"BUG: flagged_cell should NOT end the game\"\n",
    "assert g.do_action({}) == \"invalid_format\"\n",
    "assert g.state() == \"ongoing\", \"BUG: invalid_format should NOT end the game\"\n",
    "print(\"  ✅ do_action keeps game ongoing on invalid moves\")\n",
    "\n",
    "# Verify '?' is used for unrevealed cells\n",
    "board = g.get_visible_board()\n",
    "has_question = any('?' in row for row in board)\n",
    "assert has_question, \"Board should use '?' for unrevealed cells\"\n",
    "print(\"  ✅ Board uses '?' for unrevealed cells\")\n",
    "\n",
    "# Game phase tracking\n",
    "assert g.game_phase() == \"opening\" or g.move_count > 0\n",
    "print(\"  ✅ Game phase tracking works\")\n",
    "\n",
    "# ── Edge case: 0 mines board ──\n",
    "g0 = MinesweeperGame(3, 3, 0, seed=42)\n",
    "assert g0.state() == \"ongoing\"\n",
    "result = g0.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\", f\"0-mine board should win on first reveal, got {result}\"\n",
    "assert g0.state() == \"success\"\n",
    "print(\"  ✅ 0-mine board → instant win on first reveal\")\n",
    "\n",
    "# ── Edge case: 1x1 board with 0 mines ──\n",
    "g1x1 = MinesweeperGame(1, 1, 0, seed=42)\n",
    "assert g1x1.state() == \"ongoing\"\n",
    "result = g1x1.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\"\n",
    "print(\"  ✅ 1x1 board with 0 mines works\")\n",
    "\n",
    "# ── Edge case: 1x1 board — cannot have mines ──\n",
    "try:\n",
    "    MinesweeperGame(1, 1, 1, seed=42)\n",
    "    assert False, \"Should have raised ValueError\"\n",
    "except ValueError:\n",
    "    pass\n",
    "print(\"  ✅ 1x1 board with 1 mine correctly rejected\")\n",
    "\n",
    "# ── Edge case: 50x50 board ──\n",
    "g50 = MinesweeperGame(50, 50, 500, seed=42)\n",
    "assert g50.state() == \"ongoing\"\n",
    "assert g50.rows == 50 and g50.cols == 50\n",
    "assert mine_density(50, 50, 500) == 0.20\n",
    "print(\"  ✅ 50x50 board with 20% mines works\")\n",
    "\n",
    "# ── Edge cases: rectangular ──\n",
    "g1x50 = MinesweeperGame(1, 50, 10, seed=42)\n",
    "assert g1x50.rows == 1 and g1x50.cols == 50\n",
    "g50x1 = MinesweeperGame(50, 1, 10, seed=42)\n",
    "assert g50x1.rows == 50 and g50x1.cols == 1\n",
    "print(\"  ✅ 1x50 and 50x1 boards work\")\n",
    "\n",
    "# ── Edge case: 2x2 with 0 mines ──\n",
    "g2x2 = MinesweeperGame(2, 2, 0, seed=42)\n",
    "result = g2x2.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "assert result == \"win\"\n",
    "print(\"  ✅ 2x2 board with 0 mines → instant cascade win\")\n",
    "\n",
    "# Variable sizes across the full range\n",
    "for r, c, m in [(1,1,0), (2,2,0), (3,3,1), (5,5,3), (10,10,20),\n",
    "                (20,20,80), (30,30,180), (50,50,500), (1,50,10), (50,1,10)]:\n",
    "    g = MinesweeperGame(r, c, m, seed=42)\n",
    "    assert g.rows == r and g.cols == c\n",
    "    board = g.get_visible_board()\n",
    "    assert len(board) == r and len(board[0]) == c\n",
    "print(f\"  ✅ Variable board sizes (1x1 to 50x50) work\")\n",
    "\n",
    "# Test sample_board_config produces valid configs\n",
    "rng = random.Random(42)\n",
    "for _ in range(200):\n",
    "    r, c, m = sample_board_config(rng)\n",
    "    assert MIN_ROWS <= r <= MAX_ROWS\n",
    "    assert MIN_COLS <= c <= MAX_COLS\n",
    "    assert 0 <= m <= int(r * c * MAX_MINE_DENSITY)\n",
    "    g = MinesweeperGame(r, c, m, seed=42)\n",
    "print(f\"  ✅ sample_board_config produces valid configs (200 tested)\")\n",
    "\n",
    "# Test progress\n",
    "g = MinesweeperGame(5, 5, 3, seed=42)\n",
    "assert g.progress() == 0.0\n",
    "print(f\"  ✅ All game engine tests passed\")\n",
    "print(f\"  Board range: {MIN_ROWS}-{MAX_ROWS} rows × {MIN_COLS}-{MAX_COLS} cols\")\n",
    "print(f\"  Mine density: {MIN_MINE_DENSITY*100:.0f}%-{MAX_MINE_DENSITY*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617e14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Prompt System & Game Logic Helpers\n",
    "\n",
    "## ReAct Prompt System (based on LAMER paper — 74% win on MineSweeper)\n",
    "Two prompt modes:\n",
    "- **Training prompt** — Full ReAct (Reason + Act) with step-by-step reasoning, constraint examples, format enforcement\n",
    "- **Inference prompt** — ~60% fewer tokens for fast evaluation\n",
    "\n",
    "## LAMER Paper Key Findings Applied\n",
    "| Paper Finding | Implementation |\n",
    "|--------------|----------------|\n",
    "| ReAct > zero-shot (6.3% vs 4.5% base) | \"Think step-by-step → scan → estimate → act\" |\n",
    "| Pre-computed CoT hints boost performance | SAFE/MINE cell lists in every prompt |\n",
    "| RL training reaches 52% win rate | GRPO with `temperature=1.0`, `num_iterations=2` |\n",
    "| Center-opening for dense boards | Reward center, penalize edges on density >10% |\n",
    "| `temperature=0.7` for eval | Optimal eval temperature from paper |\n",
    "\n",
    "## 3-Tier Board Representation\n",
    "| Format | Board Size | Display |\n",
    "|--------|-----------|---------|\n",
    "| **A (Small)** | 1–20 | Full grid with borders and headers |\n",
    "| **B (Medium)** | 21–35 | Frontier cells + revealed number regions |\n",
    "| **C (Large)** | 36–50 | Quadrant summary + critical area snippets |\n",
    "\n",
    "## Prompt Structure (Training)\n",
    "```\n",
    "BOARD STATE → REASONING (STEP 1: scan constraints → STEP 2: probability) → OUTPUT FORMAT (valid + invalid examples)\n",
    "```\n",
    "\n",
    "## Symbol Legend\n",
    "`?`=unrevealed  `F`=flagged  `0`-`8`=revealed safe\n",
    "\n",
    "## Output Format\n",
    "```json\n",
    "{\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# ULTRA-MINIMAL PROMPTING SYSTEM — v2 Complete Rewrite\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# PROBLEM: Model outputs verbose explanations + ```json blocks that get \n",
    "# truncated by max_new_tokens=128, causing parse failures.\n",
    "#\n",
    "# SOLUTION:\n",
    "#   1. ULTRA-SHORT prompts (~150-250 chars)\n",
    "#   2. Few-shot examples showing EXACT expected output  \n",
    "#   3. Explicit \"DO NOT\" instructions\n",
    "#   4. Robust parser that handles ```json blocks\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "\n",
    "def _compute_safe_and_mine_cells(game: MinesweeperGame):\n",
    "    \"\"\"Compute both safe and mine cells in a SINGLE pass.\"\"\"\n",
    "    safe = set()\n",
    "    mines = set()\n",
    "\n",
    "    for r in range(game.rows):\n",
    "        for c in range(game.cols):\n",
    "            if (r, c) not in game._revealed:\n",
    "                continue\n",
    "            val = game._board[r][c]\n",
    "            if val <= 0:\n",
    "                continue\n",
    "\n",
    "            flags = 0\n",
    "            unrevealed = []\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    if dr == 0 and dc == 0:\n",
    "                        continue\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if 0 <= nr < game.rows and 0 <= nc < game.cols:\n",
    "                        if (nr, nc) in game._flagged:\n",
    "                            flags += 1\n",
    "                        elif (nr, nc) not in game._revealed:\n",
    "                            unrevealed.append((nr, nc))\n",
    "\n",
    "            remaining = val - flags\n",
    "\n",
    "            if remaining == 0 and unrevealed:\n",
    "                for cell in unrevealed:\n",
    "                    safe.add(cell)\n",
    "            elif remaining > 0 and remaining == len(unrevealed):\n",
    "                for cell in unrevealed:\n",
    "                    mines.add(cell)\n",
    "\n",
    "    return safe, mines\n",
    "\n",
    "\n",
    "def _compute_safe_cells(game: MinesweeperGame) -> list:\n",
    "    safe, _ = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in safe]\n",
    "\n",
    "\n",
    "def _compute_mine_cells(game: MinesweeperGame) -> list:\n",
    "    _, mines = _compute_safe_and_mine_cells(game)\n",
    "    return [list(c) for c in mines]\n",
    "\n",
    "\n",
    "def _is_logically_safe(game: MinesweeperGame, row: int, col: int) -> bool:\n",
    "    safe, _ = _compute_safe_and_mine_cells(game)\n",
    "    return (row, col) in safe\n",
    "\n",
    "\n",
    "def _is_logically_mine(game: MinesweeperGame, row: int, col: int) -> bool:\n",
    "    _, mines = _compute_safe_and_mine_cells(game)\n",
    "    return (row, col) in mines\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# COMPACT BOARD — Minimal representation\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _format_board_compact(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Ultra-compact board: just the grid, no headers for small boards.\"\"\"\n",
    "    board = game.get_visible_board()\n",
    "    \n",
    "    if game.rows <= 10 and game.cols <= 10:\n",
    "        # Tiny format: no headers\n",
    "        return \"\\n\".join(\"\".join(row) for row in board)\n",
    "    else:\n",
    "        # Larger boards: minimal headers\n",
    "        lines = []\n",
    "        for r, row in enumerate(board):\n",
    "            lines.append(f\"{r:2d}|\" + \"\".join(row))\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# ULTRA-MINIMAL PROMPT — Forces JSON-only output\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def format_state_for_llm(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Generate ULTRA-SHORT prompt with few-shot example.\n",
    "    \n",
    "    Key insight: The model keeps outputting explanations because it's \n",
    "    instruction-tuned. We MUST show it the exact format with an example.\n",
    "    \"\"\"\n",
    "    if game.state() == \"success\":\n",
    "        return '{\"type\":\"reveal\",\"row\":0,\"col\":0}'  # Dummy, game over\n",
    "    \n",
    "    rows, cols = game.rows, game.cols\n",
    "    mines = game.num_mines\n",
    "    \n",
    "    # === CRITICAL: Edge case ultra-explicit prompts ===\n",
    "    if rows == 1 and cols == 1:\n",
    "        return f\"\"\"1x1 0mines\n",
    "?\n",
    "ONLY ONE CELL EXISTS at (0,0). Reveal it to win.\n",
    "{{\"type\":\"reveal\",\"row\":0,\"col\":0}}\"\"\"\n",
    "    \n",
    "    if mines == 0:\n",
    "        # Find first unrevealed cell\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if (r, c) not in game._revealed:\n",
    "                    return f\"\"\"{rows}x{cols} 0mines ALL SAFE\n",
    "{_format_board_compact(game)}\n",
    "NO MINES - reveal ANY cell to win!\n",
    "{{\"type\":\"reveal\",\"row\":{r},\"col\":{c}}}\"\"\"\n",
    "    \n",
    "    # Normal boards - existing logic\n",
    "    board = _format_board_compact(game)\n",
    "    \n",
    "    safe_cells = _compute_safe_cells(game)\n",
    "    mine_cells = _compute_mine_cells(game)\n",
    "    \n",
    "    if safe_cells:\n",
    "        hint = f\"Safe:{safe_cells[0]}\"\n",
    "    elif mine_cells:\n",
    "        hint = f\"Mine:{mine_cells[0]}\"\n",
    "    elif len(game._revealed) == 0:\n",
    "        hint = f\"Start:center\"\n",
    "    else:\n",
    "        hint = \"Guess:any ?\"\n",
    "    \n",
    "    prompt = f\"\"\"{rows}x{cols} {mines}mines {hint}\n",
    "{board}\n",
    "Reply ONLY: {{\"type\":\"reveal\",\"row\":N,\"col\":N}} or {{\"type\":\"flag\",\"row\":N,\"col\":N}}\n",
    "Example: {{\"type\":\"reveal\",\"row\":2,\"col\":3}}\n",
    "DO NOT explain. DO NOT use ```json. Just the JSON.\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_llm_action(response: str) -> dict:\n",
    "    \"\"\"Robust parser that handles various output formats.\"\"\"\n",
    "    if not response:\n",
    "        return None\n",
    "    \n",
    "    response = response.strip()\n",
    "    \n",
    "    # Strategy 1: Try pure JSON first\n",
    "    try:\n",
    "        action = json.loads(response)\n",
    "        if _validate_action(action):\n",
    "            return action\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    # Strategy 2: Extract from ```json blocks\n",
    "    code_block_match = re.search(r'```(?:json)?\\s*(\\{[^`]*?\\})\\s*```', response, re.DOTALL)\n",
    "    if code_block_match:\n",
    "        try:\n",
    "            action = json.loads(code_block_match.group(1))\n",
    "            if _validate_action(action):\n",
    "                return action\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    \n",
    "    # Strategy 3: Extract JSON after removing code block markers\n",
    "    cleaned = re.sub(r'```(?:json)?', '', response)\n",
    "    cleaned = cleaned.strip()\n",
    "    try:\n",
    "        action = json.loads(cleaned)\n",
    "        if _validate_action(action):\n",
    "            return action\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    # Strategy 4: Find first valid JSON object\n",
    "    for match in re.finditer(r'\\{[^{}]*?\"type\"[^{}]*?\"row\"[^{}]*?\"col\"[^{}]*?\\}', response):\n",
    "        try:\n",
    "            action = json.loads(match.group())\n",
    "            if _validate_action(action):\n",
    "                return action\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    \n",
    "    # Strategy 5: Field extraction fallback\n",
    "    type_match = re.search(r'\"type\"\\s*:\\s*\"(reveal|flag)\"', response)\n",
    "    row_match = re.search(r'\"row\"\\s*:\\s*(\\d+)', response)\n",
    "    col_match = re.search(r'\"col\"\\s*:\\s*(\\d+)', response)\n",
    "    \n",
    "    if type_match and row_match and col_match:\n",
    "        return {\n",
    "            \"type\": type_match.group(1),\n",
    "            \"row\": int(row_match.group(1)),\n",
    "            \"col\": int(col_match.group(1))\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def _validate_action(action: dict) -> bool:\n",
    "    \"\"\"Check if action dict has all required fields.\"\"\"\n",
    "    if not isinstance(action, dict):\n",
    "        return False\n",
    "    if \"type\" not in action or \"row\" not in action or \"col\" not in action:\n",
    "        return False\n",
    "    if action[\"type\"] not in (\"reveal\", \"flag\"):\n",
    "        return False\n",
    "    try:\n",
    "        action[\"row\"] = int(action[\"row\"])\n",
    "        action[\"col\"] = int(action[\"col\"])\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Tests\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ULTRA-MINIMAL PROMPT SYSTEM v2\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test prompt lengths (should be ~150-300 chars now)\n",
    "print(\"\\nPrompt lengths (target: 150-300 chars):\")\n",
    "for rows, cols, mines in [(1,1,0), (3,3,1), (5,5,0), (6,6,5), (10,10,20)]:\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=42)\n",
    "    if game.state() == \"ongoing\":\n",
    "        prompt = format_state_for_llm(game)\n",
    "        print(f\"  {rows:2d}x{cols:2d} m={mines:2d}: {len(prompt):4d} chars\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE: 1x1 board (0 mines) — was failing before\")\n",
    "print(\"=\" * 70)\n",
    "game = MinesweeperGame(1, 1, 0, seed=42)\n",
    "print(format_state_for_llm(game))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE: 5x5 board (0 mines) — was failing before\")\n",
    "print(\"=\" * 70)\n",
    "game = MinesweeperGame(5, 5, 0, seed=42)\n",
    "print(format_state_for_llm(game))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE: 6x6 board (5 mines)\")\n",
    "print(\"=\" * 70)\n",
    "game = MinesweeperGame(6, 6, 5, seed=42)\n",
    "print(format_state_for_llm(game))\n",
    "\n",
    "# Test parser robustness\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PARSER ROBUSTNESS TESTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_cases = [\n",
    "    ('Pure JSON', '{\"type\":\"reveal\",\"row\":3,\"col\":3}'),\n",
    "    ('With newline', '{\"type\":\"reveal\",\"row\":3,\"col\":3}\\n'),\n",
    "    ('Code block', '```json\\n{\"type\":\"reveal\",\"row\":3,\"col\":3}\\n```'),\n",
    "    ('Verbose + JSON', 'I will reveal cell at row 3 col 3: {\"type\":\"reveal\",\"row\":3,\"col\":3}'),\n",
    "    ('Truncated block', '```json\\n{\"type\":\"reveal\",\"row\":3,\"col\":3}'),\n",
    "    ('Partial JSON', 'reveal row 3 col 3 {\"type\":\"reveal\",\"row\":3,\"col\":3'),\n",
    "    ('Scattered fields', 'type is \"reveal\" and \"row\": 3 and \"col\": 3'),\n",
    "]\n",
    "\n",
    "for name, test_input in test_cases:\n",
    "    result = parse_llm_action(test_input)\n",
    "    status = \"✅\" if result else \"❌\"\n",
    "    print(f\"  {status} {name}: {result}\")\n",
    "\n",
    "print(\"\\n✅ Ultra-minimal prompt system ready\")\n",
    "print(\"   - Prompts now ~150-300 chars (was 500+)\")\n",
    "print(\"   - Few-shot example included\")\n",
    "print(\"   - Explicit 'DO NOT explain' instruction\")\n",
    "print(\"   - Robust parser handles code blocks & truncation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302a238",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Model Before Training\n",
    "\n",
    "See how the base model performs without finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=42)\n",
    "prompt = format_state_for_llm(game)\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True,\n",
    ")\n",
    "\n",
    "print(\"=== Base Model Response ===\")\n",
    "output = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.7,\n",
    "    top_p = 0.9,\n",
    "    max_new_tokens = 128,\n",
    "    do_sample = True,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b3c5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# GRPO Reward Functions\n",
    "\n",
    "Define reward functions to guide the model's learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ca52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# REWARD FUNCTIONS v2 — Aggressive penalties for invalid output\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# \n",
    "# KEY INSIGHT: Previous rewards weren't working because:\n",
    "#   1. Verbose output with valid JSON still got positive scores\n",
    "#   2. Invalid JSON penalty (-20) was offset by other rewards\n",
    "#   3. Model learned verbosity was OK as long as JSON was somewhere\n",
    "#\n",
    "# NEW APPROACH:\n",
    "#   1. PURE JSON gets massive bonus (+15)\n",
    "#   2. Verbose output with JSON gets PENALTY (not just reduced bonus)\n",
    "#   3. Invalid JSON gets EXTREME penalty (-30)\n",
    "#   4. Total invalid penalty across all rewards = -50+\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "\n",
    "def _reconstruct_game(idx, kwargs):\n",
    "    \"\"\"Reconstruct a MinesweeperGame from dataset columns.\"\"\"\n",
    "    seeds = kwargs.get(\"seed\", [])\n",
    "    move_histories = kwargs.get(\"move_history\", [])\n",
    "    rows_list = kwargs.get(\"board_rows\", [])\n",
    "    cols_list = kwargs.get(\"board_cols\", [])\n",
    "    mines_list = kwargs.get(\"board_mines\", [])\n",
    "\n",
    "    if idx >= len(seeds) or idx >= len(move_histories):\n",
    "        return None, None\n",
    "\n",
    "    seed = seeds[idx]\n",
    "    rows = rows_list[idx] if idx < len(rows_list) else 6\n",
    "    cols = cols_list[idx] if idx < len(cols_list) else 6\n",
    "    num_mines = mines_list[idx] if idx < len(mines_list) else 5\n",
    "\n",
    "    mh_raw = move_histories[idx]\n",
    "    if isinstance(mh_raw, str):\n",
    "        move_history = json.loads(mh_raw)\n",
    "    else:\n",
    "        move_history = list(mh_raw)\n",
    "\n",
    "    game = MinesweeperGame(rows=int(rows), cols=int(cols),\n",
    "                           num_mines=int(num_mines), seed=int(seed))\n",
    "    for prev in move_history:\n",
    "        result = game.do_action(prev)\n",
    "        if result == \"mine\":\n",
    "            return None, None\n",
    "\n",
    "    return game, move_history\n",
    "\n",
    "\n",
    "def _difficulty_multiplier(game) -> float:\n",
    "    \"\"\"Difficulty-based reward multiplier (1.0 to 1.5).\"\"\"\n",
    "    board_size = game.rows * game.cols\n",
    "    if board_size == 0:\n",
    "        return 1.0\n",
    "    density = game.num_mines / board_size if board_size > 0 else 0\n",
    "    return 1.0 + 0.5 * min(1.0, density / 0.20)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 1: FORMAT REWARD — Maximum weight on pure JSON output\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def valid_json_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"Format reward with EXTREME focus on pure JSON.\n",
    "    \n",
    "    Scoring (designed so verbose output is ALWAYS worse):\n",
    "      Pure JSON only:      +15  (best case)\n",
    "      JSON + whitespace:   +10  (acceptable)\n",
    "      JSON + <20 chars:    +2   (marginal)\n",
    "      JSON + 20-50 chars:  -5   (penalty for verbosity)\n",
    "      JSON + 50-100 chars: -15  (strong penalty)\n",
    "      JSON + >100 chars:   -25  (severe penalty for explanation)\n",
    "      No valid JSON:       -30  (EXTREME PENALTY)\n",
    "    \n",
    "    This ensures verbosity is ALWAYS punished, even if JSON is valid.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"].strip() if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "        \n",
    "        # ═══ NO VALID JSON: EXTREME PENALTY ═══\n",
    "        if action is None:\n",
    "            scores.append(-30.0)\n",
    "            continue\n",
    "        \n",
    "        # ═══ VALID JSON: Score based on purity ═══\n",
    "        response_len = len(response)\n",
    "        \n",
    "        # Check if response is pure JSON\n",
    "        try:\n",
    "            parsed = json.loads(response)\n",
    "            if isinstance(parsed, dict) and \"type\" in parsed:\n",
    "                scores.append(15.0)  # Pure JSON - maximum reward\n",
    "                continue\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        \n",
    "        # JSON found but with extra content - PENALIZE verbosity\n",
    "        json_match = re.search(r'\\{[^{}]*\\}', response)\n",
    "        if json_match:\n",
    "            json_len = len(json_match.group())\n",
    "            extra_chars = response_len - json_len\n",
    "            \n",
    "            if extra_chars <= 5:\n",
    "                scores.append(10.0)   # Just whitespace/newline\n",
    "            elif extra_chars <= 20:\n",
    "                scores.append(2.0)    # Minor extra (maybe closing ```)\n",
    "            elif extra_chars <= 50:\n",
    "                scores.append(-5.0)   # PENALTY: some explanation\n",
    "            elif extra_chars <= 100:\n",
    "                scores.append(-15.0)  # STRONG PENALTY: verbose\n",
    "            else:\n",
    "                scores.append(-25.0)  # SEVERE: full explanation\n",
    "        else:\n",
    "            scores.append(-30.0)  # Shouldn't happen\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 2: GAMEPLAY REWARD — Valid game actions\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def gameplay_scores(prompts, completions, **kwargs):\n",
    "    \"\"\"Gameplay reward - penalizes invalid moves heavily.\n",
    "    \n",
    "    Invalid JSON:          -20 (also penalized in format reward)\n",
    "    Out of bounds:         -25\n",
    "    Already revealed/flag: -25\n",
    "    Hit mine:              -20\n",
    "    Valid move:            +10 to +20\n",
    "    Win bonus:             +50\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"] if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        # Invalid JSON - compound penalty\n",
    "        if action is None:\n",
    "            scores.append(-20.0)\n",
    "            continue\n",
    "\n",
    "        game, move_history = _reconstruct_game(idx, kwargs)\n",
    "        if game is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        row, col = action[\"row\"], action[\"col\"]\n",
    "        action_type = action[\"type\"]\n",
    "        diff_mult = _difficulty_multiplier(game)\n",
    "\n",
    "        # ═══ OUT OF BOUNDS: SEVERE PENALTY ═══\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(-25.0 * diff_mult)\n",
    "            continue\n",
    "\n",
    "        # ═══ 0-MINE BOARD: Simple handling ═══\n",
    "        if game.num_mines == 0:\n",
    "            if action_type == \"reveal\":\n",
    "                if (row, col) in game._revealed:\n",
    "                    scores.append(-25.0)  # Already revealed\n",
    "                else:\n",
    "                    # Check for win\n",
    "                    game_copy = MinesweeperGame(\n",
    "                        rows=game.rows, cols=game.cols,\n",
    "                        num_mines=0, seed=kwargs.get(\"seed\", [0])[idx]\n",
    "                    )\n",
    "                    for prev in move_history:\n",
    "                        game_copy.do_action(prev)\n",
    "                    result = game_copy.do_action(action)\n",
    "                    if result == \"win\":\n",
    "                        scores.append(50.0)  # Win bonus\n",
    "                    else:\n",
    "                        scores.append(15.0)  # Valid reveal\n",
    "            else:\n",
    "                scores.append(-15.0)  # Don't flag 0-mine boards\n",
    "            continue\n",
    "\n",
    "        # ═══ STANDARD BOARD ═══\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            # Already revealed\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-25.0 * diff_mult)\n",
    "                continue\n",
    "            \n",
    "            # Flagged cell\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-20.0 * diff_mult)\n",
    "                continue\n",
    "            \n",
    "            # Hit mine\n",
    "            if game._board[row][col] == -1:\n",
    "                scores.append(-20.0 * diff_mult)\n",
    "                continue\n",
    "            \n",
    "            # Valid reveal\n",
    "            score = 15.0 if (row, col) in safe_set else 10.0\n",
    "            \n",
    "            # Check for win\n",
    "            game_copy = MinesweeperGame(\n",
    "                rows=game.rows, cols=game.cols,\n",
    "                num_mines=game.num_mines, seed=kwargs.get(\"seed\", [0])[idx]\n",
    "            )\n",
    "            for prev in move_history:\n",
    "                game_copy.do_action(prev)\n",
    "            result = game_copy.do_action(action)\n",
    "            if result == \"win\":\n",
    "                score += 50.0\n",
    "            \n",
    "            scores.append(score * diff_mult)\n",
    "\n",
    "        elif action_type == \"flag\":\n",
    "            # Already flagged\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-25.0 * diff_mult)\n",
    "                continue\n",
    "            \n",
    "            # Flag revealed cell\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-25.0 * diff_mult)\n",
    "                continue\n",
    "            \n",
    "            # Flag mine (good) vs flag safe cell (bad)\n",
    "            if game._board[row][col] == -1:\n",
    "                score = 20.0 if (row, col) in mine_set else 12.0\n",
    "            else:\n",
    "                score = -10.0  # Flagged safe cell\n",
    "            \n",
    "            scores.append(score * diff_mult)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Reward 3: STRATEGIC REWARD — Bonus for smart play\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def strategic_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"Strategic reward - smaller bonuses for good strategy.\"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"] if completion else \"\"\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        # Invalid gets penalty here too\n",
    "        if action is None:\n",
    "            scores.append(-10.0)\n",
    "            continue\n",
    "\n",
    "        game, move_history = _reconstruct_game(idx, kwargs)\n",
    "        if game is None or game.state() != \"ongoing\":\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        row, col = action[\"row\"], action[\"col\"]\n",
    "        action_type = action[\"type\"]\n",
    "\n",
    "        # Out of bounds\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(-10.0)\n",
    "            continue\n",
    "\n",
    "        # Simple 0-mine handling\n",
    "        if game.num_mines == 0:\n",
    "            scores.append(5.0 if action_type == \"reveal\" else -5.0)\n",
    "            continue\n",
    "\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "        score = 0.0\n",
    "\n",
    "        # Opening move bonus\n",
    "        if len(game._revealed) == 0 and action_type == \"reveal\":\n",
    "            center_r, center_c = game.rows // 2, game.cols // 2\n",
    "            dist = abs(row - center_r) + abs(col - center_c)\n",
    "            score += max(0, 5 - dist)\n",
    "\n",
    "        # Logical move bonus\n",
    "        if action_type == \"reveal\" and (row, col) in safe_set:\n",
    "            score += 5.0\n",
    "        elif action_type == \"flag\" and (row, col) in mine_set:\n",
    "            score += 5.0\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Tests\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"REWARD FUNCTIONS v2 — Aggressive penalties for verbosity\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_prompts = [\"test\"]\n",
    "test_kwargs = {\n",
    "    \"seed\": [42],\n",
    "    \"move_history\": [\"[]\"],\n",
    "    \"board_rows\": [6],\n",
    "    \"board_cols\": [6],\n",
    "    \"board_mines\": [5],\n",
    "}\n",
    "\n",
    "# Test cases\n",
    "print(\"\\n1. PURE JSON (best case):\")\n",
    "pure_json = [[{\"role\": \"assistant\", \"content\": '{\"type\":\"reveal\",\"row\":3,\"col\":3}'}]]\n",
    "r1 = valid_json_reward(test_prompts, pure_json, **test_kwargs)[0]\n",
    "r2 = gameplay_scores(test_prompts, pure_json, **test_kwargs)[0]\n",
    "r3 = strategic_reward(test_prompts, pure_json, **test_kwargs)[0]\n",
    "total = r1 * 0.35 + r2 * 0.50 + r3 * 0.15\n",
    "print(f\"   format={r1:+.1f} gameplay={r2:+.1f} strategic={r3:+.1f} → TOTAL={total:+.2f}\")\n",
    "\n",
    "print(\"\\n2. JSON with code block (common model output):\")\n",
    "code_block = [[{\"role\": \"assistant\", \"content\": '```json\\n{\"type\":\"reveal\",\"row\":3,\"col\":3}\\n```'}]]\n",
    "r1 = valid_json_reward(test_prompts, code_block, **test_kwargs)[0]\n",
    "r2 = gameplay_scores(test_prompts, code_block, **test_kwargs)[0]\n",
    "r3 = strategic_reward(test_prompts, code_block, **test_kwargs)[0]\n",
    "total = r1 * 0.35 + r2 * 0.50 + r3 * 0.15\n",
    "print(f\"   format={r1:+.1f} gameplay={r2:+.1f} strategic={r3:+.1f} → TOTAL={total:+.2f}\")\n",
    "\n",
    "print(\"\\n3. VERBOSE with JSON (what model currently does):\")\n",
    "verbose = [[{\"role\": \"assistant\", \"content\": 'Given the scenario, I will reveal row 3 col 3: {\"type\":\"reveal\",\"row\":3,\"col\":3}'}]]\n",
    "r1 = valid_json_reward(test_prompts, verbose, **test_kwargs)[0]\n",
    "r2 = gameplay_scores(test_prompts, verbose, **test_kwargs)[0]\n",
    "r3 = strategic_reward(test_prompts, verbose, **test_kwargs)[0]\n",
    "total = r1 * 0.35 + r2 * 0.50 + r3 * 0.15\n",
    "print(f\"   format={r1:+.1f} gameplay={r2:+.1f} strategic={r3:+.1f} → TOTAL={total:+.2f}\")\n",
    "\n",
    "print(\"\\n4. INVALID JSON (worst case):\")\n",
    "invalid = [[{\"role\": \"assistant\", \"content\": \"I think row 3 col 3 is safe because...\"}]]\n",
    "r1 = valid_json_reward(test_prompts, invalid, **test_kwargs)[0]\n",
    "r2 = gameplay_scores(test_prompts, invalid, **test_kwargs)[0]\n",
    "r3 = strategic_reward(test_prompts, invalid, **test_kwargs)[0]\n",
    "total = r1 * 0.35 + r2 * 0.50 + r3 * 0.15\n",
    "print(f\"   format={r1:+.1f} gameplay={r2:+.1f} strategic={r3:+.1f} → TOTAL={total:+.2f}\")\n",
    "\n",
    "print(\"\\n5. OUT OF BOUNDS:\")\n",
    "oob = [[{\"role\": \"assistant\", \"content\": '{\"type\":\"reveal\",\"row\":99,\"col\":99}'}]]\n",
    "r1 = valid_json_reward(test_prompts, oob, **test_kwargs)[0]\n",
    "r2 = gameplay_scores(test_prompts, oob, **test_kwargs)[0]\n",
    "r3 = strategic_reward(test_prompts, oob, **test_kwargs)[0]\n",
    "total = r1 * 0.35 + r2 * 0.50 + r3 * 0.15\n",
    "print(f\"   format={r1:+.1f} gameplay={r2:+.1f} strategic={r3:+.1f} → TOTAL={total:+.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"REWARD SUMMARY (with weights [0.35, 0.50, 0.15]):\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  Pure JSON + valid move:  ~+13.5 total\")\n",
    "print(\"  Code block + valid:      ~+8 total\")\n",
    "print(\"  Verbose + valid:         ~+3 total (still positive but much lower)\")\n",
    "print(\"  Invalid JSON:            ~-22 total (SEVERE)\")\n",
    "print(\"  Out of bounds:           ~-13 total\")\n",
    "print()\n",
    "print(\"✅ Verbosity is now ALWAYS worse than concise output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b787f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Exhaustive Training Dataset Generation\n",
    "\n",
    "6-phase composition targeting **4000 samples** with density-stratified sampling:\n",
    "\n",
    "| Phase | Budget | Description |\n",
    "|-------|--------|-------------|\n",
    "| 1. Edge Cases | 10% | 50+ explicit configs (trivial, linear, rectangular, density extremes) |\n",
    "| 2. Opening | 25% | 75% fresh + 25% single-move — fix 75% early death rate |\n",
    "| 3. Pattern-Specific | 15% | Satisfied numbers (60%) + multi-region boards (40%) |\n",
    "| 4. Mid-Game | 25% | 3-15 moves, progressive flagging 10%→30%→50% |\n",
    "| 5. Endgame | 15% | 80-98% revealed, flag accounting, completion strategy |\n",
    "| 6. Forced Guess | 10% | No logical deductions available — probability reasoning |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  EXHAUSTIVE DATASET GENERATION\n",
    "#  Fixes: 75% early deaths, no pattern training, 0.7% endgame,\n",
    "#         no forced-guess scenarios, insufficient flag training\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Helper: Smart move selection with progressive flagging\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _smart_reveal(game, rng):\n",
    "    \"\"\"Pick a smart cell to reveal during history generation.\n",
    "    Prefers safe cells (if known) to avoid hitting mines and losing the game.\n",
    "    Falls back to random unrevealed cell.\n",
    "    \"\"\"\n",
    "    safe_set, _ = _compute_safe_and_mine_cells(game)\n",
    "    if safe_set:\n",
    "        return rng.choice(list(safe_set))\n",
    "\n",
    "    # Fallback: random unrevealed, unflagged cell\n",
    "    unrevealed = [(r, c) for r in range(game.rows) for c in range(game.cols)\n",
    "                  if (r, c) not in game._revealed and (r, c) not in game._flagged]\n",
    "    if not unrevealed:\n",
    "        return None\n",
    "    return rng.choice(unrevealed)\n",
    "\n",
    "\n",
    "def _smart_flag(game, rng):\n",
    "    \"\"\"Pick a logically certain mine to flag, or None if none available.\"\"\"\n",
    "    _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "    mine_candidates = [c for c in mine_set if c not in game._flagged]\n",
    "    if mine_candidates:\n",
    "        return rng.choice(mine_candidates)\n",
    "    return None  # Don't flag randomly — creates bad training data\n",
    "\n",
    "\n",
    "def _progressive_flag_probability(game):\n",
    "    \"\"\"Adaptive flagging based on game progress (LAMER-inspired).\n",
    "    - Early game (0-30%):  10% flagging (explore first)\n",
    "    - Mid game (30-70%):   30% flagging (deduce mines)\n",
    "    - Late game (70-100%): 50% flagging (lock in certain mines)\n",
    "    \"\"\"\n",
    "    progress = game.progress()\n",
    "    if progress < 0.30:\n",
    "        return 0.10\n",
    "    elif progress < 0.70:\n",
    "        return 0.30\n",
    "    else:\n",
    "        return 0.50\n",
    "\n",
    "\n",
    "def _play_smart_moves(game, rng, num_moves, use_progressive_flags=True):\n",
    "    \"\"\"Play num_moves smart moves on a game. Returns move_history list.\n",
    "    Uses progressive flagging strategy when enabled.\n",
    "    Returns early if game ends or gets stuck.\n",
    "\n",
    "    Fix #1: Added stuck_count to prevent infinite loops when no valid\n",
    "    moves can be found (e.g., all cells revealed/flagged but game ongoing).\n",
    "    \"\"\"\n",
    "    move_history = []\n",
    "    stuck_count = 0\n",
    "    MAX_STUCK = 10  # Abort after 10 consecutive failed attempts\n",
    "\n",
    "    for _ in range(num_moves):\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "\n",
    "        action_dict = None\n",
    "        flag_prob = _progressive_flag_probability(game) if use_progressive_flags else 0.15\n",
    "\n",
    "        # Try flagging with adaptive probability\n",
    "        if rng.random() < flag_prob:\n",
    "            flag_target = _smart_flag(game, rng)\n",
    "            if flag_target:\n",
    "                action_dict = {\"type\": \"flag\", \"row\": flag_target[0], \"col\": flag_target[1]}\n",
    "\n",
    "        # Fall back to reveal\n",
    "        if action_dict is None:\n",
    "            reveal_target = _smart_reveal(game, rng)\n",
    "            if reveal_target is None:\n",
    "                stuck_count += 1\n",
    "                if stuck_count >= MAX_STUCK:\n",
    "                    break  # Prevent infinite loop\n",
    "                continue\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": reveal_target[0], \"col\": reveal_target[1]}\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            break  # Hit a mine — stop\n",
    "\n",
    "        move_history.append(action_dict)\n",
    "        stuck_count = 0  # Reset on successful move\n",
    "\n",
    "    return move_history\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Scenario generators: endgame, forced-guess, multi-region\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _generate_endgame_state(rows, cols, num_mines, rng, completion_target=0.85):\n",
    "    \"\"\"Generate boards that are 80-98% complete.\n",
    "    Critical for teaching finishing strategy and flag accounting.\n",
    "    Returns (game, move_history) or (None, None) on failure.\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    safe_total = rows * cols - num_mines\n",
    "    if safe_total <= 1:\n",
    "        return None, None, seed\n",
    "\n",
    "    target_revealed = int(safe_total * rng.uniform(completion_target, 0.98))\n",
    "    target_revealed = max(1, min(target_revealed, safe_total - 1))\n",
    "\n",
    "    move_history = []\n",
    "    stuck_count = 0\n",
    "    max_stuck = 20\n",
    "\n",
    "    while len(game._revealed) < target_revealed and game.state() == \"ongoing\":\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        if safe_set:\n",
    "            target = rng.choice(list(safe_set))\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        else:\n",
    "            # No logical moves — reveal a random safe cell (we know the board)\n",
    "            all_safe_unrevealed = [\n",
    "                (r, c) for r in range(rows) for c in range(cols)\n",
    "                if game._board[r][c] != -1\n",
    "                and (r, c) not in game._revealed\n",
    "                and (r, c) not in game._flagged\n",
    "            ]\n",
    "            if not all_safe_unrevealed:\n",
    "                break\n",
    "            target = rng.choice(all_safe_unrevealed)\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "            stuck_count += 1\n",
    "            if stuck_count >= max_stuck:\n",
    "                break\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Optionally add some flags in endgame\n",
    "    if game.state() == \"ongoing\":\n",
    "        _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "        flaggable = [c for c in mine_set if c not in game._flagged]\n",
    "        if flaggable and rng.random() < 0.7:\n",
    "            num_flags = rng.randint(1, min(len(flaggable), 5))\n",
    "            for target in rng.sample(flaggable, num_flags):\n",
    "                action_dict = {\"type\": \"flag\", \"row\": target[0], \"col\": target[1]}\n",
    "                game.do_action(action_dict)\n",
    "                move_history.append(action_dict)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    return game, move_history, seed\n",
    "\n",
    "\n",
    "def _generate_forced_guess_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Generate a board state where no 100% certain logical moves exist.\n",
    "    These teach the model probability-based guessing.\n",
    "    Returns (game, move_history, seed) or (None, None, seed).\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    move_history = []\n",
    "    max_reveal_attempts = rows * cols\n",
    "\n",
    "    for _ in range(max_reveal_attempts):\n",
    "        if game.state() != \"ongoing\":\n",
    "            return None, None, seed\n",
    "\n",
    "        safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "\n",
    "        if not safe_set and not mine_set and len(game._revealed) > 0:\n",
    "            # No logical moves available — this is what we want!\n",
    "            unrevealed_count = sum(\n",
    "                1 for r in range(rows) for c in range(cols)\n",
    "                if (r, c) not in game._revealed and (r, c) not in game._flagged\n",
    "            )\n",
    "            if unrevealed_count >= 2:\n",
    "                return game, move_history, seed\n",
    "\n",
    "        if safe_set:\n",
    "            target = rng.choice(list(safe_set))\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        else:\n",
    "            # Must guess — reveal random safe cell (using board knowledge)\n",
    "            all_safe = [\n",
    "                (r, c) for r in range(rows) for c in range(cols)\n",
    "                if game._board[r][c] != -1\n",
    "                and (r, c) not in game._revealed\n",
    "                and (r, c) not in game._flagged\n",
    "            ]\n",
    "            if not all_safe:\n",
    "                break\n",
    "            target = rng.choice(all_safe)\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Fallback: return whatever state we reached (might still have logical moves)\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "def _generate_multi_region_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Create board with multiple separated revealed regions.\n",
    "    Teaches model to reason across disconnected information.\n",
    "    Returns (game, move_history, seed) or (None, None, seed).\n",
    "    \"\"\"\n",
    "    if rows < 6 or cols < 6:\n",
    "        return None, None, 0  # Need space for multiple regions\n",
    "\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    # Pick 2-4 starting points in different quadrants\n",
    "    quadrant_centers = [\n",
    "        (rows // 4, cols // 4),\n",
    "        (rows // 4, 3 * cols // 4),\n",
    "        (3 * rows // 4, cols // 4),\n",
    "        (3 * rows // 4, 3 * cols // 4),\n",
    "    ]\n",
    "    rng.shuffle(quadrant_centers)\n",
    "    num_regions = rng.randint(2, min(4, len(quadrant_centers)))\n",
    "    selected = quadrant_centers[:num_regions]\n",
    "\n",
    "    move_history = []\n",
    "    for r, c in selected:\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "        r = max(0, min(r, rows - 1))\n",
    "        c = max(0, min(c, cols - 1))\n",
    "\n",
    "        if (r, c) not in game._revealed and game._board[r][c] != -1:\n",
    "            action_dict = {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "            result = game.do_action(action_dict)\n",
    "            if result == \"mine\":\n",
    "                return None, None, seed\n",
    "            move_history.append(action_dict)\n",
    "\n",
    "        # Reveal a few logical neighbors around this region\n",
    "        for _ in range(rng.randint(1, 3)):\n",
    "            if game.state() != \"ongoing\":\n",
    "                break\n",
    "            safe_set, _ = _compute_safe_and_mine_cells(game)\n",
    "            if safe_set:\n",
    "                # Prefer safe cells near this region\n",
    "                nearby = [\n",
    "                    (sr, sc) for sr, sc in safe_set\n",
    "                    if abs(sr - r) <= rows // 3 and abs(sc - c) <= cols // 3\n",
    "                ]\n",
    "                target = rng.choice(nearby) if nearby else rng.choice(list(safe_set))\n",
    "                action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "                result = game.do_action(action_dict)\n",
    "                if result == \"mine\":\n",
    "                    return None, None, seed\n",
    "                move_history.append(action_dict)\n",
    "\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "def _generate_satisfied_numbers_state(rows, cols, num_mines, rng):\n",
    "    \"\"\"Generate board with multiple satisfied numbers (easy deductions available).\n",
    "    Satisfied number = number whose count of adjacent flags equals its value.\n",
    "    All remaining unrevealed neighbors of a satisfied number are safe.\n",
    "    Teaches basic constraint satisfaction.\n",
    "    Returns (game, move_history, seed).\n",
    "    \"\"\"\n",
    "    seed = rng.randint(0, 999999)\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "    if game.state() != \"ongoing\":\n",
    "        return None, None, seed\n",
    "\n",
    "    move_history = []\n",
    "\n",
    "    # Reveal some cells first\n",
    "    num_initial = rng.randint(3, max(3, min(15, rows * cols // 4)))\n",
    "    for _ in range(num_initial):\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "        target = _smart_reveal(game, rng)\n",
    "        if target is None:\n",
    "            break\n",
    "        action_dict = {\"type\": \"reveal\", \"row\": target[0], \"col\": target[1]}\n",
    "        result = game.do_action(action_dict)\n",
    "        if result == \"mine\":\n",
    "            return None, None, seed\n",
    "        move_history.append(action_dict)\n",
    "\n",
    "    # Now flag logically certain mines to create satisfied numbers\n",
    "    if game.state() == \"ongoing\":\n",
    "        for _ in range(5):\n",
    "            _, mine_set = _compute_safe_and_mine_cells(game)\n",
    "            flaggable = [c for c in mine_set if c not in game._flagged]\n",
    "            if not flaggable:\n",
    "                break\n",
    "            target = rng.choice(flaggable)\n",
    "            action_dict = {\"type\": \"flag\", \"row\": target[0], \"col\": target[1]}\n",
    "            game.do_action(action_dict)\n",
    "            move_history.append(action_dict)\n",
    "\n",
    "    if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "        return game, move_history, seed\n",
    "    return None, None, seed\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Density-stratified board sampling\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "DENSITY_TARGETS = [\n",
    "    # (density_range, weight, label)\n",
    "    ((0.00, 0.00), 0.08, \"Zero mines\"),       # 8%  - trivial edge case\n",
    "    ((0.01, 0.05), 0.17, \"Very sparse\"),       # 17%\n",
    "    ((0.05, 0.10), 0.25, \"Sparse\"),            # 25%\n",
    "    ((0.10, 0.15), 0.25, \"Medium\"),            # 25%\n",
    "    ((0.15, 0.20), 0.25, \"Dense/Max\"),         # 25%\n",
    "]\n",
    "\n",
    "\n",
    "def _sample_board_with_density(rng, target_density_range=None):\n",
    "    \"\"\"Sample board config with explicit density control.\n",
    "    If target_density_range is None, picks one from DENSITY_TARGETS.\n",
    "    \"\"\"\n",
    "    if target_density_range is None:\n",
    "        # Weighted random density band\n",
    "        weights = [w for _, w, _ in DENSITY_TARGETS]\n",
    "        ranges = [r for r, _, _ in DENSITY_TARGETS]\n",
    "        idx = rng.choices(range(len(DENSITY_TARGETS)), weights=weights, k=1)[0]\n",
    "        target_density_range = ranges[idx]\n",
    "\n",
    "    # Sample board size — boosted large-board representation for 50×50 support\n",
    "    size_band = rng.random()\n",
    "    if size_band < 0.25:\n",
    "        rows, cols = rng.randint(1, 8), rng.randint(1, 8)      # 25% tiny\n",
    "    elif size_band < 0.45:\n",
    "        rows, cols = rng.randint(5, 15), rng.randint(5, 15)    # 20% small\n",
    "    elif size_band < 0.65:\n",
    "        rows, cols = rng.randint(10, 30), rng.randint(10, 30)  # 20% medium\n",
    "    elif size_band < 0.85:\n",
    "        rows, cols = rng.randint(20, 40), rng.randint(20, 40)  # 20% large\n",
    "    else:\n",
    "        rows, cols = rng.randint(30, 50), rng.randint(30, 50)  # 15% XL (30-50)\n",
    "\n",
    "    total = rows * cols\n",
    "    min_d, max_d = target_density_range\n",
    "\n",
    "    if min_d == 0.0 and max_d == 0.0:\n",
    "        return rows, cols, 0\n",
    "\n",
    "    min_mines = max(0, int(math.ceil(total * min_d)))\n",
    "    max_mines = min(int(total * max_d), int(total * MAX_MINE_DENSITY), total - 1)\n",
    "\n",
    "    if max_mines < min_mines:\n",
    "        num_mines = max(0, min(min_mines, total - 1))\n",
    "    else:\n",
    "        num_mines = rng.randint(min_mines, max_mines)\n",
    "\n",
    "    return rows, cols, num_mines\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Exhaustive edge-case configs (50+ scenarios)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "EDGE_CASE_CONFIGS = [\n",
    "    # (rows, cols, mines, label)\n",
    "\n",
    "    # === TRIVIAL BOARDS ===\n",
    "    (1, 1, 0,   \"1x1 trivial\"),\n",
    "    (2, 2, 0,   \"2x2 no mines\"),\n",
    "    (3, 3, 0,   \"3x3 no mines\"),\n",
    "    (4, 4, 0,   \"4x4 no mines\"),\n",
    "    (5, 5, 0,   \"5x5 no mines - cascade practice\"),\n",
    "\n",
    "    # === LINEAR BOARDS (1D Minesweeper) ===\n",
    "    (1, 5, 1,   \"1x5 single mine\"),\n",
    "    (1, 10, 2,  \"1x10 two mines\"),\n",
    "    (1, 20, 4,  \"1x20 row\"),\n",
    "    (1, 50, 10, \"1x50 maximum row\"),\n",
    "    (5, 1, 1,   \"5x1 column\"),\n",
    "    (10, 1, 2,  \"10x1 column\"),\n",
    "    (20, 1, 4,  \"20x1 column\"),\n",
    "    (50, 1, 10, \"50x1 maximum column\"),\n",
    "\n",
    "    # === TINY BOARDS ===\n",
    "    (1, 2, 0,   \"1x2 trivial\"),\n",
    "    (2, 1, 0,   \"2x1 trivial\"),\n",
    "    (2, 2, 1,   \"2x2 single mine\"),\n",
    "    (2, 3, 1,   \"2x3 mini\"),\n",
    "    (3, 2, 1,   \"3x2 mini\"),\n",
    "    (3, 3, 1,   \"3x3 single mine\"),\n",
    "    (3, 3, 2,   \"3x3 two mines\"),\n",
    "    (4, 4, 3,   \"4x4 medium density\"),\n",
    "\n",
    "    # === EXTREME RECTANGULAR ===\n",
    "    (2, 50, 20, \"2x50 ultra-wide\"),\n",
    "    (50, 2, 20, \"50x2 ultra-tall\"),\n",
    "    (3, 40, 24, \"3x40 extreme ratio\"),\n",
    "    (40, 3, 24, \"40x3 extreme ratio\"),\n",
    "    (5, 50, 50, \"5x50 max density wide\"),\n",
    "    (50, 5, 50, \"50x5 max density tall\"),\n",
    "\n",
    "    # === CLASSIC MINESWEEPER SIZES ===\n",
    "    (8, 8, 1,   \"8x8 very sparse\"),\n",
    "    (8, 8, 5,   \"8x8 sparse\"),\n",
    "    (8, 8, 10,  \"8x8 medium - classic beginner\"),\n",
    "    (8, 8, 13,  \"8x8 max density\"),\n",
    "    (16, 16, 10, \"16x16 sparse\"),\n",
    "    (16, 16, 40, \"16x16 medium - classic intermediate\"),\n",
    "    (16, 16, 51, \"16x16 max density\"),\n",
    "    (16, 30, 20, \"16x30 rectangular sparse\"),\n",
    "    (16, 30, 96, \"16x30 rectangular dense - classic expert\"),\n",
    "\n",
    "    # === LARGE BOARDS ===\n",
    "    (20, 20, 10, \"20x20 very sparse\"),\n",
    "    (20, 20, 80, \"20x20 max density\"),\n",
    "    (25, 25, 30, \"25x25 sparse\"),\n",
    "    (25, 25, 125, \"25x25 max density\"),\n",
    "    (30, 30, 50, \"30x30 sparse\"),\n",
    "    (30, 30, 180, \"30x30 max density\"),\n",
    "    (40, 40, 100, \"40x40 sparse\"),\n",
    "    (40, 40, 320, \"40x40 max density\"),\n",
    "\n",
    "    # === MAXIMUM SIZE ===\n",
    "    (50, 50, 10,  \"50x50 ultra-sparse\"),\n",
    "    (50, 50, 100, \"50x50 sparse\"),\n",
    "    (50, 50, 250, \"50x50 medium\"),\n",
    "    (50, 50, 500, \"50x50 maximum density\"),\n",
    "\n",
    "    # === DENSITY EDGE CASES ===\n",
    "    (10, 10, 0,  \"10x10 no mines\"),\n",
    "    (15, 15, 0,  \"15x15 no mines - large trivial\"),\n",
    "    (20, 20, 0,  \"20x20 no mines - huge trivial\"),\n",
    "    (10, 10, 1,  \"10x10 single mine\"),\n",
    "    (20, 20, 1,  \"20x20 single mine in large board\"),\n",
    "\n",
    "    # === MORE RECTANGULAR VARIETY ===\n",
    "    (3, 50, 30,  \"3x50 wide\"),\n",
    "    (50, 3, 30,  \"50x3 tall\"),\n",
    "    (5, 15, 15,  \"5x15 wide rect\"),\n",
    "    (15, 5, 15,  \"15x5 tall rect\"),\n",
    "    (6, 8, 6,    \"6x8 rect\"),\n",
    "    (8, 6, 6,    \"8x6 rect\"),\n",
    "    (7, 13, 18,  \"7x13 odd rect\"),\n",
    "    (13, 7, 18,  \"13x7 odd rect\"),\n",
    "    (15, 30, 90, \"15x30 wide large\"),\n",
    "]\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Dataset item builder (DRY helper)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a Minesweeper AI. Output ONLY valid JSON. No explanations, no reasoning, just {\\\"type\\\":\\\"reveal\\\",\\\"row\\\":N,\\\"col\\\":N}.\"\n",
    "\n",
    "def _build_dataset_item(game, seed, move_history):\n",
    "    \"\"\"Build a single dataset item dict from a game state.\"\"\"\n",
    "    prompt_text = format_state_for_llm(game)\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_text}\n",
    "        ],\n",
    "        \"seed\": seed,\n",
    "        \"move_history\": json.dumps(move_history),\n",
    "        \"board_rows\": game.rows,\n",
    "        \"board_cols\": game.cols,\n",
    "        \"board_mines\": game.num_mines,\n",
    "    }\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  MAIN GENERATOR — 6-Phase Exhaustive Composition\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def generate_exhaustive_dataset(num_samples=4000, rng_seed=42):\n",
    "    \"\"\"\n",
    "    Comprehensive Minesweeper training dataset covering ALL scenarios.\n",
    "\n",
    "    6-Phase composition:\n",
    "      Phase 1: Edge cases           — 10%  (50+ explicit configs)\n",
    "      Phase 2: Opening-heavy        — 25%  (fresh + single-move boards)\n",
    "      Phase 3: Pattern-specific     — 15%  (satisfied numbers, multi-region)\n",
    "      Phase 4: Mid-game deduction   — 25%  (core logical reasoning)\n",
    "      Phase 5: Endgame completion   — 15%  (80-98% revealed, flag accounting)\n",
    "      Phase 6: Forced guess         — 10%  (no logical moves available)\n",
    "\n",
    "    Improvements over previous version:\n",
    "      ✅ 50+ edge case configs (was 25)\n",
    "      ✅ Progressive flagging 10%→30%→50% by game phase (was flat 15%)\n",
    "      ✅ Density-stratified board sampling\n",
    "      ✅ Dedicated endgame generator (was 0.7% late-game)\n",
    "      ✅ Forced-guess scenario training (was 0%)\n",
    "      ✅ Multi-region disconnected boards (was 0%)\n",
    "      ✅ Satisfied-number pattern training (was 0%)\n",
    "      ✅ 4000 samples (was 3000)\n",
    "    \"\"\"\n",
    "    rng = random.Random(rng_seed)\n",
    "    np.random.seed(rng_seed)\n",
    "\n",
    "    dataset_items = []\n",
    "    phase_counts = {\n",
    "        \"edge_case\": 0, \"opening\": 0, \"pattern\": 0,\n",
    "        \"midgame\": 0, \"endgame\": 0, \"forced_guess\": 0,\n",
    "    }\n",
    "    config_counts = {}\n",
    "    density_counts = {\"zero\": 0, \"very_sparse\": 0, \"sparse\": 0, \"medium\": 0, \"dense\": 0}\n",
    "\n",
    "    def _track_config(game):\n",
    "        key = f\"{game.rows}x{game.cols}m{game.num_mines}\"\n",
    "        config_counts[key] = config_counts.get(key, 0) + 1\n",
    "        d = game.num_mines / (game.rows * game.cols) if game.rows * game.cols > 0 else 0\n",
    "        if d == 0:\n",
    "            density_counts[\"zero\"] += 1\n",
    "        elif d <= 0.05:\n",
    "            density_counts[\"very_sparse\"] += 1\n",
    "        elif d <= 0.10:\n",
    "            density_counts[\"sparse\"] += 1\n",
    "        elif d <= 0.15:\n",
    "            density_counts[\"medium\"] += 1\n",
    "        else:\n",
    "            density_counts[\"dense\"] += 1\n",
    "\n",
    "    # Budget per phase\n",
    "    n_edge     = int(num_samples * 0.10)\n",
    "    n_opening  = int(num_samples * 0.25)\n",
    "    n_pattern  = int(num_samples * 0.15)\n",
    "    n_midgame  = int(num_samples * 0.25)\n",
    "    n_endgame  = int(num_samples * 0.15)\n",
    "    n_forced   = num_samples - n_edge - n_opening - n_pattern - n_midgame - n_endgame\n",
    "\n",
    "    print(f\"  Phase budgets: edge={n_edge}, opening={n_opening}, pattern={n_pattern}, \"\n",
    "          f\"midgame={n_midgame}, endgame={n_endgame}, forced={n_forced}\")\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 1: Edge Cases (10%) — 50+ explicit configs\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 1: Edge cases...\")\n",
    "    edge_generated = 0\n",
    "    edge_idx = 0\n",
    "    while edge_generated < n_edge:\n",
    "        ec_rows, ec_cols, ec_mines, ec_label = EDGE_CASE_CONFIGS[edge_idx % len(EDGE_CASE_CONFIGS)]\n",
    "        edge_idx += 1\n",
    "        seed = rng.randint(0, 999999)\n",
    "\n",
    "        game = MinesweeperGame(rows=ec_rows, cols=ec_cols, num_mines=ec_mines, seed=seed)\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        # 0-3 moves for variety\n",
    "        num_moves = rng.randint(0, min(3, max(0, ec_rows * ec_cols - ec_mines - 1)))\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=True)\n",
    "\n",
    "        if game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"edge_case\"] += 1\n",
    "            edge_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 2: Opening-Heavy Training (25%) — Fix 75% early death rate\n",
    "    # 75% fresh (0 moves), 25% single-move\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 2: Opening training...\")\n",
    "    opening_generated = 0\n",
    "    opening_attempts = 0\n",
    "    while opening_generated < n_opening and opening_attempts < n_opening * 5:\n",
    "        opening_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng)\n",
    "\n",
    "        seed = rng.randint(0, 999999)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "        if num_mines == 0:\n",
    "            if game.state() == \"ongoing\":\n",
    "                dataset_items.append(_build_dataset_item(game, seed, []))\n",
    "                _track_config(game)\n",
    "                phase_counts[\"opening\"] += 1\n",
    "                opening_generated += 1\n",
    "            continue\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        # 75% fresh boards, 25% single-move\n",
    "        num_moves = 0 if rng.random() < 0.75 else 1\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=False)\n",
    "\n",
    "        if game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"opening\"] += 1\n",
    "            opening_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 3: Pattern-Specific Scenarios (15%)\n",
    "    # Mix of: satisfied-number boards (60%), multi-region boards (40%)\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 3: Pattern-specific scenarios...\")\n",
    "    pattern_generated = 0\n",
    "    pattern_attempts = 0\n",
    "    while pattern_generated < n_pattern and pattern_attempts < n_pattern * 10:\n",
    "        pattern_attempts += 1\n",
    "\n",
    "        # 60% satisfied numbers, 40% multi-region\n",
    "        if rng.random() < 0.60:\n",
    "            # Satisfied numbers — need boards with mines\n",
    "            rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.20))\n",
    "            if rows < 3 or cols < 3:\n",
    "                continue\n",
    "            game, move_history, seed = _generate_satisfied_numbers_state(\n",
    "                rows, cols, num_mines, rng\n",
    "            )\n",
    "        else:\n",
    "            # Multi-region — need larger boards\n",
    "            rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.15))\n",
    "            rows = max(rows, 8)\n",
    "            cols = max(cols, 8)\n",
    "            num_mines = min(num_mines, int(rows * cols * 0.15))\n",
    "            if num_mines < 1:\n",
    "                num_mines = max(1, int(rows * cols * 0.05))\n",
    "            game, move_history, seed = _generate_multi_region_state(\n",
    "                rows, cols, num_mines, rng\n",
    "            )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"pattern\"] += 1\n",
    "            pattern_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 4: Mid-Game Logical Deduction (25%) — Core gameplay\n",
    "    # 3-15 moves played, progressive flagging, density-stratified\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 4: Mid-game deduction...\")\n",
    "    midgame_generated = 0\n",
    "    midgame_attempts = 0\n",
    "    while midgame_generated < n_midgame and midgame_attempts < n_midgame * 5:\n",
    "        midgame_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng)\n",
    "\n",
    "        if num_mines == 0:\n",
    "            continue  # Skip zero-mine for midgame\n",
    "\n",
    "        seed = rng.randint(0, 999999)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "        if game.state() != \"ongoing\":\n",
    "            continue\n",
    "\n",
    "        total_safe = rows * cols - num_mines\n",
    "        max_moves = min(15, max(3, total_safe - 1))\n",
    "        num_moves = rng.randint(3, max_moves)\n",
    "\n",
    "        move_history = _play_smart_moves(game, rng, num_moves, use_progressive_flags=True)\n",
    "\n",
    "        if game.state() == \"ongoing\" and len(game._revealed) > 0:\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"midgame\"] += 1\n",
    "            midgame_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 5: Endgame Completion (15%) — 80-98% revealed\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 5: Endgame completion...\")\n",
    "    endgame_generated = 0\n",
    "    endgame_attempts = 0\n",
    "    while endgame_generated < n_endgame and endgame_attempts < n_endgame * 10:\n",
    "        endgame_attempts += 1\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng, (0.05, 0.20))\n",
    "\n",
    "        if num_mines < 1 or rows * cols < 8:\n",
    "            continue\n",
    "\n",
    "        completion = rng.uniform(0.80, 0.95)\n",
    "        game, move_history, seed = _generate_endgame_state(\n",
    "            rows, cols, num_mines, rng, completion_target=completion\n",
    "        )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"endgame\"] += 1\n",
    "            endgame_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # PHASE 6: Forced Guess Scenarios (10%) — No logical deductions\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    print(\"  Phase 6: Forced guess scenarios...\")\n",
    "    forced_generated = 0\n",
    "    forced_attempts = 0\n",
    "    while forced_generated < n_forced and forced_attempts < n_forced * 15:\n",
    "        forced_attempts += 1\n",
    "        # Dense boards more likely to produce forced-guess states\n",
    "        rows, cols, num_mines = _sample_board_with_density(rng, (0.10, 0.20))\n",
    "\n",
    "        if num_mines < 2 or rows * cols < 6:\n",
    "            continue\n",
    "\n",
    "        game, move_history, seed = _generate_forced_guess_state(\n",
    "            rows, cols, num_mines, rng\n",
    "        )\n",
    "\n",
    "        if game is not None and game.state() == \"ongoing\":\n",
    "            dataset_items.append(_build_dataset_item(game, seed, move_history))\n",
    "            _track_config(game)\n",
    "            phase_counts[\"forced_guess\"] += 1\n",
    "            forced_generated += 1\n",
    "\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    # Shuffle and trim\n",
    "    # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "    rng.shuffle(dataset_items)\n",
    "    dataset_items = dataset_items[:num_samples]\n",
    "    ds = Dataset.from_list(dataset_items)\n",
    "\n",
    "    return ds, config_counts, phase_counts, density_counts\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "#  Generate & Analyze\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  EXHAUSTIVE DATASET GENERATION\")\n",
    "print(\"  4000 samples | 6 phases | 50+ edge cases | density-stratified\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "dataset, config_counts, phase_counts, density_counts = generate_exhaustive_dataset(\n",
    "    num_samples=4000, rng_seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(f\"Created {len(dataset)} training examples\\n\")\n",
    "\n",
    "# Phase distribution\n",
    "print(\"Phase distribution:\")\n",
    "for phase, count in phase_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {phase:14s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Density distribution\n",
    "print(f\"\\nDensity distribution:\")\n",
    "for band, count in density_counts.items():\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {band:14s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Board size distribution (top 20)\n",
    "print(f\"\\nBoard size distribution (top 20):\")\n",
    "sorted_configs = sorted(config_counts.items(), key=lambda x: -x[1])\n",
    "for config, count in sorted_configs[:20]:\n",
    "    pct = count / len(dataset) * 100 if len(dataset) > 0 else 0\n",
    "    print(f\"  {config:16s}: {count:4d} ({pct:.1f}%)\")\n",
    "if len(sorted_configs) > 20:\n",
    "    print(f\"  ... and {len(sorted_configs) - 20} more unique configs\")\n",
    "print(f\"\\nTotal unique board configs: {len(config_counts)}\")\n",
    "\n",
    "# Board size statistics\n",
    "all_rows = [item[\"board_rows\"] for item in dataset]\n",
    "all_cols = [item[\"board_cols\"] for item in dataset]\n",
    "all_mines = [item[\"board_mines\"] for item in dataset]\n",
    "print(f\"\\nBoard size statistics:\")\n",
    "print(f\"  Rows:  min={min(all_rows)}, max={max(all_rows)}, mean={np.mean(all_rows):.1f}\")\n",
    "print(f\"  Cols:  min={min(all_cols)}, max={max(all_cols)}, mean={np.mean(all_cols):.1f}\")\n",
    "print(f\"  Mines: min={min(all_mines)}, max={max(all_mines)}, mean={np.mean(all_mines):.1f}\")\n",
    "densities = [m / (r * c) * 100 for r, c, m in zip(all_rows, all_cols, all_mines) if r * c > 0]\n",
    "print(f\"  Density: min={min(densities):.1f}%, max={max(densities):.1f}%, mean={np.mean(densities):.1f}%\")\n",
    "\n",
    "zero_mine_count = sum(1 for m in all_mines if m == 0)\n",
    "print(f\"  Zero-mine boards: {zero_mine_count} ({zero_mine_count/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "move_counts = [len(json.loads(item[\"move_history\"])) for item in dataset]\n",
    "print(f\"\\nMove statistics:\")\n",
    "print(f\"  Min: {min(move_counts)}, Max: {max(move_counts)}, \"\n",
    "      f\"Mean: {np.mean(move_counts):.1f}, Median: {np.median(move_counts):.1f}\")\n",
    "\n",
    "# Phase-specific move stats\n",
    "print(f\"\\nLogical deduction coverage:\")\n",
    "has_safe = 0\n",
    "has_mine = 0\n",
    "has_both = 0\n",
    "for item in dataset:\n",
    "    mh = json.loads(item[\"move_history\"])\n",
    "    has_flag = any(m.get(\"type\") == \"flag\" for m in mh)\n",
    "    has_rev = any(m.get(\"type\") == \"reveal\" for m in mh)\n",
    "    if has_flag:\n",
    "        has_mine += 1\n",
    "    if has_rev:\n",
    "        has_safe += 1\n",
    "    if has_flag and has_rev:\n",
    "        has_both += 1\n",
    "print(f\"  Samples with reveals: {has_safe} ({has_safe/len(dataset)*100:.1f}%)\")\n",
    "print(f\"  Samples with flags:   {has_mine} ({has_mine/len(dataset)*100:.1f}%)\")\n",
    "print(f\"  Samples with both:    {has_both} ({has_both/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "# Verify dataset columns\n",
    "print(f\"\\nDataset columns: {dataset.column_names}\")\n",
    "print(f\"  ✅ board_rows, board_cols, board_mines present for reward functions\")\n",
    "\n",
    "# ── Save dataset to JSON ──\n",
    "dataset_json_path = \"minesweeper_dataset.json\"\n",
    "\n",
    "json_records = []\n",
    "for item in dataset:\n",
    "    record = {\n",
    "        \"prompt_text\": item[\"prompt\"][-1][\"content\"],  # Last message is user content\n",
    "        \"move_history\": item[\"move_history\"],\n",
    "        \"board_rows\": item[\"board_rows\"],\n",
    "        \"board_cols\": item[\"board_cols\"],\n",
    "        \"board_mines\": item[\"board_mines\"],\n",
    "        \"prompt_text\": item[\"prompt\"][0][\"content\"],\n",
    "    }\n",
    "    json_records.append(record)\n",
    "\n",
    "with open(dataset_json_path, \"w\") as f:\n",
    "    json.dump(json_records, f, indent=2)\n",
    "\n",
    "print(dataset[0][\"prompt\"][-1][\"content\"][:300] + \"...\")\n",
    "\n",
    "print(f\"   {len(json_records)} records with fields: seed, move_history, board_rows/cols/mines, prompt_text\")print(dataset[0][\"prompt\"][0][\"content\"][:300] + \"...\")\n",
    "\n",
    "      f\"{dataset[0]['board_mines']} mines):\")\n",
    "print(f\"\\nSample prompt ({dataset[0]['board_rows']}x{dataset[0]['board_cols']}, \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e4491",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Configure GRPO Training\n",
    "\n",
    "Set up GRPO trainer with all hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478959ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# CHECKPOINT MANAGEMENT SYSTEM\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# - Saves checkpoints every 100 steps\n",
    "# - Tracks latest checkpoint in a JSON file\n",
    "# - Automatically resumes from last checkpoint\n",
    "# - Preserves all checkpoints for hackathon submission\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "CHECKPOINT_DIR = \"minesweeper_checkpoints\"\n",
    "CHECKPOINT_TRACKER = os.path.join(CHECKPOINT_DIR, \"checkpoint_tracker.json\")\n",
    "\n",
    "def get_checkpoint_tracker():\n",
    "    \"\"\"Load or create checkpoint tracker.\"\"\"\n",
    "    if os.path.exists(CHECKPOINT_TRACKER):\n",
    "        with open(CHECKPOINT_TRACKER, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {\n",
    "        \"latest_checkpoint\": None,\n",
    "        \"latest_step\": 0,\n",
    "        \"total_steps_trained\": 0,\n",
    "        \"checkpoints\": [],\n",
    "        \"training_sessions\": []\n",
    "    }\n",
    "\n",
    "def save_checkpoint_tracker(tracker):\n",
    "    \"\"\"Save checkpoint tracker.\"\"\"\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    with open(CHECKPOINT_TRACKER, 'w') as f:\n",
    "        json.dump(tracker, f, indent=2)\n",
    "\n",
    "def find_latest_checkpoint():\n",
    "    \"\"\"Find the latest checkpoint directory.\"\"\"\n",
    "    tracker = get_checkpoint_tracker()\n",
    "    \n",
    "    # First check tracker\n",
    "    if tracker[\"latest_checkpoint\"] and os.path.exists(tracker[\"latest_checkpoint\"]):\n",
    "        return tracker[\"latest_checkpoint\"], tracker[\"latest_step\"]\n",
    "    \n",
    "    # Fallback: scan checkpoint directories\n",
    "    checkpoint_dirs = glob(os.path.join(CHECKPOINT_DIR, \"checkpoint-*\"))\n",
    "    if not checkpoint_dirs:\n",
    "        return None, 0\n",
    "    \n",
    "    # Sort by step number\n",
    "    def get_step(path):\n",
    "        try:\n",
    "            return int(os.path.basename(path).split(\"-\")[1])\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    checkpoint_dirs.sort(key=get_step, reverse=True)\n",
    "    latest = checkpoint_dirs[0]\n",
    "    step = get_step(latest)\n",
    "    \n",
    "    return latest, step\n",
    "\n",
    "# Check for existing checkpoint\n",
    "latest_checkpoint, resume_step = find_latest_checkpoint()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHECKPOINT MANAGEMENT SYSTEM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if latest_checkpoint:\n",
    "    print(f\"✅ Found existing checkpoint: {latest_checkpoint}\")\n",
    "    print(f\"   Will resume from step: {resume_step}\")\n",
    "    RESUME_FROM_CHECKPOINT = latest_checkpoint\n",
    "else:\n",
    "    print(\"📝 No existing checkpoint found. Starting fresh training.\")\n",
    "    RESUME_FROM_CHECKPOINT = None\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# TRAINING CONFIG — With checkpoint saving every 100 steps\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "max_prompt_length = 800\n",
    "max_completion_length = 96  # Increased from 64 — model needs buffer\n",
    "\n",
    "# Target total steps (can increase this and resume to train more)\n",
    "TARGET_TOTAL_STEPS = 2000  # Increase this as needed before hackathon\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    # === Generation ===\n",
    "    temperature = 0.7,  # FIXED: match eval temperature exactly\n",
    "    top_p = 0.9,\n",
    "\n",
    "    # === Optimization ===\n",
    "    learning_rate = 5e-6,  # Reduced from 1e-5 for stability\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.03,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    max_grad_norm = 1.0,\n",
    "\n",
    "    # === Batch sizes ===\n",
    "    logging_steps = 10,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_generations = 8,\n",
    "\n",
    "    # === Lengths ===\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_completion_length,  # Now 96\n",
    "\n",
    "    # === Training duration ===\n",
    "    max_steps = TARGET_TOTAL_STEPS,\n",
    "    \n",
    "    # === CHECKPOINT SAVING ===\n",
    "    save_steps = 100,                    # Save every 100 steps\n",
    "    save_total_limit = None,             # Keep ALL checkpoints (no limit)\n",
    "    output_dir = CHECKPOINT_DIR,         # Save to checkpoint directory\n",
    "    save_strategy = \"steps\",\n",
    "    \n",
    "    # === GRPO specific ===\n",
    "    beta = 0.02,\n",
    "    num_iterations = 2,\n",
    "\n",
    "    # === Reward weighting ===\n",
    "    # Rebalanced: gameplay dominates, format important, strategic bonus\n",
    "    reward_weights = [0.35, 0.50, 0.15],  # [format, gameplay, strategic]\n",
    "\n",
    "    # === Other ===\n",
    "    remove_unused_columns = False,\n",
    "    report_to = \"none\",\n",
    "    seed = 42,\n",
    "    bf16 = True,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"TRAINING CONFIGURATION:\")\n",
    "print(f\"  Target total steps:    {TARGET_TOTAL_STEPS}\")\n",
    "print(f\"  Resume from step:      {resume_step if RESUME_FROM_CHECKPOINT else 0}\")\n",
    "print(f\"  Remaining steps:       {TARGET_TOTAL_STEPS - resume_step}\")\n",
    "print(f\"  Save checkpoint every: {training_args.save_steps} steps\")\n",
    "print(f\"  Checkpoint directory:  {CHECKPOINT_DIR}/\")\n",
    "print(f\"  Keep all checkpoints:  Yes (save_total_limit=None)\")\n",
    "print()\n",
    "print(\"To train more steps before hackathon:\")\n",
    "print(\"  1. Increase TARGET_TOTAL_STEPS above\")\n",
    "print(\"  2. Re-run this cell and the training cell\")\n",
    "print(\"  3. Training will resume from the latest checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c88f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "#  VERIFICATION: System prompt is in EVERY dataset item\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "print(f\"Dataset size: {len(dataset)} items\")\n",
    "print(f\"SYSTEM_PROMPT: {SYSTEM_PROMPT!r}\\n\")\n",
    "\n",
    "# Check first 3 items\n",
    "for i in range(min(3, len(dataset))):\n",
    "    item = dataset[i]\n",
    "    prompt_messages = item[\"prompt\"]\n",
    "    has_system = any(\n",
    "        msg.get(\"role\") == \"system\" and SYSTEM_PROMPT in msg.get(\"content\", \"\")\n",
    "        for msg in prompt_messages\n",
    "    )\n",
    "    print(f\"  Item {i}: {len(prompt_messages)} messages | \"\n",
    "          f\"system_prompt={'✅' if has_system else '❌ MISSING'} | \"\n",
    "          f\"roles={[m['role'] for m in prompt_messages]}\")\n",
    "\n",
    "# Spot-check ALL items\n",
    "missing = [i for i in range(len(dataset))\n",
    "           if not any(m.get(\"role\") == \"system\" for m in dataset[i][\"prompt\"])]\n",
    "if missing:\n",
    "    print(f\"\\n❌ CRITICAL: {len(missing)} items MISSING system prompt: {missing[:10]}...\")\n",
    "else:\n",
    "    print(f\"\\n✅ All {len(dataset)} items have system prompt\")\n",
    "\n",
    "# Verify tokenized form includes system prompt text\n",
    "sample_text = tokenizer.apply_chat_template(\n",
    "    dataset[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "assert SYSTEM_PROMPT in sample_text, \"❌ System prompt NOT in tokenized text!\"\n",
    "print(f\"✅ System prompt present in tokenized chat template\")\n",
    "print(f\"   Tokenized length (chars): {len(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "# Board configs to evaluate on during training\n",
    "EVAL_CONFIGS = [\n",
    "    (1, 1, 0),     # Trivial — 0 mines  (was failing!)\n",
    "    (3, 3, 1),     # Tiny\n",
    "    (5, 5, 0),     # Zero mines (was failing!)\n",
    "    (5, 5, 3),     # Small\n",
    "    (6, 6, 5),     # Standard\n",
    "    (8, 8, 10),    # Medium\n",
    "    (10, 10, 20),  # Large\n",
    "    (15, 15, 45),  # XL\n",
    "    (1, 10, 2),    # Row board\n",
    "    (20, 20, 80),  # XX-Large\n",
    "]\n",
    "\n",
    "\n",
    "class MinesweeperEvalCallback(TrainerCallback):\n",
    "    \"\"\"Periodically play games during training.\n",
    "    \n",
    "    Tracks:\n",
    "    - Win rate (games won / total)\n",
    "    - Invalid count (parse failures + invalid moves)\n",
    "    - Output length (to verify brevity is learned)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eval_every_steps=50, num_games=10):\n",
    "        self.eval_every_steps = eval_every_steps\n",
    "        self.num_games = min(num_games, len(EVAL_CONFIGS))\n",
    "\n",
    "    def on_step_end(self, args, state, control, model=None, processing_class=None, **kwargs):\n",
    "        if state.global_step % self.eval_every_steps != 0:\n",
    "            return\n",
    "\n",
    "        tokenizer = processing_class\n",
    "        if tokenizer is None or model is None:\n",
    "            return\n",
    "\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "\n",
    "        wins = 0\n",
    "        total_moves = 0\n",
    "        invalid_count = 0\n",
    "        total_response_len = 0\n",
    "        response_count = 0\n",
    "\n",
    "        for i in range(self.num_games):\n",
    "            rows, cols, mines = EVAL_CONFIGS[i % len(EVAL_CONFIGS)]\n",
    "            game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines,\n",
    "                                   seed=10000 + i)\n",
    "            moves = 0\n",
    "            invalids = 0\n",
    "            consecutive_invalids = 0\n",
    "            seen_actions = set()\n",
    "            repeat_count = 0\n",
    "            max_iterations = min(200, rows * cols + 50)\n",
    "\n",
    "            iteration = 0\n",
    "            while game.state() == \"ongoing\" and iteration < max_iterations:\n",
    "                iteration += 1\n",
    "                prompt = format_state_for_llm(game)\n",
    "                text = tokenizer.apply_chat_template(\n",
    "                    [\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True,\n",
    "                )\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                                   max_length=max_prompt_length + 100)\n",
    "                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model.generate(\n",
    "                        **inputs,\n",
    "                        temperature=0.7,\n",
    "                        max_new_tokens=96,  # Increased from 64 — match training\n",
    "                        do_sample=True,\n",
    "                        top_p=0.9,\n",
    "                    )\n",
    "\n",
    "                gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "                response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "                \n",
    "                # Track response length\n",
    "                total_response_len += len(response)\n",
    "                response_count += 1\n",
    "                \n",
    "                action = parse_llm_action(response)\n",
    "\n",
    "                if action is None:\n",
    "                    invalids += 1\n",
    "                    consecutive_invalids += 1\n",
    "                    if consecutive_invalids >= 5:\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "                consecutive_invalids = 0\n",
    "\n",
    "                action_key = (action['type'], action['row'], action['col'])\n",
    "                if action_key in seen_actions:\n",
    "                    repeat_count += 1\n",
    "                    if repeat_count >= 3:\n",
    "                        break\n",
    "                else:\n",
    "                    repeat_count = 0\n",
    "                    seen_actions.add(action_key)\n",
    "\n",
    "                result = game.do_action(action)\n",
    "                if result in (\"mine\", \"win\"):\n",
    "                    moves += 1\n",
    "                    break\n",
    "                elif result == \"ok\":\n",
    "                    moves += 1\n",
    "                else:\n",
    "                    invalids += 1\n",
    "                    consecutive_invalids += 1\n",
    "                    if consecutive_invalids >= 5:\n",
    "                        break\n",
    "\n",
    "            if game.state() == \"success\":\n",
    "                wins += 1\n",
    "            total_moves += moves\n",
    "            invalid_count += invalids\n",
    "\n",
    "        win_rate = wins / self.num_games\n",
    "        avg_moves = total_moves / self.num_games\n",
    "        avg_resp_len = total_response_len / max(1, response_count)\n",
    "        \n",
    "        # Color-coded output\n",
    "        inv_color = \"🔴\" if invalid_count > 10 else (\"🟡\" if invalid_count > 5 else \"🟢\")\n",
    "        len_color = \"🔴\" if avg_resp_len > 100 else (\"🟡\" if avg_resp_len > 50 else \"🟢\")\n",
    "        \n",
    "        print(f\"\\n[Eval @ step {state.global_step}] \"\n",
    "              f\"Win: {wins}/{self.num_games} ({win_rate*100:.0f}%) | \"\n",
    "              f\"Moves: {avg_moves:.1f} | \"\n",
    "              f\"{inv_color} Invalid: {invalid_count} | \"\n",
    "              f\"{len_color} AvgLen: {avg_resp_len:.0f}\\n\")\n",
    "\n",
    "        if was_training:\n",
    "            model.train()\n",
    "\n",
    "eval_callback = MinesweeperEvalCallback(eval_every_steps=50, num_games=10)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVAL CALLBACK v2\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Games per eval:      {eval_callback.num_games}\")\n",
    "print(f\"  Eval every:          {eval_callback.eval_every_steps} steps\")\n",
    "print(f\"  max_new_tokens:      96 (increased from 64)\")\n",
    "print(f\"  Configs:             {len(EVAL_CONFIGS)} boards including 0-mine cases\")\n",
    "print()\n",
    "print(\"Now tracking:\")\n",
    "print(\"  - Invalid count (🟢<5, 🟡5-10, 🔴>10)\")\n",
    "print(\"  - Response length (🟢<50, 🟡50-100, 🔴>100) - shorter is better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb33de0",
   "metadata": {},
   "source": [
    "# 🚨 Emergency Merge — Run ANYTIME\n",
    "\n",
    "These utility functions let you **merge the latest checkpoint into a standalone model** at any point:\n",
    "- **During** training (in a separate cell)\n",
    "- **After** training finishes or crashes\n",
    "- **Before** deadline — stop training, merge, and submit\n",
    "\n",
    "Just call `merge_latest_checkpoint()` whenever you need a submittable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# 🚨 EMERGENCY MERGE - Run this ANYTIME to get merged model from latest checkpoint\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "def merge_latest_checkpoint(force=False):\n",
    "    \"\"\"\n",
    "    Merge the latest checkpoint into a standalone model.\n",
    "    Can be run DURING training (in another cell) or AFTER training stops.\n",
    "    \n",
    "    Args:\n",
    "        force: If True, merge even if already merged\n",
    "    \n",
    "    Returns:\n",
    "        Path to merged model or None\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🔄 EMERGENCY CHECKPOINT MERGE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Find all checkpoints\n",
    "    checkpoint_dirs = glob(os.path.join(CHECKPOINT_DIR, \"checkpoint-*\"))\n",
    "    \n",
    "    if not checkpoint_dirs:\n",
    "        print(\"❌ No checkpoints found!\")\n",
    "        print(f\"   Searched in: {CHECKPOINT_DIR}\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by step number\n",
    "    def get_step(path):\n",
    "        try:\n",
    "            return int(os.path.basename(path).split(\"-\")[1])\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    checkpoint_dirs.sort(key=get_step, reverse=True)\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    latest_step = get_step(latest_checkpoint)\n",
    "    \n",
    "    print(f\"📂 Found {len(checkpoint_dirs)} checkpoint(s)\")\n",
    "    print(f\"   Latest: {os.path.basename(latest_checkpoint)} (step {latest_step})\")\n",
    "    \n",
    "    # Output directory for merged model\n",
    "    merged_output = os.path.join(CHECKPOINT_DIR, f\"merged_step_{latest_step}\")\n",
    "    \n",
    "    # Check if already merged\n",
    "    if os.path.exists(merged_output) and not force:\n",
    "        print(f\"✅ Already merged: {merged_output}\")\n",
    "        print(\"   Use force=True to re-merge\")\n",
    "        return merged_output\n",
    "    \n",
    "    print(f\"\\n🔧 Merging checkpoint to: {merged_output}\")\n",
    "    print(\"   This takes ~5-10 minutes...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the checkpoint\n",
    "        from peft import PeftModel\n",
    "        \n",
    "        # Load base model + LoRA adapter\n",
    "        print(\"   Step 1/3: Loading base model...\")\n",
    "        checkpoint_model, checkpoint_tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name=latest_checkpoint,\n",
    "            max_seq_length=2048,\n",
    "            dtype=torch.bfloat16,\n",
    "            load_in_4bit=False,\n",
    "        )\n",
    "        \n",
    "        # Merge LoRA weights into base model\n",
    "        print(\"   Step 2/3: Merging LoRA weights...\")\n",
    "        checkpoint_model = FastLanguageModel.for_inference(checkpoint_model)\n",
    "        merged_model = checkpoint_model.merge_and_unload()\n",
    "        \n",
    "        # Save merged model\n",
    "        print(\"   Step 3/3: Saving merged model...\")\n",
    "        os.makedirs(merged_output, exist_ok=True)\n",
    "        merged_model.save_pretrained(merged_output)\n",
    "        checkpoint_tokenizer.save_pretrained(merged_output)\n",
    "        \n",
    "        print(f\"\\n✅ SUCCESS! Merged model saved to:\")\n",
    "        print(f\"   {merged_output}\")\n",
    "        print(f\"\\n📊 Model stats:\")\n",
    "        print(f\"   - Trained steps: {latest_step}\")\n",
    "        print(f\"   - Size: ~{sum(os.path.getsize(os.path.join(merged_output, f)) for f in os.listdir(merged_output)) / (1024**3):.1f} GB\")\n",
    "        \n",
    "        # Also create a \"latest\" symlink/copy for convenience\n",
    "        latest_link = os.path.join(CHECKPOINT_DIR, \"merged_latest\")\n",
    "        if os.path.exists(latest_link):\n",
    "            if os.path.islink(latest_link) or os.path.isdir(latest_link):\n",
    "                shutil.rmtree(latest_link, ignore_errors=True)\n",
    "        try:\n",
    "            os.symlink(merged_output, latest_link, target_is_directory=True)\n",
    "            print(f\"   - Also available at: {latest_link}\")\n",
    "        except:\n",
    "            pass  # Symlinks might not work on all systems\n",
    "        \n",
    "        return merged_output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR during merge: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def list_checkpoints():\n",
    "    \"\"\"Show all available checkpoints\"\"\"\n",
    "    checkpoint_dirs = glob(os.path.join(CHECKPOINT_DIR, \"checkpoint-*\"))\n",
    "    \n",
    "    if not checkpoint_dirs:\n",
    "        print(\"No checkpoints found yet. Training might not have started.\")\n",
    "        return\n",
    "    \n",
    "    checkpoint_dirs.sort(key=lambda p: int(os.path.basename(p).split(\"-\")[1]))\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"📁 AVAILABLE CHECKPOINTS\")\n",
    "    print(\"=\" * 70)\n",
    "    for cp in checkpoint_dirs:\n",
    "        step = os.path.basename(cp).split(\"-\")[1]\n",
    "        size = sum(os.path.getsize(os.path.join(cp, f)) for f in os.listdir(cp)) / (1024**2)\n",
    "        print(f\"  checkpoint-{step:>4s}  ({size:>6.1f} MB)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# Quick status check\n",
    "list_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# 🧪 QUICK TEST - Verify merged model works\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def quick_test_merged_model(model_path):\n",
    "    \"\"\"Test merged model on 3 boards to verify it produces valid actions.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🧪 TESTING MERGED MODEL\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load merged model\n",
    "    print(f\"Loading from: {model_path}\")\n",
    "    test_model, test_tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=model_path,\n",
    "        max_seq_length=2048,\n",
    "        dtype=torch.bfloat16,\n",
    "        load_in_4bit=False,\n",
    "    )\n",
    "    test_model = FastLanguageModel.for_inference(test_model)\n",
    "    \n",
    "    test_boards = [\n",
    "        (1, 1, 0, \"1×1 trivial\"),\n",
    "        (5, 5, 0, \"5×5 zero mines\"),\n",
    "        (6, 6, 5, \"6×6 standard\"),\n",
    "    ]\n",
    "    \n",
    "    wins = 0\n",
    "    for rows, cols, mines, label in test_boards:\n",
    "        game = MinesweeperGame(rows, cols, mines, seed=42)\n",
    "        prompt = format_state_for_llm(game)\n",
    "        \n",
    "        text = test_tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "        \n",
    "        output = test_model.generate(\n",
    "            **test_tokenizer(text, return_tensors=\"pt\").to(\"cuda\"),\n",
    "            temperature=0.7,\n",
    "            max_new_tokens=96,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        \n",
    "        response = test_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        response_only = response.split(\"assistant\")[-1].strip() if \"assistant\" in response else response\n",
    "        \n",
    "        action = parse_llm_action(response_only)\n",
    "        \n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"  Response: {response_only[:100]}\")\n",
    "        print(f\"  Parsed: {action}\")\n",
    "        \n",
    "        if action:\n",
    "            result = game.do_action(action)\n",
    "            print(f\"  Result: {result}\")\n",
    "            if result in [\"win\", \"ok\"]:\n",
    "                wins += 1\n",
    "                print(\"  ✅ VALID\")\n",
    "            else:\n",
    "                print(f\"  ❌ INVALID ({result})\")\n",
    "        else:\n",
    "            print(\"  ❌ PARSE FAILED\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"QUICK TEST RESULT: {wins}/3 valid actions\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Cleanup\n",
    "    del test_model\n",
    "    del test_tokenizer\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return wins >= 2  # At least 2/3 should work\n",
    "\n",
    "\n",
    "# Test the latest merged model\n",
    "merged_path = os.path.join(CHECKPOINT_DIR, \"merged_latest\")\n",
    "if os.path.exists(merged_path):\n",
    "    success = quick_test_merged_model(merged_path)\n",
    "    if success:\n",
    "        print(\"✅ Model is ready for submission!\")\n",
    "    else:\n",
    "        print(\"⚠️ Model might need more training\")\n",
    "else:\n",
    "    print(\"No merged model found. Run merge_latest_checkpoint() first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8e106",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Train the Model\n",
    "\n",
    "Start GRPO training with reward functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d03871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# CHECKPOINT TRACKING CALLBACK\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class CheckpointTrackerCallback(TrainerCallback):\n",
    "    \"\"\"Track checkpoints and update the tracker file after each save.\"\"\"\n",
    "    \n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        \"\"\"Called after a checkpoint is saved.\"\"\"\n",
    "        checkpoint_path = os.path.join(args.output_dir, f\"checkpoint-{state.global_step}\")\n",
    "        \n",
    "        tracker = get_checkpoint_tracker()\n",
    "        tracker[\"latest_checkpoint\"] = checkpoint_path\n",
    "        tracker[\"latest_step\"] = state.global_step\n",
    "        tracker[\"total_steps_trained\"] = state.global_step\n",
    "        \n",
    "        if checkpoint_path not in tracker[\"checkpoints\"]:\n",
    "            tracker[\"checkpoints\"].append(checkpoint_path)\n",
    "        \n",
    "        save_checkpoint_tracker(tracker)\n",
    "        \n",
    "        print(f\"\\n💾 Checkpoint saved: {checkpoint_path}\")\n",
    "        print(f\"   Total steps trained: {state.global_step}\")\n",
    "\n",
    "\n",
    "# Create trainer with checkpoint tracking\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        valid_json_reward,   # FORMAT (50%): +15 pure JSON, -30 invalid\n",
    "        gameplay_scores,     # GAMEPLAY (40%): +15 valid, -25 invalid\n",
    "        strategic_reward,    # STRATEGY (10%): +5 logical\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    "    callbacks = [eval_callback, CheckpointTrackerCallback()],\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GRPO TRAINER WITH CHECKPOINT RESUMPTION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Reward Functions (with weights):\")\n",
    "print(\"  [1] valid_json_reward  (50%) — Format compliance\")\n",
    "print(\"  [2] gameplay_scores    (40%) — Game validity\")\n",
    "print(\"  [3] strategic_reward   (10%) — Smart play\")\n",
    "print()\n",
    "\n",
    "# Record training session\n",
    "tracker = get_checkpoint_tracker()\n",
    "session_info = {\n",
    "    \"start_time\": datetime.now().isoformat(),\n",
    "    \"resume_from\": RESUME_FROM_CHECKPOINT,\n",
    "    \"target_steps\": TARGET_TOTAL_STEPS,\n",
    "}\n",
    "tracker[\"training_sessions\"].append(session_info)\n",
    "save_checkpoint_tracker(tracker)\n",
    "\n",
    "# Start or resume training\n",
    "if RESUME_FROM_CHECKPOINT:\n",
    "    print(f\"🔄 RESUMING from checkpoint: {RESUME_FROM_CHECKPOINT}\")\n",
    "    print(f\"   Starting at step: {resume_step}\")\n",
    "    print(f\"   Training until step: {TARGET_TOTAL_STEPS}\")\n",
    "    print()\n",
    "    trainer.train(resume_from_checkpoint=RESUME_FROM_CHECKPOINT)\n",
    "else:\n",
    "    print(\"🚀 STARTING fresh training\")\n",
    "    print(f\"   Training until step: {TARGET_TOTAL_STEPS}\")\n",
    "    print()\n",
    "    trainer.train()\n",
    "\n",
    "# Update tracker after training completes\n",
    "tracker = get_checkpoint_tracker()\n",
    "tracker[\"training_sessions\"][-1][\"end_time\"] = datetime.now().isoformat()\n",
    "tracker[\"training_sessions\"][-1][\"final_step\"] = trainer.state.global_step\n",
    "save_checkpoint_tracker(tracker)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING SESSION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Final step: {trainer.state.global_step}\")\n",
    "print(f\"  Checkpoints saved in: {CHECKPOINT_DIR}/\")\n",
    "print()\n",
    "print(\"To continue training:\")\n",
    "print(\"  1. Increase TARGET_TOTAL_STEPS in the config cell\")\n",
    "print(\"  2. Re-run config cell and this training cell\")\n",
    "print(\"  3. Training will automatically resume from latest checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8d025",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Test Trained Model\n",
    "\n",
    "Evaluate the finetuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00276c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on variable board sizes across the full competition range\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "test_configs = [\n",
    "    (1, 1, 0, 200, \"1x1 Trivial\"),\n",
    "    (3, 3, 1, 201, \"Tiny\"),\n",
    "    (5, 5, 3, 202, \"Small/Easy\"),\n",
    "    (6, 6, 5, 99,  \"Standard\"),\n",
    "    (8, 8, 10, 101, \"Medium\"),\n",
    "    (10, 10, 20, 203, \"Large 20%\"),\n",
    "    (15, 15, 45, 204, \"XL 20%\"),\n",
    "    (1, 20, 4, 205, \"Row Board\"),\n",
    "    (20, 1, 4, 206, \"Column Board\"),\n",
    "    (5, 5, 0, 207, \"Zero Mines\"),\n",
    "]\n",
    "\n",
    "for rows, cols, mines, seed, label in test_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"=== {label} ({rows}x{cols}, {mines} mines) ===\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    test_game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "\n",
    "    # Handle already-won games (0-mine boards that auto-cascade)\n",
    "    if test_game.state() != \"ongoing\":\n",
    "        print(f\"  Game auto-resolved: {test_game.state()}\")\n",
    "        continue\n",
    "\n",
    "    test_prompt = format_state_for_llm(test_game)\n",
    "\n",
    "    test_text = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": test_prompt},\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True,\n",
    "                       max_length=max_prompt_length + 100)\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.7,  # LAMER paper: 0.7 for eval\n",
    "        max_new_tokens=128,  # HACKATHON CONSTRAINT: JSON-only\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "\n",
    "    # Decode only generated tokens\n",
    "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "    print(f\"Response: {response_text.strip()}\")\n",
    "\n",
    "    action = parse_llm_action(response_text)\n",
    "    print(f\"Parsed action: {action}\")\n",
    "\n",
    "    if action:\n",
    "        result = test_game.do_action(action)\n",
    "        print(f\"Result: {result} | Game state: {test_game.state()}\")\n",
    "    else:\n",
    "        print(\"⚠️ Failed to parse a valid action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2551f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Exhaustive Evaluation: Full Competition Range\n",
    "\n",
    "Play complete games across 37 board configurations (1×1 to 50×50, 0-20% mines).\n",
    "**No move limit** — only two outcomes: SUCCESS (all safe cells revealed) or FAILURE (mine revealed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31315fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def play_full_game(model, tokenizer, rows=6, cols=6, num_mines=5, seed=None,\n",
    "#                    verbose=False):\n",
    "#     \"\"\"Play a complete Minesweeper game, tracking detailed metrics.\n",
    "\n",
    "#     Supports any board size from 1x1 to 50x50.\n",
    "#     NO move limit — game ends ONLY on:\n",
    "#       - SUCCESS: all non-mine cells are revealed\n",
    "#       - FAILURE: any mine cell is revealed\n",
    "#     A safety iteration cap prevents infinite loops from repeated invalid actions.\n",
    "#     \"\"\"\n",
    "#     game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "#     # Edge case: game already won (e.g., 0-mine board)\n",
    "#     if game.state() != \"ongoing\":\n",
    "#         return {\n",
    "#             \"game\": game,\n",
    "#             \"moves\": 0,\n",
    "#             \"logical_moves\": 0,\n",
    "#             \"flags_correct\": 0,\n",
    "#             \"flags_wrong\": 0,\n",
    "#             \"total_invalids\": 0,\n",
    "#             \"result\": game.state(),\n",
    "#             \"progress\": game.progress(),\n",
    "#             \"config\": f\"{rows}x{cols}m{num_mines}\",\n",
    "#         }\n",
    "\n",
    "#     moves = 0\n",
    "#     consecutive_invalids = 0\n",
    "#     total_invalids = 0\n",
    "#     logical_moves = 0\n",
    "#     flags_correct = 0\n",
    "#     flags_wrong = 0\n",
    "#     seen_actions = set()   # Fix #4: detect repeated actions (stuck loop)\n",
    "#     repeat_count = 0       # Fix #4: consecutive repeat counter\n",
    "#     # Safety cap to prevent infinite loops — NOT a game move limit\n",
    "#     # Capped at 500 to prevent runaway 50×50 evals (was rows*cols*3+50 = 7550 for 50×50)\n",
    "#     max_iterations = min(500, rows * cols + 100)\n",
    "\n",
    "#     iteration = 0\n",
    "#     while game.state() == \"ongoing\" and iteration < max_iterations:\n",
    "#         iteration += 1\n",
    "#         prompt = format_state_for_llm(game)\n",
    "#         text = tokenizer.apply_chat_template(\n",
    "#             [\n",
    "#                 {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "#                 {\"role\": \"user\", \"content\": prompt},\n",
    "#             ],\n",
    "#             tokenize=False,\n",
    "#             add_generation_prompt=True,\n",
    "#         )\n",
    "\n",
    "#         inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "#                            max_length=max_prompt_length + 100)\n",
    "#         inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             output = model.generate(\n",
    "#                 **inputs,\n",
    "#                 temperature=0.7,  # LAMER paper: 0.7 for eval\n",
    "#                 max_new_tokens=128,  # HACKATHON CONSTRAINT: JSON-only\n",
    "#                 do_sample=True,\n",
    "#                 top_p=0.9,\n",
    "#                 repetition_penalty=1.2,\n",
    "#             )\n",
    "\n",
    "#         # Decode ONLY generated tokens\n",
    "#         gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "#         response = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "#         action = parse_llm_action(response)\n",
    "\n",
    "#         if action is None:\n",
    "#             consecutive_invalids += 1\n",
    "#             total_invalids += 1\n",
    "#             if consecutive_invalids >= 5:\n",
    "#                 break  # Agent is stuck — abort\n",
    "#             continue\n",
    "\n",
    "#         # Fix #4: Check for repeated actions (stuck detection)\n",
    "#         action_key = (action['type'], action['row'], action['col'])\n",
    "#         if action_key in seen_actions:\n",
    "#             repeat_count += 1\n",
    "#             if repeat_count >= 3:  # Same move 3 times = stuck\n",
    "#                 break\n",
    "#         else:\n",
    "#             repeat_count = 0\n",
    "#             seen_actions.add(action_key)\n",
    "\n",
    "#         # Track logical moves (compute BEFORE applying action)\n",
    "#         safe_set, mine_set = _compute_safe_and_mine_cells(game)\n",
    "#         r, c = action[\"row\"], action[\"col\"]\n",
    "#         if action[\"type\"] == \"reveal\" and (r, c) in safe_set:\n",
    "#             logical_moves += 1\n",
    "#         elif action[\"type\"] == \"flag\" and (r, c) in mine_set:\n",
    "#             logical_moves += 1\n",
    "\n",
    "#         # Track flag accuracy\n",
    "#         if action[\"type\"] == \"flag\":\n",
    "#             if 0 <= r < game.rows and 0 <= c < game.cols:\n",
    "#                 if game._board[r][c] == -1:\n",
    "#                     flags_correct += 1\n",
    "#                 else:\n",
    "#                     flags_wrong += 1\n",
    "\n",
    "#         if verbose:\n",
    "#             print(f\"  Move {moves}: {action}\")\n",
    "\n",
    "#         result = game.do_action(action)\n",
    "#         if result in (\"mine\", \"win\", \"ok\"):\n",
    "#             moves += 1\n",
    "#         elif result in (\"out_of_bounds\", \"already_revealed\", \"flagged_cell\",\n",
    "#                          \"invalid_flag\", \"invalid_format\"):\n",
    "#             # Invalid moves don't count but game stays ongoing\n",
    "#             total_invalids += 1\n",
    "#             consecutive_invalids += 1\n",
    "#             if consecutive_invalids >= 5:\n",
    "#                 break\n",
    "\n",
    "#         if result in (\"mine\", \"win\"):\n",
    "#             break\n",
    "\n",
    "#     return {\n",
    "#         \"game\": game,\n",
    "#         \"moves\": moves,\n",
    "#         \"logical_moves\": logical_moves,\n",
    "#         \"flags_correct\": flags_correct,\n",
    "#         \"flags_wrong\": flags_wrong,\n",
    "#         \"total_invalids\": total_invalids,\n",
    "#         \"result\": game.state(),\n",
    "#         \"progress\": game.progress(),\n",
    "#         \"config\": f\"{rows}x{cols}m{num_mines}\",\n",
    "#     }\n",
    "\n",
    "\n",
    "# # ──────────────────────────────────────────────────────────────────────\n",
    "# # EXHAUSTIVE Multi-Size Evaluation — Competition Spec\n",
    "# # n, m ∈ [1, 50], mines 0-20% of total cells\n",
    "# # Only two outcomes: SUCCESS or FAILURE (no timeouts)\n",
    "# # ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# EVAL_SUITE = [\n",
    "#     # (rows, cols, mines, num_games, label)\n",
    "\n",
    "#     # === Trivial / Edge Cases ===\n",
    "#     (1, 1, 0,   5,  \"1x1 trivial\"),\n",
    "#     (1, 2, 0,   5,  \"1x2 trivial\"),\n",
    "#     (2, 1, 0,   5,  \"2x1 trivial\"),\n",
    "#     (2, 2, 0,   5,  \"2x2 no mines\"),\n",
    "#     (3, 3, 0,   5,  \"3x3 no mines\"),\n",
    "#     (5, 5, 0,   5,  \"5x5 no mines\"),\n",
    "\n",
    "#     # === Tiny Boards ===\n",
    "#     (3, 3, 1,  10,  \"3x3 1 mine\"),\n",
    "#     (4, 4, 3,  10,  \"4x4 3 mines\"),\n",
    "\n",
    "#     # === Small Boards ===\n",
    "#     (5, 5, 3,  15,  \"5x5 easy\"),\n",
    "#     (5, 5, 5,  10,  \"5x5 max density\"),\n",
    "\n",
    "#     # === Standard ===\n",
    "#     (6, 6, 5,  20,  \"6x6 standard\"),\n",
    "#     (6, 6, 7,  10,  \"6x6 hard\"),\n",
    "\n",
    "#     # === Medium ===\n",
    "#     (7, 7, 7,  10,  \"7x7 medium\"),\n",
    "#     (8, 8, 10, 10,  \"8x8 medium\"),\n",
    "#     (8, 8, 12, 10,  \"8x8 max density\"),\n",
    "\n",
    "#     # === Large ===\n",
    "#     (10, 10, 10,  5, \"10x10 10%\"),\n",
    "#     (10, 10, 20, 10, \"10x10 20%\"),\n",
    "#     (15, 15, 45,  5, \"15x15 20%\"),\n",
    "\n",
    "#     # === XL ===\n",
    "#     (20, 20, 80,  3, \"20x20 20%\"),\n",
    "#     (25, 25, 125, 3, \"25x25 20%\"),\n",
    "#     (30, 30, 180, 2, \"30x30 20%\"),\n",
    "\n",
    "#     # === XXL ===\n",
    "#     (40, 40, 320, 2, \"40x40 20%\"),\n",
    "#     (50, 50, 500, 2, \"50x50 20%\"),\n",
    "\n",
    "#     # === Rectangular ===\n",
    "#     (1, 10, 2,   5, \"1x10 row\"),\n",
    "#     (10, 1, 2,   5, \"10x1 column\"),\n",
    "#     (1, 50, 10,  3, \"1x50 row\"),\n",
    "#     (50, 1, 10,  3, \"50x1 column\"),\n",
    "#     (6, 8, 6,    5, \"6x8 rect\"),\n",
    "#     (8, 6, 6,    5, \"8x6 rect\"),\n",
    "#     (5, 15, 15,  3, \"5x15 wide\"),\n",
    "#     (15, 5, 15,  3, \"15x5 tall\"),\n",
    "#     (3, 50, 30,  2, \"3x50 extreme wide\"),\n",
    "#     (50, 3, 30,  2, \"50x3 extreme tall\"),\n",
    "\n",
    "#     # === Sparse (low density) ===\n",
    "#     (10, 10, 1,  5, \"10x10 sparse\"),\n",
    "#     (20, 20, 4,  3, \"20x20 sparse\"),\n",
    "#     (50, 50, 10, 2, \"50x50 sparse\"),\n",
    "\n",
    "#     # === Progressive Difficulty (Fix #10: LAMER generalization test) ===\n",
    "#     # Same size, increasing mines — tests density scaling\n",
    "#     (10, 10, 5,  5, \"10x10 5% progressive\"),\n",
    "#     (10, 10, 15, 5, \"10x10 15% progressive\"),\n",
    "\n",
    "#     # Increasing size, same ~10% density — tests size scaling\n",
    "#     (15, 15, 23, 3, \"15x15 10% density\"),\n",
    "#     (20, 20, 40, 3, \"20x20 10% density\"),\n",
    "\n",
    "#     # Generalization to harder unseen configs\n",
    "#     (25, 25, 62, 2, \"25x25 10% generalization\"),\n",
    "#     (30, 30, 90, 2, \"30x30 10% generalization\"),\n",
    "# ]\n",
    "\n",
    "# FastLanguageModel.for_inference(model)\n",
    "# total_games = sum(n for _,_,_,n,_ in EVAL_SUITE)\n",
    "# print(f\"{'='*80}\")\n",
    "# print(f\"  EXHAUSTIVE EVALUATION — {total_games} games across {len(EVAL_SUITE)} configs\")\n",
    "# print(f\"  Competition spec: n,m ∈ [1,50], mines 0-20%, no move limit\")\n",
    "# print(f\"  Includes progressive difficulty test (LAMER generalization)\")\n",
    "# print(f\"  Only two outcomes: SUCCESS or FAILURE\")\n",
    "# print(f\"{'='*80}\\n\")\n",
    "\n",
    "# all_results = []\n",
    "# per_config_stats = {}\n",
    "\n",
    "# for rows, cols, mines, num_games, label in EVAL_SUITE:\n",
    "#     config_key = f\"{rows}x{cols}m{mines}\"\n",
    "#     wins = 0\n",
    "#     fails = 0\n",
    "#     config_results = []\n",
    "\n",
    "#     for i in range(num_games):\n",
    "#         info = play_full_game(model, tokenizer, rows=rows, cols=cols,\n",
    "#                               num_mines=mines, seed=5000 + i + hash(config_key) % 10000)\n",
    "#         config_results.append(info)\n",
    "#         all_results.append(info)\n",
    "\n",
    "#         if info[\"result\"] == \"success\":\n",
    "#             wins += 1\n",
    "#         elif info[\"result\"] == \"failed\":\n",
    "#             fails += 1\n",
    "\n",
    "#     # Per-config summary\n",
    "#     avg_moves = np.mean([r[\"moves\"] for r in config_results])\n",
    "#     avg_logical = np.mean([r[\"logical_moves\"] for r in config_results])\n",
    "#     avg_progress = np.mean([r[\"progress\"] for r in config_results])\n",
    "#     avg_invalids = np.mean([r[\"total_invalids\"] for r in config_results])\n",
    "#     stuck = sum(1 for r in config_results if r[\"result\"] == \"ongoing\")\n",
    "#     wr = wins / num_games * 100\n",
    "\n",
    "#     per_config_stats[config_key] = {\n",
    "#         \"label\": label, \"wins\": wins, \"fails\": fails, \"stuck\": stuck,\n",
    "#         \"total\": num_games, \"win_rate\": wr,\n",
    "#         \"avg_moves\": avg_moves, \"avg_progress\": avg_progress,\n",
    "#     }\n",
    "\n",
    "#     status_icon = \"✅\" if wr >= 50 else \"⚠️\" if wr >= 20 else \"❌\"\n",
    "#     print(f\"  {status_icon} {label:22s} ({config_key:12s}): \"\n",
    "#           f\"{wins:2d}/{num_games:2d} wins ({wr:5.1f}%) | \"\n",
    "#           f\"fails={fails} stuck={stuck} | \"\n",
    "#           f\"moves={avg_moves:5.1f} | logical={avg_logical:4.1f} | \"\n",
    "#           f\"progress={avg_progress:.0%} | invalids={avg_invalids:.1f}\")\n",
    "\n",
    "# # ── Overall Summary ──\n",
    "# total_games_actual = len(all_results)\n",
    "# total_wins = sum(1 for r in all_results if r[\"result\"] == \"success\")\n",
    "# total_fails = sum(1 for r in all_results if r[\"result\"] == \"failed\")\n",
    "# total_stuck = sum(1 for r in all_results if r[\"result\"] == \"ongoing\")\n",
    "# fc = sum(r[\"flags_correct\"] for r in all_results)\n",
    "# fw = sum(r[\"flags_wrong\"] for r in all_results)\n",
    "\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"  OVERALL: {total_wins}/{total_games_actual} wins ({total_wins/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"{'='*80}\")\n",
    "# print(f\"  Wins (success):    {total_wins:4d} ({total_wins/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"  Losses (failure):  {total_fails:4d} ({total_fails/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"  Stuck (loop cap):  {total_stuck:4d} ({total_stuck/total_games_actual*100:.1f}%)\")\n",
    "# print(f\"  Avg moves:         {np.mean([r['moves'] for r in all_results]):.1f}\")\n",
    "# print(f\"  Avg progress:      {np.mean([r['progress'] for r in all_results]):.0%}\")\n",
    "# print(f\"  Avg logical moves: {np.mean([r['logical_moves'] for r in all_results]):.1f}\")\n",
    "# if fc + fw > 0:\n",
    "#     print(f\"  Flag accuracy:     {fc}/{fc+fw} ({fc/(fc+fw)*100:.1f}%)\")\n",
    "# else:\n",
    "#     print(f\"  Flags: none placed\")\n",
    "\n",
    "# # ── Category Breakdown ──\n",
    "# categories = {\n",
    "#     \"Trivial (0 mines)\": [k for k, v in per_config_stats.items() if \"m0\" in k],\n",
    "#     \"Tiny (≤4x4)\":       [k for k, v in per_config_stats.items()\n",
    "#                            if v[\"label\"].startswith((\"3x3\", \"4x4\")) and \"m0\" not in k],\n",
    "#     \"Small (5x5)\":       [k for k, v in per_config_stats.items() if k.startswith(\"5x5\")],\n",
    "#     \"Standard (6x6)\":    [k for k, v in per_config_stats.items() if k.startswith(\"6x6\")],\n",
    "#     \"Medium (7-8)\":      [k for k, v in per_config_stats.items()\n",
    "#                            if k.startswith((\"7x7\", \"8x8\"))],\n",
    "#     \"Large (10-15)\":     [k for k, v in per_config_stats.items()\n",
    "#                            if k.startswith((\"10x10\", \"15x15\"))],\n",
    "#     \"XL (20-50)\":        [k for k, v in per_config_stats.items()\n",
    "#                            if k.startswith((\"20x20\", \"25x25\", \"30x30\", \"40x40\", \"50x50\"))],\n",
    "#     \"Rectangular\":       [k for k, v in per_config_stats.items()\n",
    "#                            if \"rect\" in v[\"label\"] or \"row\" in v[\"label\"]\n",
    "#                            or \"column\" in v[\"label\"] or \"wide\" in v[\"label\"]\n",
    "#                            or \"tall\" in v[\"label\"]],\n",
    "#     \"Sparse\":            [k for k, v in per_config_stats.items() if \"sparse\" in v[\"label\"]],\n",
    "#     \"Progressive\":       [k for k, v in per_config_stats.items()\n",
    "#                            if \"progressive\" in v[\"label\"] or \"generalization\" in v[\"label\"]\n",
    "#                            or \"density\" in v[\"label\"]],\n",
    "# }\n",
    "\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"  CATEGORY BREAKDOWN\")\n",
    "# print(f\"{'='*80}\")\n",
    "# for cat_name, keys in categories.items():\n",
    "#     if not keys:\n",
    "#         continue\n",
    "#     cat_wins = sum(per_config_stats[k][\"wins\"] for k in keys)\n",
    "#     cat_total = sum(per_config_stats[k][\"total\"] for k in keys)\n",
    "#     if cat_total > 0:\n",
    "#         cat_wr = cat_wins / cat_total * 100\n",
    "#         icon = \"✅\" if cat_wr >= 50 else \"⚠️\" if cat_wr >= 20 else \"❌\"\n",
    "#         print(f\"  {icon} {cat_name:22s}: {cat_wins:3d}/{cat_total:3d} ({cat_wr:5.1f}%)\")\n",
    "# print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306cc45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Checkpoint Status & Final Model Save\n",
    "\n",
    "Check training progress and save the final model for hackathon submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# SAVE FINAL MODEL FOR HACKATHON SUBMISSION\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# This cell saves the final merged model ready for submission.\n",
    "# It uses the latest checkpoint and creates a properly merged model.\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import os, shutil, gc\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "# Get training info from checkpoint tracker\n",
    "tracker = get_checkpoint_tracker()\n",
    "total_steps = tracker.get(\"total_steps_trained\", 0)\n",
    "latest_ckpt = tracker.get(\"latest_checkpoint\", None)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SAVING FINAL MODEL FOR HACKATHON SUBMISSION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Total steps trained: {total_steps}\")\n",
    "print(f\"  Latest checkpoint:   {latest_ckpt}\")\n",
    "print(f\"  Timestamp:           {timestamp}\")\n",
    "print()\n",
    "\n",
    "# Directory names with step count for clarity\n",
    "lora_dir = f\"my_minesweeper_model_step{total_steps}_{timestamp}\"\n",
    "merged_dir = f\"my_minesweeper_model_merged_step{total_steps}_{timestamp}\"\n",
    "merged_dir_latest = \"my_minesweeper_model_merged_latest\"\n",
    "lora_dir_latest = \"my_minesweeper_model_latest\"\n",
    "\n",
    "# Save LoRA adapters\n",
    "model.save_pretrained(lora_dir)\n",
    "tokenizer.save_pretrained(lora_dir)\n",
    "print(f\"✅ LoRA adapters saved to: {lora_dir}/\")\n",
    "\n",
    "# Also save to \"latest\" directories\n",
    "model.save_pretrained(lora_dir_latest)\n",
    "tokenizer.save_pretrained(lora_dir_latest)\n",
    "print(f\"✅ LoRA adapters also saved to: {lora_dir_latest}/\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# Save merged model in 16bit\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Try Unsloth's native method first\n",
    "    model.save_pretrained_merged(\n",
    "        merged_dir,\n",
    "        tokenizer,\n",
    "        save_method=\"merged_16bit\",\n",
    "    )\n",
    "    print(f\"✅ Merged 16-bit model saved via Unsloth to: {merged_dir}/\")\n",
    "except (UnboundLocalError, Exception) as e:\n",
    "    print(f\"⚠️ Unsloth merge failed ({type(e).__name__}: {e})\")\n",
    "    print(\"   Falling back to manual LoRA merge...\")\n",
    "\n",
    "    try:\n",
    "        from peft import PeftModel\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "        print(\"   Loading base model for merge...\")\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"/workspace/workspace/Qwen2.5-14B-Instruct\",\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        print(\"   Applying LoRA adapters...\")\n",
    "        merged_model = PeftModel.from_pretrained(base_model, lora_dir)\n",
    "        merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "        print(f\"   Saving merged model to: {merged_dir}/\")\n",
    "        merged_model.save_pretrained(merged_dir, safe_serialization=True)\n",
    "        tokenizer.save_pretrained(merged_dir)\n",
    "\n",
    "        del base_model, merged_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"✅ Merged 16-bit model saved to: {merged_dir}/\")\n",
    "\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ BOTH merge methods failed!\")\n",
    "        print(f\"   Unsloth error: {e}\")\n",
    "        print(f\"   Manual merge error: {e2}\")\n",
    "        print(f\"   LoRA adapters are still saved at: {lora_dir}/\")\n",
    "\n",
    "# Copy to \"latest\" directory\n",
    "if os.path.exists(merged_dir) and os.listdir(merged_dir):\n",
    "    if os.path.exists(merged_dir_latest):\n",
    "        shutil.rmtree(merged_dir_latest)\n",
    "    shutil.copytree(merged_dir, merged_dir_latest)\n",
    "    print(f\"✅ Also copied to: {merged_dir_latest}/\")\n",
    "\n",
    "# Update checkpoint tracker with final model info\n",
    "tracker[\"final_model\"] = {\n",
    "    \"lora_dir\": lora_dir,\n",
    "    \"merged_dir\": merged_dir,\n",
    "    \"total_steps\": total_steps,\n",
    "    \"timestamp\": timestamp,\n",
    "}\n",
    "save_checkpoint_tracker(tracker)\n",
    "\n",
    "# Verify saved files\n",
    "if os.path.exists(merged_dir):\n",
    "    saved_files = os.listdir(merged_dir)\n",
    "    safetensors = [f for f in saved_files if f.endswith(\".safetensors\")]\n",
    "    print(f\"\\n📁 Saved files in {merged_dir}:\")\n",
    "    print(f\"   Total files: {len(saved_files)}\")\n",
    "    print(f\"   Safetensors shards: {len(safetensors)}\")\n",
    "    print(f\"   Config: {'✅' if 'config.json' in saved_files else '❌'}\")\n",
    "    print(f\"   Tokenizer: {'✅' if 'tokenizer.json' in saved_files else '❌'}\")\n",
    "\n",
    "# List all saved checkpoints\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ALL SAVED CHECKPOINTS:\")\n",
    "print(f\"{'='*70}\")\n",
    "checkpoints = sorted(glob(os.path.join(CHECKPOINT_DIR, \"checkpoint-*\")))\n",
    "for ckpt in checkpoints:\n",
    "    step = os.path.basename(ckpt).split(\"-\")[1]\n",
    "    print(f\"  📁 {ckpt} (step {step})\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"HACKATHON SUBMISSION READY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  🏆 SUBMIT THIS: {merged_dir_latest}/\")\n",
    "print(f\"     (or the timestamped version: {merged_dir}/)\")\n",
    "print()\n",
    "print(f\"  Total training: {total_steps} steps\")\n",
    "print(f\"  All checkpoints preserved in: {CHECKPOINT_DIR}/\")\n",
    "print()\n",
    "print(\"To train more before submission:\")\n",
    "print(\"  1. Increase TARGET_TOTAL_STEPS in config cell\")\n",
    "print(\"  2. Re-run config and training cells\")\n",
    "print(\"  3. Re-run this save cell\")\n",
    "print(\"  4. Submit the new merged_latest model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# CHECK CHECKPOINT STATUS\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Run this cell anytime to see your training progress\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHECKPOINT STATUS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "tracker = get_checkpoint_tracker()\n",
    "\n",
    "print(f\"\\n📊 Training Progress:\")\n",
    "print(f\"   Total steps trained:  {tracker.get('total_steps_trained', 0)}\")\n",
    "print(f\"   Latest checkpoint:    {tracker.get('latest_checkpoint', 'None')}\")\n",
    "print(f\"   Training sessions:    {len(tracker.get('training_sessions', []))}\")\n",
    "\n",
    "# List all checkpoints\n",
    "checkpoints = sorted(glob(os.path.join(CHECKPOINT_DIR, \"checkpoint-*\")))\n",
    "print(f\"\\n📁 Saved Checkpoints ({len(checkpoints)} total):\")\n",
    "for ckpt in checkpoints:\n",
    "    step = os.path.basename(ckpt).split(\"-\")[1]\n",
    "    size_mb = sum(os.path.getsize(os.path.join(ckpt, f)) \n",
    "                  for f in os.listdir(ckpt) if os.path.isfile(os.path.join(ckpt, f))) / 1e6\n",
    "    print(f\"   checkpoint-{step:>4s} ({size_mb:.0f} MB)\")\n",
    "\n",
    "# Show training sessions\n",
    "sessions = tracker.get(\"training_sessions\", [])\n",
    "if sessions:\n",
    "    print(f\"\\n📅 Training Sessions:\")\n",
    "    for i, session in enumerate(sessions[-5:], 1):  # Show last 5 sessions\n",
    "        start = session.get(\"start_time\", \"?\")[:19]\n",
    "        end = session.get(\"end_time\", \"ongoing\")[:19] if session.get(\"end_time\") else \"ongoing\"\n",
    "        final = session.get(\"final_step\", \"?\")\n",
    "        print(f\"   Session {i}: {start} → {end} (step {final})\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"NEXT STEPS:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  To continue training:  Increase TARGET_TOTAL_STEPS and re-run training\")\n",
    "print(f\"  To save final model:   Run the next cell\")\n",
    "print(f\"  Current target:        {TARGET_TOTAL_STEPS} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaed02d",
   "metadata": {},
   "source": [
    "# Inference from Merged Model\n",
    "\n",
    "Load the saved merged model from disk (no LoRA, no Unsloth) and verify it works for Minesweeper inference.\n",
    "\n",
    "⚠️ **Important:** Unsloth patches transformers globally when imported. The cell below includes a workaround to reset these patches.\n",
    "\n",
    "**If you still get errors**, the cleanest solution is:\n",
    "1. **Restart Kernel** (Kernel → Restart)\n",
    "2. Run **only** the cells needed for inference (skip model loading/training cells)\n",
    "3. Or run the inference in a separate Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# INFERENCE FROM MERGED MODEL (Subprocess Approach)\n",
    "# \n",
    "# Unsloth patches transformers globally and cannot be easily undone.\n",
    "# This cell writes a standalone inference script and runs it in a \n",
    "# fresh Python subprocess where Unsloth was never imported.\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Write standalone inference script\n",
    "inference_script = '''\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "# ── Load model (pure transformers, no Unsloth) ──\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Use the _latest directory (always points to most recent model)\n",
    "merged_dir = \"my_minesweeper_model_merged_latest\"\n",
    "\n",
    "print(f\"Loading merged model from: {merged_dir}/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_dir)\n",
    "print(f\"  ✅ Tokenizer loaded ({tokenizer.vocab_size} vocab)\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.eval()\n",
    "print(f\"  ✅ Model loaded on {model.device}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ── Minimal MinesweeperGame for testing ──\n",
    "class MinesweeperGame:\n",
    "    def __init__(self, rows, cols, num_mines, seed=None):\n",
    "        self.rows, self.cols, self.num_mines = rows, cols, num_mines\n",
    "        self._revealed, self._flagged = set(), set()\n",
    "        rng = random.Random(seed)\n",
    "        all_cells = [(r, c) for r in range(rows) for c in range(cols)]\n",
    "        mines = set(rng.sample(all_cells, min(num_mines, len(all_cells))))\n",
    "        self._board = [[0]*cols for _ in range(rows)]\n",
    "        for r, c in mines:\n",
    "            self._board[r][c] = -1\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if self._board[r][c] != -1:\n",
    "                    count = sum(1 for dr in [-1,0,1] for dc in [-1,0,1]\n",
    "                               if 0 <= r+dr < rows and 0 <= c+dc < cols\n",
    "                               and self._board[r+dr][c+dc] == -1)\n",
    "                    self._board[r][c] = count\n",
    "        self._state = \"ongoing\"\n",
    "        if num_mines == 0:\n",
    "            self._state = \"success\"\n",
    "    \n",
    "    def state(self): return self._state\n",
    "    \n",
    "    def get_visible_board(self):\n",
    "        board = []\n",
    "        for r in range(self.rows):\n",
    "            row = []\n",
    "            for c in range(self.cols):\n",
    "                if (r,c) in self._flagged: row.append(\"F\")\n",
    "                elif (r,c) in self._revealed: row.append(str(self._board[r][c]))\n",
    "                else: row.append(\"?\")\n",
    "            board.append(row)\n",
    "        return board\n",
    "    \n",
    "    def do_action(self, action):\n",
    "        if self._state != \"ongoing\": return self._state\n",
    "        r, c = action.get(\"row\"), action.get(\"col\")\n",
    "        if not (0 <= r < self.rows and 0 <= c < self.cols): return \"invalid\"\n",
    "        if action[\"type\"] == \"flag\":\n",
    "            if (r,c) in self._revealed: return \"invalid\"\n",
    "            self._flagged.add((r,c))\n",
    "            return \"ok\"\n",
    "        if (r,c) in self._revealed or (r,c) in self._flagged: return \"invalid\"\n",
    "        if self._board[r][c] == -1:\n",
    "            self._state = \"failed\"\n",
    "            return \"mine\"\n",
    "        self._reveal(r, c)\n",
    "        safe = self.rows * self.cols - self.num_mines\n",
    "        if len(self._revealed) >= safe:\n",
    "            self._state = \"success\"\n",
    "            return \"win\"\n",
    "        return \"ok\"\n",
    "    \n",
    "    def _reveal(self, r, c):\n",
    "        if (r,c) in self._revealed or (r,c) in self._flagged: return\n",
    "        if not (0 <= r < self.rows and 0 <= c < self.cols): return\n",
    "        if self._board[r][c] == -1: return\n",
    "        self._revealed.add((r,c))\n",
    "        if self._board[r][c] == 0:\n",
    "            for dr in [-1,0,1]:\n",
    "                for dc in [-1,0,1]:\n",
    "                    self._reveal(r+dr, c+dc)\n",
    "\n",
    "# ── Prompt formatting ──\n",
    "SYSTEM_PROMPT = \"You are a Minesweeper AI. Output ONLY valid JSON.\"\n",
    "\n",
    "def format_prompt(game):\n",
    "    board = game.get_visible_board()\n",
    "    grid = \"   \" + \" \".join(str(c) for c in range(game.cols)) + \"\\\\n\"\n",
    "    for r, row in enumerate(board):\n",
    "        grid += f\"{r:2d} \" + \" \".join(row) + \"\\\\n\"\n",
    "    return f\"\"\"Minesweeper {game.rows}×{game.cols}, {game.num_mines} mines\n",
    "\n",
    "{grid}\n",
    "Legend: ?=unrevealed F=flagged 0-8=safe\n",
    "\n",
    "Output JSON only: {{\"type\":\"reveal\",\"row\":N,\"col\":N}} or {{\"type\":\"flag\",\"row\":N,\"col\":N}}\n",
    "Row: 0-{game.rows-1}, Col: 0-{game.cols-1}\"\"\"\n",
    "\n",
    "def parse_action(response):\n",
    "    for match in re.finditer(r\"\\\\{[^{}]*\\\\}\", response):\n",
    "        try:\n",
    "            action = json.loads(match.group())\n",
    "            if \"type\" in action and \"row\" in action and \"col\" in action:\n",
    "                if action[\"type\"] in (\"reveal\", \"flag\"):\n",
    "                    action[\"row\"] = int(action[\"row\"])\n",
    "                    action[\"col\"] = int(action[\"col\"])\n",
    "                    return action\n",
    "        except: pass\n",
    "    return None\n",
    "\n",
    "# ── Run tests ──\n",
    "test_configs = [\n",
    "    (1, 1, 0, 300, \"1×1 Trivial\"),\n",
    "    (3, 3, 1, 301, \"Tiny 3×3\"),\n",
    "    (5, 5, 3, 302, \"Small 5×5\"),\n",
    "    (6, 6, 5, 99,  \"Standard 6×6\"),\n",
    "    (8, 8, 10, 303, \"Medium 8×8\"),\n",
    "    (10, 10, 20, 304, \"Large 10×10\"),\n",
    "    (15, 15, 45, 305, \"XL 15×15\"),\n",
    "    (1, 20, 4, 306, \"Linear 1×20\"),\n",
    "    (5, 5, 0, 307, \"Zero Mines 5×5\"),\n",
    "]\n",
    "\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"  MERGED MODEL INFERENCE TEST — {len(test_configs)} boards\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "results = {\"pass\": 0, \"fail\": 0, \"skip\": 0}\n",
    "\n",
    "for rows, cols, mines, seed, label in test_configs:\n",
    "    print(f\"\\\\n--- {label} ({rows}×{cols}, {mines} mines, seed={seed}) ---\")\n",
    "    \n",
    "    game = MinesweeperGame(rows, cols, mines, seed)\n",
    "    if game.state() != \"ongoing\":\n",
    "        print(f\"  Game auto-resolved: {game.state()}\")\n",
    "        results[\"skip\"] += 1\n",
    "        continue\n",
    "    \n",
    "    prompt = format_prompt(game)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.7,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response = tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "    print(f\"  Response: {response[:150]}{'...' if len(response) > 150 else ''}\")\n",
    "    \n",
    "    action = parse_action(response)\n",
    "    print(f\"  Parsed:   {action}\")\n",
    "    \n",
    "    if action:\n",
    "        result = game.do_action(action)\n",
    "        print(f\"  Result:   {result} → game {game.state()}\")\n",
    "        if result != \"mine\":\n",
    "            results[\"pass\"] += 1\n",
    "        else:\n",
    "            results[\"fail\"] += 1\n",
    "    else:\n",
    "        print(f\"  ⚠️ Failed to parse valid action\")\n",
    "        results[\"fail\"] += 1\n",
    "\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"  INFERENCE TEST SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Pass (valid move): {results['pass']}/{results['pass'] + results['fail']}\")\n",
    "print(f\"  Fail (bad parse/mine): {results['fail']}\")\n",
    "print(f\"  Skipped (auto-win): {results['skip']}\")\n",
    "total = results['pass'] + results['fail']\n",
    "if total > 0:\n",
    "    print(f\"  Success rate: {results['pass']/total*100:.1f}%\")\n",
    "print(f\"\\\\n✅ Merged model inference test complete!\")\n",
    "print(f\"   Model path: {merged_dir}/\")\n",
    "'''\n",
    "\n",
    "# Write script to file\n",
    "script_path = \"run_inference_clean.py\"\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(inference_script)\n",
    "print(f\"✅ Wrote inference script to: {script_path}\")\n",
    "\n",
    "# Run in subprocess (fresh Python, no Unsloth contamination)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Running inference in fresh Python subprocess...\")\n",
    "print(\"(This avoids Unsloth's transformers patches)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, script_path],\n",
    "    capture_output=False,  # Stream output directly\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ Subprocess completed successfully!\")\n",
    "else:\n",
    "    print(f\"❌ Subprocess failed with return code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c190f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Fixes & Improvements Applied\n",
    "\n",
    "## 4-Paper Hybrid Integration (LAMER + XRPO + GRPO-LEAD + S-GRPO)\n",
    "\n",
    "### Paper 1: LAMER — Meta-RL for Language Agents (74% win rate on MineSweeper)\n",
    "| LAMER Finding | Implementation |\n",
    "|---------------|----------------|\n",
    "| ReAct prompting (Reason + Act) | Explicit \"think step-by-step before acting\" in system prompt |\n",
    "| Pre-computed logical hints (CoT) | SAFE/MINE cell lists injected into every prompt |\n",
    "| Center-opening strategy | Reward center on dense boards (>10%), penalize edges/corners |\n",
    "| `temperature=1.0` for training | Full exploration during GRPO generation |\n",
    "| `temperature=0.7` for eval | LAMER paper eval temperature |\n",
    "| `num_iterations=2` | LAMER paper: 2 GRPO iterations for MineSweeper |\n",
    "| STEP 1/STEP 2 reasoning | Satisfied/constrained number scanning |\n",
    "\n",
    "### Paper 2: XRPO — Adaptive Exploration with Difficulty Reweighting\n",
    "| XRPO Finding | Implementation |\n",
    "|--------------|----------------|\n",
    "| Difficulty reweighting | `_difficulty_multiplier()` → harder boards get amplified reward signal (×0.7–×1.5) |\n",
    "| Exploration heuristic | STEP 4 in prompt: prefer high-info cells, low numbers, avoid edges |\n",
    "| Novelty bonus concept | Implicit: difficulty multiplier serves similar purpose (hard=novel→stronger signal) |\n",
    "| Adaptive difficulty proxy | `0.6 × density/0.20 + 0.4 × log(size)/log(2500)` → sigmoid multiplier |\n",
    "| Safety check | Returns 1.0 for 0-mine boards and degenerate cases (Fix #2) |\n",
    "\n",
    "### Paper 3: GRPO-LEAD — Length Penalty & Explicit Wrong Penalty\n",
    "| GRPO-LEAD Finding | Implementation |\n",
    "|-------------------|----------------|\n",
    "| Group-normalized length penalty | 2-pass z-score normalization across correct responses (Fix #6) |\n",
    "| ≤200 token response cap | Instruction in training prompt: \"Total response ≤ 200 tokens\" |\n",
    "| Explicit wrong penalty | Mine reveal: -26 (was -25), wrong flag: -11 (was -10) |\n",
    "| Lower learning rate | `5e-6` (was `2e-5`) for stability with penalty terms |\n",
    "| Concise reasoning | \"2-3 sentences max\" instruction in prompt output format |\n",
    "\n",
    "### Paper 4: S-GRPO — Early Exit When Solution Found\n",
    "| S-GRPO Finding | Implementation |\n",
    "|----------------|----------------|\n",
    "| Early exit instruction | \"Once you find a logical move in Steps 1-3, STOP reasoning and output it immediately\" |\n",
    "| Reduced wasted tokens | Combined with GRPO-LEAD length penalty → shorter, focused responses |\n",
    "| Step-ordered deduction | Steps 1→2→3→4 with explicit \"stop when found\" at each logical step |\n",
    "\n",
    "## Robustness Fixes (Latest Session)\n",
    "| # | Issue | Fix | Priority |\n",
    "|---|-------|-----|----------|\n",
    "| 1 | Infinite loops in `_play_smart_moves()` | `stuck_count` with `MAX_STUCK=10` — break after 10 failed attempts | P0 |\n",
    "| 2 | Div-by-zero in `_difficulty_multiplier()` | Safety check: return 1.0 for `board_size==0` or `num_mines==0` | P3 |\n",
    "| 3 | Missing one-cell-left endgame hint | Compute exact last cell coords, inject `CRITICAL` hint with specific action | P2 |\n",
    "| 4 | Model repeating same valid move forever | `seen_actions` set + `repeat_count` in eval callback & `play_full_game` — break after 3 repeats | P1 |\n",
    "| 6 | Wrong length penalty (absolute not group) | 2-pass GRPO-LEAD: z-score normalize lengths across correct responses, clamp multiplier [0.5, 1.5] | P1 |\n",
    "| 9 | Manual merge fallback had no error handling | Nested try/except — if both Unsloth & PEFT merge fail, print recovery instructions | P3 |\n",
    "| 10 | No progressive difficulty in eval suite | Added 6 configs: same-size density scaling + same-density size scaling + generalization tests | P3 |\n",
    "\n",
    "## 50×50 Board Scalability Fixes\n",
    "| # | Issue | Fix | Impact |\n",
    "|---|-------|-----|--------|\n",
    "| S1 | Token budget mismatch (1900+128=2028, no room for reasoning) | Rebalanced to 1792+256=2048 exact fit | 50×50 Format C (~1335 tokens) fits with 457 token margin for reasoning |\n",
    "| S2 | Large boards only 10% of training data (sizes 1-50) | Boosted to 15% at sizes 30-50; bands now 25/20/20/20/15 | 3× more large board training samples |\n",
    "| S3 | Flat +100 win bonus regardless of board size | Scaled: `100 × (1 + min(1, board_size/1000))` — 50×50→+250, 6×6→+104 | Model motivated to complete large boards |\n",
    "| S4 | Eval `max_iterations` too high (rows*cols*3 = 7500 for 50×50) | Capped to `min(500, rows*cols+100)` | Prevents runaway 50×50 eval loops |\n",
    "| S5 | All eval/inference used `max_new_tokens=128` | Reverted to 128 everywhere — HACKATHON CONSTRAINT: JSON-only output, no reasoning | Pure JSON action is ~10-25 tokens, well under 128 limit |\n",
    "\n",
    "## Exhaustive Dataset Generation\n",
    "| Feature | Details |\n",
    "|---------|---------|\n",
    "| Total samples | 4000 (was 3000) |\n",
    "| Edge cases | 50+ configs (was 25) — trivial, linear, rectangular, density extremes |\n",
    "| Opening training | 25% fresh/single-move boards — train safe opening strategies |\n",
    "| Pattern-specific | 15% — satisfied-number boards + multi-region disconnected boards |\n",
    "| Mid-game deduction | 25% — 3-15 moves, progressive flagging 10%→30%→50% |\n",
    "| Endgame completion | 15% — 80-98% revealed — flag accounting, finish strategy |\n",
    "| Forced guess | 10% — no logical deductions available |\n",
    "| Progressive flagging | 10% early → 30% mid → 50% late |\n",
    "| Density stratification | 8% zero, 17% very sparse, 25% sparse, 25% medium, 25% dense |\n",
    "| Stuck prevention | `MAX_STUCK=10` in `_play_smart_moves()` (Fix #1) |\n",
    "\n",
    "## Prompt System (Hybrid: 4-Paper Master Template)\n",
    "| Feature | Paper Source | Implementation |\n",
    "|---------|-------------|----------------|\n",
    "| ReAct reasoning | LAMER | \"Think step-by-step → STEP 1-4 → Act\" |\n",
    "| Pattern recognition | XRPO | STEP 3: 1-2-1 line, 1-1 corner, zero cascade |\n",
    "| Forced-guess heuristic | XRPO | STEP 4: prefer high-info cells, low numbers, avoid edges |\n",
    "| Early exit | S-GRPO | \"Once you find a logical move in Steps 1-3, STOP\" |\n",
    "| Length control | GRPO-LEAD | \"Total response ≤ 200 tokens\", \"2-3 sentences max\" |\n",
    "| 3-tier board format | Custom | A (≤20): full grid, B (21-35): frontier, C (36-50): summary |\n",
    "| Phase-aware prompts | LAMER | Opening (center), Mid-game (deduction), Endgame (flag accounting) |\n",
    "| Edge case guidance | Custom | 0-mine, linear, tiny, large, high-density, all-flagged, last-cell |\n",
    "| One-cell-left hint | Fix #3 | Computes exact cell coords → \"Reveal (r,c) to WIN!\" or \"Flag (r,c)!\" |\n",
    "| All-remaining-mines | Fix #3 | \"ALL REMAINING N CELLS ARE MINES: Flag any!\" |\n",
    "| Inference variant | LAMER | ~60% shorter for eval/test |\n",
    "\n",
    "## Reward System (3 Functions, Hybrid)\n",
    "| Reward | Weight | Paper Enhancements |\n",
    "|--------|--------|-------------------|\n",
    "| `valid_json_reward` | 0.20 | GRPO-LEAD: group-normalized z-score length penalty (Fix #6) |\n",
    "| `gameplay_scores` | 0.65 | XRPO: difficulty reweighting (×0.7–×1.5), GRPO-LEAD: explicit wrong penalty |\n",
    "| `strategic_reward` | 0.15 | XRPO: difficulty reweighting, LAMER: center-opening |\n",
    "\n",
    "## Evaluation System\n",
    "| Feature | Details |\n",
    "|---------|---------|\n",
    "| Eval callback | 10 configs every 50 steps, temp=0.7, stuck detection (Fix #4) |\n",
    "| Exhaustive eval | 43+ configs (was 37), 1×1 to 50×50 |\n",
    "| Progressive difficulty | Same-size density scaling + same-density size scaling (Fix #10) |\n",
    "| Generalization test | 25×25 10%, 30×30 10% — harder unseen configs |\n",
    "| Stuck detection | Repeated action tracking — break after 3 same-move repeats (Fix #4) |\n",
    "| Category breakdown | Trivial, Tiny, Small, Standard, Medium, Large, XL, Rectangular, Sparse, Progressive |\n",
    "\n",
    "## Training Config (Hybrid Hyperparameters)\n",
    "| Parameter | Value | Source |\n",
    "|-----------|-------|--------|\n",
    "| temperature | 1.0 (train), 0.7 (eval) | LAMER |\n",
    "| learning_rate | 5e-6 | GRPO-LEAD (reduced for stability) |\n",
    "| num_iterations | 2 | LAMER |\n",
    "| beta (KL) | 0.04 | LAMER |\n",
    "| reward_weights | [0.20, 0.65, 0.15] | Hybrid (format↑ for length penalty) |\n",
    "| max_completion_length | 128 | GRPO-LEAD (length control) |\n",
    "| max_grad_norm | 0.5 | Gradient clipping for stability |\n",
    "| warmup_ratio | 0.05 | Stable early training |\n",
    "\n",
    "## Model Save & Inference\n",
    "| Feature | Details |\n",
    "|---------|---------|\n",
    "| LoRA save | `my_minesweeper_model/` — always succeeds |\n",
    "| Merged save | Try Unsloth → fallback PEFT merge → error recovery instructions (Fix #9) |\n",
    "| Merged inference | Standalone HF transformers load — no Unsloth/LoRA needed |\n",
    "| Inference test | 9 diverse boards, pass/fail summary |\n",
    "\n",
    "## Competition Spec Compliance\n",
    "| Requirement | Implementation |\n",
    "|-------------|---------------|\n",
    "| Board rows: 1–50 | `MIN_ROWS=1, MAX_ROWS=50` in game engine |\n",
    "| Board cols: 1–50 | `MIN_COLS=1, MAX_COLS=50` in game engine |\n",
    "| Mines: 0–20% of cells | `MAX_MINE_DENSITY=0.20`, 0 mines allowed |\n",
    "| No move limit | Only success/failure |\n",
    "| Success = all safe revealed | `_check_win()` checks `len(revealed) >= safe_cells` |\n",
    "| Failure = mine revealed | Only `_reveal_cell` hitting mine sets `_state=\"failed\"` |\n",
    "| max_new_tokens: 128 | `max_completion_length=128` in GRPOConfig |\n",
    "\n",
    "## Critical Bugs Fixed (Previous Sessions)\n",
    "| # | Bug | Fix |\n",
    "|---|-----|-----|\n",
    "\n",
    "| 1 | `do_action()` set `_state=\"failed\"` for ALL invalid moves | Only `mine` sets state to \"failed\" |\n",
    "| 8 | Random flags in training data | `_smart_flag()` only flags logically certain mines || 9 | Reward scale imbalance | Rebalanced: JSON=-10, mine=-26, win=+100 |\n",
    "\n",
    "| 2 | Reward functions signature mismatch with TRL GRPOTrainer | `(prompts, completions, **kwargs)` |\n",
    "| 9 | Reward scale imbalance | Rebalanced: JSON=-10, mine=-26, win=+100 || 8 | Random flags in training data | `_smart_flag()` only flags logically certain mines |\n",
    "\n",
    "| 3 | Hardcoded board size in rewards | `_reconstruct_game()` reads from kwargs || 7 | `remove_unused_columns` not set | Explicitly `False` |\n",
    "\n",
    "| 4 | `max_prompt_length=700` truncated prompts | Increased to 1900 || 6 | Eval decoded full output including prompt | Decodes only generated tokens |\n",
    "| 5 | Separate O(n²) passes for safe/mine cells | Combined single pass |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
